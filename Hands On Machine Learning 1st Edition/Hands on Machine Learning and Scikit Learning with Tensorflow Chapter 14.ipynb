{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from keras.layers import SimpleRNN\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data using Numpy arrays\n",
    "x_train = x_train.reshape(60000, 28,28).astype('float32') /  255\n",
    "x_test = x_test.reshape(10000, 28,28).astype('float32') / 255\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_shape=[batch_size, time_steps, features]\n",
    "#return_sequences - return last sequence in output sequence or full sequence.\n",
    "from keras.layers import Flatten\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.SimpleRNN(units = 150, activation='tanh',  return_sequences=True,use_bias=True, kernel_initializer='glorot_uniform',\n",
    "                                   bias_initializer='zeros',input_shape=( 28,28)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(40, activation = 'tanh'),\n",
    "        tf.keras.layers.Dense(10, activation='sigmoid')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 28, 150)           26850     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                168040    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "=================================================================\n",
      "Total params: 195,300\n",
      "Trainable params: 195,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001,),\n",
    "        metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 14s 226us/sample - loss: 2.2415 - accuracy: 0.2646 - val_loss: 2.1612 - val_accuracy: 0.4979\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 13s 215us/sample - loss: 2.1053 - accuracy: 0.5990 - val_loss: 2.0545 - val_accuracy: 0.6658\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 2.0233 - accuracy: 0.6906 - val_loss: 1.9912 - val_accuracy: 0.7143\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 1.9727 - accuracy: 0.7282 - val_loss: 1.9502 - val_accuracy: 0.7429\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 12s 207us/sample - loss: 1.9384 - accuracy: 0.7509 - val_loss: 1.9211 - val_accuracy: 0.7605\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 13s 222us/sample - loss: 1.9133 - accuracy: 0.7657 - val_loss: 1.8990 - val_accuracy: 0.7750\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 1.8938 - accuracy: 0.7774 - val_loss: 1.8815 - val_accuracy: 0.7850\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 1.8782 - accuracy: 0.7872 - val_loss: 1.8672 - val_accuracy: 0.7953\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 1.8651 - accuracy: 0.7953 - val_loss: 1.8551 - val_accuracy: 0.8053\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 1.8538 - accuracy: 0.8027 - val_loss: 1.8445 - val_accuracy: 0.8109\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 1.8439 - accuracy: 0.8093 - val_loss: 1.8352 - val_accuracy: 0.8176\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 13s 213us/sample - loss: 1.8350 - accuracy: 0.8144 - val_loss: 1.8267 - val_accuracy: 0.8226\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 1.8269 - accuracy: 0.8192 - val_loss: 1.8190 - val_accuracy: 0.8283\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 13s 219us/sample - loss: 1.8194 - accuracy: 0.8233 - val_loss: 1.8119 - val_accuracy: 0.8332\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 1.8125 - accuracy: 0.8272 - val_loss: 1.8052 - val_accuracy: 0.8378\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 1.8059 - accuracy: 0.8314 - val_loss: 1.7989 - val_accuracy: 0.8413\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 12s 201us/sample - loss: 1.7998 - accuracy: 0.8353 - val_loss: 1.7930 - val_accuracy: 0.8446\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 12s 201us/sample - loss: 1.7940 - accuracy: 0.8382 - val_loss: 1.7874 - val_accuracy: 0.8468\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 1.7885 - accuracy: 0.8407 - val_loss: 1.7820 - val_accuracy: 0.8493\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 1.7832 - accuracy: 0.8435 - val_loss: 1.7769 - val_accuracy: 0.8511\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 13s 212us/sample - loss: 1.7782 - accuracy: 0.8462 - val_loss: 1.7720 - val_accuracy: 0.8537\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 12s 204us/sample - loss: 1.7734 - accuracy: 0.8490 - val_loss: 1.7673 - val_accuracy: 0.8561\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 12s 205us/sample - loss: 1.7687 - accuracy: 0.8513 - val_loss: 1.7628 - val_accuracy: 0.8580\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 1.7643 - accuracy: 0.8537 - val_loss: 1.7585 - val_accuracy: 0.8598\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 12s 207us/sample - loss: 1.7600 - accuracy: 0.8557 - val_loss: 1.7543 - val_accuracy: 0.8617\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 1.7558 - accuracy: 0.8579 - val_loss: 1.7502 - val_accuracy: 0.8638\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 13s 214us/sample - loss: 1.7518 - accuracy: 0.8596 - val_loss: 1.7462 - val_accuracy: 0.8654\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 13s 222us/sample - loss: 1.7479 - accuracy: 0.8617 - val_loss: 1.7424 - val_accuracy: 0.8674\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 13s 209us/sample - loss: 1.7441 - accuracy: 0.8635 - val_loss: 1.7387 - val_accuracy: 0.8692\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 13s 214us/sample - loss: 1.7405 - accuracy: 0.8653 - val_loss: 1.7351 - val_accuracy: 0.8706\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 18s 306us/sample - loss: 1.7369 - accuracy: 0.8670 - val_loss: 1.7316 - val_accuracy: 0.8725\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 20s 333us/sample - loss: 1.7335 - accuracy: 0.8684 - val_loss: 1.7282 - val_accuracy: 0.8743\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 12s 206us/sample - loss: 1.7301 - accuracy: 0.8701 - val_loss: 1.7249 - val_accuracy: 0.8761\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 1.7268 - accuracy: 0.8716 - val_loss: 1.7217 - val_accuracy: 0.8778\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 12s 204us/sample - loss: 1.7236 - accuracy: 0.8728 - val_loss: 1.7186 - val_accuracy: 0.8800\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 1.7205 - accuracy: 0.8741 - val_loss: 1.7155 - val_accuracy: 0.8815\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 12s 206us/sample - loss: 1.7175 - accuracy: 0.8752 - val_loss: 1.7125 - val_accuracy: 0.8826\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 12s 205us/sample - loss: 1.7146 - accuracy: 0.8760 - val_loss: 1.7096 - val_accuracy: 0.8834\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 12s 205us/sample - loss: 1.7117 - accuracy: 0.8772 - val_loss: 1.7068 - val_accuracy: 0.8847\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 1.7089 - accuracy: 0.8784 - val_loss: 1.7040 - val_accuracy: 0.8854\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 12s 204us/sample - loss: 1.7061 - accuracy: 0.8797 - val_loss: 1.7013 - val_accuracy: 0.8865\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 12s 207us/sample - loss: 1.7034 - accuracy: 0.8809 - val_loss: 1.6986 - val_accuracy: 0.8881\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 13s 211us/sample - loss: 1.7008 - accuracy: 0.8822 - val_loss: 1.6960 - val_accuracy: 0.8890\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 12s 208us/sample - loss: 1.6982 - accuracy: 0.8832 - val_loss: 1.6935 - val_accuracy: 0.8897\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 13s 221us/sample - loss: 1.6957 - accuracy: 0.8845 - val_loss: 1.6910 - val_accuracy: 0.8910\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 13s 220us/sample - loss: 1.6933 - accuracy: 0.8856 - val_loss: 1.6886 - val_accuracy: 0.8927\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 13s 215us/sample - loss: 1.6909 - accuracy: 0.8868 - val_loss: 1.6862 - val_accuracy: 0.8935\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 14s 226us/sample - loss: 1.6885 - accuracy: 0.8880 - val_loss: 1.6839 - val_accuracy: 0.8945\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 14s 231us/sample - loss: 1.6862 - accuracy: 0.8890 - val_loss: 1.6816 - val_accuracy: 0.8957\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 14s 230us/sample - loss: 1.6839 - accuracy: 0.8899 - val_loss: 1.6794 - val_accuracy: 0.8968\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 14s 229us/sample - loss: 1.6817 - accuracy: 0.8910 - val_loss: 1.6772 - val_accuracy: 0.8979\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 14s 236us/sample - loss: 1.6796 - accuracy: 0.8918 - val_loss: 1.6750 - val_accuracy: 0.8986\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 14s 234us/sample - loss: 1.6774 - accuracy: 0.8927 - val_loss: 1.6729 - val_accuracy: 0.9000\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 13s 225us/sample - loss: 1.6753 - accuracy: 0.8933 - val_loss: 1.6708 - val_accuracy: 0.9009\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 12s 201us/sample - loss: 1.6733 - accuracy: 0.8942 - val_loss: 1.6688 - val_accuracy: 0.9016\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 1.6713 - accuracy: 0.8950 - val_loss: 1.6668 - val_accuracy: 0.9023\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 1.6693 - accuracy: 0.8959 - val_loss: 1.6648 - val_accuracy: 0.9026\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 1.6674 - accuracy: 0.8967 - val_loss: 1.6629 - val_accuracy: 0.9032\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 13s 213us/sample - loss: 1.6655 - accuracy: 0.8976 - val_loss: 1.6610 - val_accuracy: 0.9039\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 12s 206us/sample - loss: 1.6636 - accuracy: 0.8986 - val_loss: 1.6592 - val_accuracy: 0.9042\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 1.6617 - accuracy: 0.8993 - val_loss: 1.6574 - val_accuracy: 0.9051\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 12s 204us/sample - loss: 1.6599 - accuracy: 0.8999 - val_loss: 1.6556 - val_accuracy: 0.9058\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 13s 215us/sample - loss: 1.6582 - accuracy: 0.9006 - val_loss: 1.6538 - val_accuracy: 0.9067\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 13s 211us/sample - loss: 1.6564 - accuracy: 0.9014 - val_loss: 1.6521 - val_accuracy: 0.9074\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 12s 204us/sample - loss: 1.6547 - accuracy: 0.9021 - val_loss: 1.6504 - val_accuracy: 0.9082\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 1.6530 - accuracy: 0.9029 - val_loss: 1.6487 - val_accuracy: 0.9089\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 13s 213us/sample - loss: 1.6514 - accuracy: 0.9036 - val_loss: 1.6471 - val_accuracy: 0.9095\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 13s 209us/sample - loss: 1.6497 - accuracy: 0.9045 - val_loss: 1.6455 - val_accuracy: 0.9099\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 13s 218us/sample - loss: 1.6481 - accuracy: 0.9051 - val_loss: 1.6439 - val_accuracy: 0.9106\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 13s 211us/sample - loss: 1.6466 - accuracy: 0.9057 - val_loss: 1.6423 - val_accuracy: 0.9111\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 13s 213us/sample - loss: 1.6450 - accuracy: 0.9062 - val_loss: 1.6408 - val_accuracy: 0.9118\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 12s 205us/sample - loss: 1.6435 - accuracy: 0.9069 - val_loss: 1.6393 - val_accuracy: 0.9124\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 12s 201us/sample - loss: 1.6420 - accuracy: 0.9076 - val_loss: 1.6378 - val_accuracy: 0.9129\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 12s 201us/sample - loss: 1.6405 - accuracy: 0.9081 - val_loss: 1.6364 - val_accuracy: 0.9136\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 13s 211us/sample - loss: 1.6390 - accuracy: 0.9087 - val_loss: 1.6349 - val_accuracy: 0.9145\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 1.6376 - accuracy: 0.9093 - val_loss: 1.6335 - val_accuracy: 0.9149\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 12s 208us/sample - loss: 1.6362 - accuracy: 0.9102 - val_loss: 1.6321 - val_accuracy: 0.9159\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 13s 213us/sample - loss: 1.6348 - accuracy: 0.9108 - val_loss: 1.6308 - val_accuracy: 0.9166\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 12s 204us/sample - loss: 1.6335 - accuracy: 0.9116 - val_loss: 1.6294 - val_accuracy: 0.9173\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 1.6321 - accuracy: 0.9122 - val_loss: 1.6281 - val_accuracy: 0.9177\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 1.6308 - accuracy: 0.9127 - val_loss: 1.6268 - val_accuracy: 0.9183\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 1.6295 - accuracy: 0.9132 - val_loss: 1.6255 - val_accuracy: 0.9188\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 1.6282 - accuracy: 0.9137 - val_loss: 1.6243 - val_accuracy: 0.9194\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 1.6269 - accuracy: 0.9142 - val_loss: 1.6230 - val_accuracy: 0.9202\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 1.6257 - accuracy: 0.9146 - val_loss: 1.6218 - val_accuracy: 0.9207\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 12s 207us/sample - loss: 1.6245 - accuracy: 0.9152 - val_loss: 1.6206 - val_accuracy: 0.9213\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 12s 207us/sample - loss: 1.6232 - accuracy: 0.9157 - val_loss: 1.6194 - val_accuracy: 0.9216\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 13s 225us/sample - loss: 1.6221 - accuracy: 0.9162 - val_loss: 1.6182 - val_accuracy: 0.9219\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 14s 239us/sample - loss: 1.6209 - accuracy: 0.9167 - val_loss: 1.6171 - val_accuracy: 0.9224\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 12s 204us/sample - loss: 1.6197 - accuracy: 0.9170 - val_loss: 1.6160 - val_accuracy: 0.9228\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 12s 205us/sample - loss: 1.6186 - accuracy: 0.9174 - val_loss: 1.6148 - val_accuracy: 0.9231\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 13s 208us/sample - loss: 1.6175 - accuracy: 0.9179 - val_loss: 1.6137 - val_accuracy: 0.9231\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 13s 221us/sample - loss: 1.6163 - accuracy: 0.9186 - val_loss: 1.6126 - val_accuracy: 0.9231\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 13s 222us/sample - loss: 1.6152 - accuracy: 0.9192 - val_loss: 1.6116 - val_accuracy: 0.9236\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 13s 210us/sample - loss: 1.6142 - accuracy: 0.9197 - val_loss: 1.6105 - val_accuracy: 0.9239\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 12s 208us/sample - loss: 1.6131 - accuracy: 0.9203 - val_loss: 1.6095 - val_accuracy: 0.9245\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 1.6120 - accuracy: 0.9205 - val_loss: 1.6084 - val_accuracy: 0.9248\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 12s 201us/sample - loss: 1.6110 - accuracy: 0.9209 - val_loss: 1.6074 - val_accuracy: 0.9247\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 12s 206us/sample - loss: 1.6100 - accuracy: 0.9215 - val_loss: 1.6064 - val_accuracy: 0.9246\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 13s 210us/sample - loss: 1.6090 - accuracy: 0.9219 - val_loss: 1.6054 - val_accuracy: 0.9252\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size = 150 , epochs=100, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "History Dict:  {'loss': [2.241520832180977, 2.105324090719223, 2.023261062502861, 1.9727430495619773, 1.9384458243846894, 1.9132837748527527, 1.8938307082653045, 1.8781572061777114, 1.8650737899541854, 1.8538193696737288, 1.8439013981819152, 1.8349955922365189, 1.8268818521499635, 1.81940573066473, 1.8124551874399186, 1.8059466627240182, 1.799816099703312, 1.7940134206414222, 1.7884986734390258, 1.7832394415140151, 1.7782091099023818, 1.7733855119347572, 1.7687499827146531, 1.7642866492271423, 1.7599819254875184, 1.7558240041136741, 1.7518026247620582, 1.7479087367653847, 1.7441343349218368, 1.7404722717404366, 1.7369161367416381, 1.7334601470828057, 1.730099019408226, 1.7268279698491096, 1.723642595410347, 1.7205388084053994, 1.7175128906965256, 1.714561335146427, 1.7116809314489365, 1.7088686609268189, 1.7061216726899147, 1.7034373465180397, 1.7008132186532021, 1.6982469567656517, 1.6957363539934158, 1.6932793429493904, 1.6908739826083183, 1.6885184305906296, 1.6862109276652335, 1.6839498472213745, 1.6817336133122445, 1.6795607650279998, 1.6774298828840255, 1.675339651107788, 1.6732887929677964, 1.6712760937213897, 1.6693004491925238, 1.6673607370257377, 1.6654559323191642, 1.6635850456357002, 1.6617471194267273, 1.6599412593245506, 1.6581666108965873, 1.6564223599433898, 1.6547077265381813, 1.6530219686031342, 1.6513643929362296, 1.6497342893481255, 1.648131039738655, 1.6465540340542792, 1.6450026699900626, 1.6434763967990875, 1.6419746735692025, 1.6404969638586044, 1.6390427234768867, 1.6376114624738694, 1.6362027049064636, 1.6348159238696098, 1.6334506887197495, 1.6321064919233321, 1.6307828786969185, 1.6294793930649758, 1.6281955796480179, 1.626930984556675, 1.6256851559877397, 1.6244576585292816, 1.6232480520009995, 1.6220558878779412, 1.620880784392357, 1.6197222858667373, 1.6185799556970597, 1.6174533838033676, 1.6163421812653542, 1.6152459183335304, 1.614164188504219, 1.6130965834856033, 1.6120427027344704, 1.6110021495819091, 1.6099745264649392, 1.608959429860115], 'accuracy': [0.26455, 0.59905, 0.69065, 0.7282, 0.75093335, 0.76573336, 0.77736664, 0.78721666, 0.7952833, 0.80275, 0.8092833, 0.8143833, 0.81921667, 0.8233167, 0.8272333, 0.8314, 0.83525, 0.83818334, 0.8407, 0.84351665, 0.8462, 0.84898335, 0.8513333, 0.8537167, 0.85573334, 0.85795, 0.8596, 0.8617333, 0.8635167, 0.8652667, 0.8670167, 0.86835, 0.87008333, 0.87155, 0.8727667, 0.87408334, 0.87518334, 0.87605, 0.8772333, 0.87838334, 0.8797333, 0.88086665, 0.8821667, 0.88325, 0.88451666, 0.88556665, 0.88678336, 0.888, 0.8890167, 0.88991666, 0.89096665, 0.89176667, 0.89265, 0.8932667, 0.89415, 0.8950167, 0.8958833, 0.8967, 0.8976333, 0.89856666, 0.89933336, 0.89988333, 0.90056664, 0.90138334, 0.90215, 0.90291667, 0.90356666, 0.9044833, 0.90515, 0.90571666, 0.90625, 0.9069, 0.90756667, 0.9080667, 0.9087167, 0.90933335, 0.9101667, 0.9108, 0.9115667, 0.91218334, 0.9126833, 0.9132, 0.9137333, 0.91421664, 0.91463333, 0.9152333, 0.91571665, 0.91623336, 0.9167, 0.9169833, 0.9174167, 0.91793334, 0.91856664, 0.9191833, 0.91975, 0.9202833, 0.92053336, 0.9209333, 0.92148334, 0.92191666], 'val_loss': [2.1611912190914153, 2.0545036470890046, 1.9911914616823196, 1.950227501988411, 1.9210590320825576, 1.8989733201265335, 1.8815041810274125, 1.8671820223331452, 1.855064687728882, 1.844534758925438, 1.8351843374967576, 1.8267387503385544, 1.819007825255394, 1.8118562030792236, 1.8051847690343856, 1.7989190465211868, 1.7930018085241317, 1.7873881286382676, 1.782042065858841, 1.776934388279915, 1.7720411121845245, 1.7673420822620391, 1.7628203511238099, 1.7584614622592927, 1.754252946972847, 1.7501839554309846, 1.746245001554489, 1.742427768111229, 1.7387247210741044, 1.73512924015522, 1.7316352957487107, 1.7282374954223634, 1.7249308627843858, 1.7217109298706055, 1.7185734981298446, 1.7155147701501847, 1.712531237602234, 1.7096196126937866, 1.7067768800258636, 1.7040001547336578, 1.7012868428230286, 1.6986344486474991, 1.6960406523942948, 1.6935032725334167, 1.6910202294588088, 1.6885895919799805, 1.6862095129489898, 1.6838782286643983, 1.6815940952301025, 1.6793556129932403, 1.6771612697839737, 1.6750096148252487, 1.6728993713855744, 1.670829244852066, 1.6687980335950852, 1.666804631948471, 1.6648479008674621, 1.6629268258810044, 1.6610404640436172, 1.6591878294944764, 1.6573680704832077, 1.6555803054571152, 1.6538237553834916, 1.6520976555347442, 1.6504012763500213, 1.6487339788675308, 1.6470950013399124, 1.6454837554693222, 1.6438996452093124, 1.642342032790184, 1.640810404419899, 1.639304167032242, 1.6378227972984314, 1.6363657063245773, 1.634932433962822, 1.6335224086046218, 1.6321351367235184, 1.6307701289653778, 1.629426852464676, 1.6281048631668091, 1.6268036568164825, 1.6255227559804917, 1.6242617243528366, 1.623020080924034, 1.6217973667383194, 1.6205931276082992, 1.6194069588184357, 1.6182384246587753, 1.6170871186256408, 1.6159525805711745, 1.614834379553795, 1.6137321317195892, 1.6126454704999924, 1.6115739333629608, 1.610517166852951, 1.609474747776985, 1.6084462749958037, 1.6074313932657243, 1.6064296823740005, 1.6054407513141633], 'val_accuracy': [0.4979, 0.6658, 0.7143, 0.7429, 0.7605, 0.775, 0.785, 0.7953, 0.8053, 0.8109, 0.8176, 0.8226, 0.8283, 0.8332, 0.8378, 0.8413, 0.8446, 0.8468, 0.8493, 0.8511, 0.8537, 0.8561, 0.858, 0.8598, 0.8617, 0.8638, 0.8654, 0.8674, 0.8692, 0.8706, 0.8725, 0.8743, 0.8761, 0.8778, 0.88, 0.8815, 0.8826, 0.8834, 0.8847, 0.8854, 0.8865, 0.8881, 0.889, 0.8897, 0.891, 0.8927, 0.8935, 0.8945, 0.8957, 0.8968, 0.8979, 0.8986, 0.9, 0.9009, 0.9016, 0.9023, 0.9026, 0.9032, 0.9039, 0.9042, 0.9051, 0.9058, 0.9067, 0.9074, 0.9082, 0.9089, 0.9095, 0.9099, 0.9106, 0.9111, 0.9118, 0.9124, 0.9129, 0.9136, 0.9145, 0.9149, 0.9159, 0.9166, 0.9173, 0.9177, 0.9183, 0.9188, 0.9194, 0.9202, 0.9207, 0.9213, 0.9216, 0.9219, 0.9224, 0.9228, 0.9231, 0.9231, 0.9231, 0.9236, 0.9239, 0.9245, 0.9248, 0.9247, 0.9246, 0.9252]}\n"
     ]
    }
   ],
   "source": [
    "print('\\nHistory Dict: ', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_learningCurve(history, epochs):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure(figsize=(10,6))\n",
    "    epoch_range = range(1, epochs+1)\n",
    "    plt.plot(epoch_range, history.history['accuracy'])\n",
    "    plt.plot(epoch_range, history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(epoch_range, history.history['loss'])\n",
    "    plt.plot(epoch_range, history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGDCAYAAABjkcdfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3Sc1Z3/8fcddY36qHdLrnKXhQvNdiC0QICEUEIJJOAlZDeFZM+y2ZL9ZbMbdjfLwm6SJSShLS2EEkKJaTHFgA1yL3KRi7rVey/398czrshGsjQelc/rnOeMNM8zM98xHPtz7r3P9xprLSIiIiJyZrn8XYCIiIjIZKQQJiIiIuIHCmEiIiIifqAQJiIiIuIHCmEiIiIifqAQJiIiIuIHCmEiMuEZY7KNMdYYEziEa281xqwd6fuIiHwWhTARGVOMMQeNMT3GmPgTnt/sDUDZ/qlMRGR0KYSJyFh0ALjh8C/GmLlAmP/KEREZfQphIjIW/R9wyzG/fw14/NgLjDHRxpjHjTG1xpgSY8zfG2Nc3nMBxpifGWPqjDH7gS8M8trfGmOqjDEVxpifGGMChlukMSbVGPNHY0yDMabYGHPHMecWG2MKjTEtxphqY8x93udDjTFPGGPqjTFNxphPjDFJw/1sERn/FMJEZCxaB0QZY2Z5w9F1wBMnXPM/QDSQAyzHCW23ec/dAVwOLAQKgGtOeO1jQB8w1XvNRcDtp1Hn00A5kOr9jH81xlzgPfcA8IC1NgrIBZ71Pv81b90ZgAe4E+g8jc8WkXFOIUxExqrDo2GfB3YBFYdPHBPM/tZa22qtPQj8J3Cz95JrgfuttWXW2gbgp8e8Ngm4FPiutbbdWlsD/Bdw/XCKM8ZkAOcCf2Ot7bLWbgZ+c0wNvcBUY0y8tbbNWrvumOc9wFRrbb+1doO1tmU4ny0iE4NCmIiMVf8HfBW4lROmIoF4IBgoOea5EiDN+3MqUHbCucOygCCgyjsd2AT8CkgcZn2pQIO1tvUkNXwDmA7s8k45Xn7M93odeMYYU2mM+XdjTNAwP1tEJgCFMBEZk6y1JTgL9C8DXjjhdB3OiFLWMc9lcnS0rApnuu/Yc4eVAd1AvLU2xntEWWtnD7PESiDOGBM5WA3W2r3W2htwwt2/Ac8ZY9zW2l5r7f+z1uYBZ+NMm96CiEw6CmEiMpZ9A/ictbb92Cettf04a6z+xRgTaYzJAu7m6LqxZ4FvG2PSjTGxwD3HvLYKeAP4T2NMlDHGZYzJNcYsH05h1toy4EPgp97F9vO89T4JYIy5yRiTYK0dAJq8L+s3xqw0xsz1Tqm24ITJ/uF8tohMDAphIjJmWWv3WWsLT3L6r4B2YD+wFngKeNh77tc4U35bgI18eiTtFpzpzJ1AI/AckHIaJd4AZOOMir0I/Mha+6b33CXADmNMG84i/euttV1AsvfzWoAi4F0+fdOBiEwCxlrr7xpEREREJh2NhImIiIj4gUKYiIiIiB8ohImIiIj4gUKYiIiIiB8ohImIiIj4QaC/Cxiu+Ph4m52d7e8yRERERD7Thg0b6qy1CYOdG3chLDs7m8LCk7UNEhERERk7jDElJzun6UgRERERP1AIExEREfEDhTARERERPxh3a8JERERk7Ovt7aW8vJyuri5/l3JGhIaGkp6eTlBQ0JBfoxAmIiIio668vJzIyEiys7Mxxvi7HJ+y1lJfX095eTlTpkwZ8us0HSkiIiKjrqurC4/HM+EDGIAxBo/HM+xRP4UwERER8YnJEMAOO53vqhAmIiIiE059fT0LFixgwYIFJCcnk5aWduT3np6eIb3Hbbfdxu7du31Wo9aEiYiIyITj8XjYvHkzAP/0T/9EREQEP/jBD467xlqLtRaXa/AxqUceecSnNWokTERERCaN4uJi5syZw5133kl+fj5VVVWsWrWKgoICZs+ezY9//OMj15577rls3ryZvr4+YmJiuOeee5g/fz7Lli2jpqZmxLVoJExERER86v+9vIOdlS2j+p55qVH86IrZp/XanTt38sgjj/Dggw8CcO+99xIXF0dfXx8rV67kmmuuIS8v77jXNDc3s3z5cu69917uvvtuHn74Ye65554RfQeNhJ2gpauXNbtrqG3t9ncpIiIi4gO5ubmcddZZR35/+umnyc/PJz8/n6KiInbu3Pmp14SFhXHppZcCsGjRIg4ePDjiOjQSdoLS+g5ue+QTHrxpEZfMSfZ3OSIiIuPe6Y5Y+Yrb7T7y8969e3nggQf4+OOPiYmJ4aabbhq01URwcPCRnwMCAujr6xtxHRoJO4EnwvlDbmgf2p0TIiIiMn61tLQQGRlJVFQUVVVVvP7662fsszUSdoLY8MMhTNORIiIiE11+fj55eXnMmTOHnJwczjnnnDP22cZae8Y+bDQUFBTYwsJCn37G7H9czXVnZfKPV+R99sUiIiLyKUVFRcyaNcvfZZxRg31nY8wGa23BYNdrOnIQcRHBGgkTERERn1IIG0RceDD1WhMmIiIiPqQQNog4dzCNHQphIiIi4jsKYYOIc4fQ0KYQJiIiIr6jEDaIOHcQ9e09jLebFkRERGT8UAgbRJw7hO6+ATp7+/1dioiIiExQCmGD8LidXmH1mpIUEREZl1asWPGpxqv3338/d91110lfExER4euyjqMQNohYt7rmi4iIjGc33HADzzzzzHHPPfPMM9xwww1+qujTFMIGEXc4hOkOSRERkXHpmmuu4ZVXXqG72+n7efDgQSorK1mwYAEXXHAB+fn5zJ07l5deeslvNWrbokEcno7UHZIiIiKj4E/3wKFto/ueyXPh0ntPetrj8bB48WJWr17NlVdeyTPPPMN1111HWFgYL774IlFRUdTV1bF06VK++MUvYowZ3fqGQCNhg9B0pIiIyPh37JTk4alIay0//OEPmTdvHhdeeCEVFRVUV1f7pT6NhA0iKjSQoACj6UgREZHRcIoRK1+66qqruPvuu9m4cSOdnZ3k5+fz6KOPUltby4YNGwgKCiI7O5uuri6/1OezkTBjTIYxZo0xpsgYs8MY851BrrnRGLPVe3xojJnvq3qGwxhDbHiwpiNFRETGsYiICFasWMHXv/71Iwvym5ubSUxMJCgoiDVr1lBSUuK3+nw5HdkHfN9aOwtYCnzLGJN3wjUHgOXW2nnAPwMP+bCeYYlza/9IERGR8e6GG25gy5YtXH/99QDceOONFBYWUlBQwJNPPsnMmTP9VpvPpiOttVVAlffnVmNMEZAG7Dzmmg+Peck6IN1X9QyX9o8UEREZ/66++urjdsCJj4/no48+GvTatra2M1UWcIYW5htjsoGFwPpTXPYN4E9nop6hiHMHa2G+iIiI+IzPF+YbYyKA54HvWmtbTnLNSpwQdu5Jzq8CVgFkZmb6qNLjxbmDqW/rPiOfJSIiIpOPT0fCjDFBOAHsSWvtCye5Zh7wG+BKa239YNdYax+y1hZYawsSEhJ8V/Ax4tzBtHT10ds/cEY+T0RERCYXX94daYDfAkXW2vtOck0m8AJws7V2j69qOR2HG7ZqXZiIiMjpOXYt1kR3Ot/Vl9OR5wA3A9uMMZu9z/0QyASw1j4I/CPgAX7p7VTbZ60t8GFNQ3Zsw9bEyFA/VyMiIjK+hIaGUl9fj8fj8Us3+jPJWkt9fT2hocPLC768O3ItcMo/dWvt7cDtvqphJOLUNV9EROS0paenU15eTm1trb9LOSNCQ0NJTx9ekwd1zD8JjzsEUAgTERE5HUFBQUyZMsXfZYxp2jvyJGLdQYBCmIiIiPiGQthJxIZrOlJERER8RyHsJIICXESHBSmEiYiIiE8ohJ2C9o8UERERX1EIO4U4dzCNCmEiIiLiAwphp6D9I0VERMRXFMJOIS5c05EiIiLiGwphpxAX4UxHTqZtF0REROTMUAg7BY87mL4BS0tXn79LERERkQlGIewUDvcK0+J8ERERGW0KYacQF+GEMK0LExERkdGmEHai6p3w88Vw4D082sRbREREfEQh7ERBYVC3G5pKNR0pIiIiPqMQdqLIFOextQqPpiNFRETERxTCThQUCmGx0FJFeHAgoUEuGtq7/V2ViIiITDAKYYOJTIXWQ4DTsLWhvdfPBYmIiMhEoxA2mMhkaK0CnDskNRImIiIio00hbDCRKUdDmDtEd0eKiIjIqFMIG0xUCrRVw0A/ceFBNHQohImIiMjoUggbTGQy2AFor3VGwtoUwkRERGR0KYQN5nCbipZKPBHBtPf009Xb79+aREREZEJRCBvMkV5hh442bNWUpIiIiIwihbDBHNOwNc67dVG9piRFRERkFCmEDSYiEYzruK75ukNSRERERpNC2GBcARCRBK1Vmo4UERERn1AIO5nIZGipwqPpSBEREfEBhbCT8W5dFB0WhMtoOlJERERGl0LYyXi3LnK5DLHhwWrYKiIiIqNKIexkIlOgswF6u4hzB6thq4iIiIwqhbCTifK2qWg75IQwTUeKiIjIKFIIO5nIZOex1RvCNB0pIiIio0gh7GQiU53HlkqNhImIiMioUwg7mWNGwjzuYBo7eugfsP6tSURERCYMhbCTCYuFgBCnYas7GGuhubPX31WJiIjIBKEQdjLGOIvzj9k/sqG9289FiYiIyEShEHYqkSne6cgQQF3zRUREZPQohJ1KZDK0VBLrDgK0f6SIiIiMHp+FMGNMhjFmjTGmyBizwxjznUGumWmM+cgY022M+YGvajlt3q2LPN5NvOt1h6SIiIiMkkAfvncf8H1r7UZjTCSwwRjzprV25zHXNADfBq7yYR2nLzIZetuJD+4mwGWoauryd0UiIiIyQfhsJMxaW2Wt3ej9uRUoAtJOuKbGWvsJMDZvO4xyeoUFtleTFhNGaUOHnwsSERGRieKMrAkzxmQDC4H1p/n6VcaYQmNMYW1t7WiWdmpHeoVVkRkXTolCmIiIiIwSn4cwY0wE8DzwXWtty+m8h7X2IWttgbW2ICEhYXQLPJVI7/6RrYfIiAunTCFMRERERolPQ5gxJggngD1prX3Bl5/lE4dHwloqyYwLp6G9h9ausTlzKiIiIuOLL++ONMBvgSJr7X2++hyfCnZDSDS0HiLLEw6gdWEiIiIyKnx5d+Q5wM3ANmPMZu9zPwQyAay1DxpjkoFCIAoYMMZ8F8g73WlLn4hMPrImDKCsoYPZqdF+LkpERETGO5+FMGvtWsB8xjWHgHRf1TAqvFsXZcRpJExERERGjzrmfxbv1kXRYUHEhAcphImIiMioUAj7LJHOSBgDA06binqFMBERERk5hbDPEpkCA33QUa82FSIiIjJqFMI+ywkNW8sbO+kfsP6tSURERMY9hbDP4t26iNYqsuLC6RuwVDZ1+rcmERERGfcUwj7LCSNhgKYkRUREZMQUwj5LRBJgjmxdBGpTISIiIiOnEPZZAoLAnQAtlaTGhBHoMgphIiIiMmIKYUMRmQythwhwGdJjwyhRCBMREZERUggbiqhUp1cYqE2FiIiIjAqFsKHw7h8JkBkXrulIERERGTGFsKGITIH2WujvJcsTTlNHL82dvf6uSkRERMYxhbChiExxHlsPqU2FiIiIjAqFsKE4JoSpTYWIiIiMBoWwoRikYatCmIiIiIyEQthQHN66qKWCyNAg4tzBlNQrhImIiMjpUwgbinAPhMVC7W5AbSpERERk5BTChsIYSMyDmp2A2lSIiIjIyCmEDVViHtQUgbVkxYVT0dRJb/+Av6sSERGRcUohbKgSZ0F3CzSXkxkXTv+Apaqpy99ViYiIyDilEDZUSbOdx5oitakQERGREVMIG6qEmc5jzQ4yPQphIiIiMjIKYUMVFgNRaVBTRHJUKMEBLkoa2v1dlYiIiIxTCmHD4b1DMsBlSI8NU5sKEREROW0KYcOROAtq90B/HxlqUyEiIiIjoBA2HEmzob8bGvaT5QmnpL4Da62/qxIREZFxSCFsOBJnOY81O8iMC6e1q4/mzl7/1iQiIiLjkkLYcMTPAONSmwoREREZMYWw4QgKhbhcqHZGwgBt5C0iIiKnRSFsuJKc7YsyNRImIiIiI6AQNlyJedCwH7fpITkqlD3Vrf6uSERERMYhhbDhSswDLNTtZn5GNJvLmvxdkYiIiIxDCmHDlZjnPNYUsTAzlpL6Durbuv1bk4iIiIw7CmHDFTcFAkOhegcLM2IA2FKu0TAREREZHoWw4XIFQMIMqClibno0AS7DplKFMBERERkehbDT4d1DMjw4kBlJkQphIiIiMmwKYacjMQ9aq6CjgYWZMWwpa2JgQNsXiYiIyNAphJ2OExbnt3b3sa+2zb81iYiIyLjisxBmjMkwxqwxxhQZY3YYY74zyDXGGPPfxphiY8xWY0y+r+oZVUmHQ9hOFngX52tKUkRERIbDlyNhfcD3rbWzgKXAt4wxeSdccykwzXusAv7Xh/WMnsgUCI2GmiJy4t1EhQaySf3CREREZBh8FsKstVXW2o3en1uBIiDthMuuBB63jnVAjDEmxVc1jRpjIHE21OzE5TIsyIxlU2mjv6sSERGRceSMrAkzxmQDC4H1J5xKA8qO+b2cTwc1jDGrjDGFxpjC2tpaX5U5PImzoGYnWMvCjBj2VLfS1t3n76pERERknPB5CDPGRADPA9+11raceHqQl3zqNkNr7UPW2gJrbUFCQoIvyhy+xFnQ1QwtlSzIjGHAwlY1bRUREZEh8mkIM8YE4QSwJ621LwxySTmQcczv6UClL2saNUmznceaIhakO4vztY+kiIiIDJUv7440wG+BImvtfSe57I/ALd67JJcCzdbaKl/VNKoSZzmPNTuIdQeTE+/WHZIiIiIyZIE+fO9zgJuBbcaYzd7nfghkAlhrHwReAy4DioEO4DYf1jO6wmIhJhPKPwFgQUYM7+2tw1qLkz9FRERETs5nIcxau5bB13wde40FvuWrGnxuynIo+iMM9LMwM4YXNlVQ0dRJemy4vysTERGRMU4d80cid6WzOL9yEwszYwE1bRUREZGhUQgbiSnLncd9a5iRHElokEshTERERIZEIWwk3PGQPA/2v0NQgIu5adFsLlPTVhEREflsCmEjlbsSytZDdxsLM2PZXtlCd1+/v6sSERGRMU4hbKRyVsJAL5R8yMKMGHr6BiiqavV3VSIiIjLGKYSNVOZSCAiB/e8cWZy/WftIioiIyGdQCBupoDDIWgb715AcHUpyVCiFJQphIiIicmoKYaMhZ6WzmXfrIc6fHs+7e2rp6Rvwd1UiIiIyhimEjYacFc7j/ne5ZE4yrV19fLS/3p8ViYiIyBinEDYakudBuAf2r+Hs3HgiQgJZvX18bIEpIiIi/qEQNhpcLqdx6741hAa6WDkzkTd2VNM/YP1dmYiIiIxRCmGjJXcltB2C2t1cMjuZ+vYeCg82+LsqERERGaMUwkZLzgrncf8aVsxIIDjQxeodh/xZkYiIiIxhCmGjJSYT4nJh3xrcIYGcPy2B17cfwlpNSYqIiMinKYSNptyVcHAt9PVwyZxkKpu72FbR7O+qREREZAxSCBtNOSugtx0qCrlwViIBLsPq7ZqSFBERkU9TCBtN2eeBccG+NcSEB7Msx8NqTUmKiIjIIBTCRlNYDGQsgaKXwVounpPM/rp2imva/F2ZiIiIjDEKYaNt3nVQWwSVm7g4Lwlj0JSkiIiIfIpC2Gib8yUIDIXNT5IYFUp+ZqxaVYiIiMinKISNttBomHUFbHsOeru4ZHYyOypbKGvo8HdlIiIiMoYMKYQZY3KNMSHen1cYY75tjInxbWnj2IIboasJdr/GxbOTAXhdo2EiIiJyjKGOhD0P9BtjpgK/BaYAT/msqvFuyvkQlQ6bnyLTE05eShQvb9WG3iIiInLUUEPYgLW2D7gauN9a+z0gxXdljXOuAFhwA+x7G1oq+UpBOlvKmthS1uTvykRERGSMGGoI6zXG3AB8DXjF+1yQb0qaIObfAHYAtv6OaxalExESyCMfHPB3VSIiIjJGDDWE3QYsA/7FWnvAGDMFeMJ3ZU0AnlzIPBs2PUlkSCDXFmTwytYqqlu6/F2ZiIiIjAFDCmHW2p3W2m9ba582xsQCkdbae31c2/i34KtQvxfKC7n17Gz6reX/Pirxd1UiIiIyBgz17sh3jDFRxpg4YAvwiDHmPt+WNgHMvgqCwmHzE2R6wvn8rCSeXF9CV2+/vysTERERPxvqdGS0tbYF+BLwiLV2EXCh78qaIEIiIe9K2P4C9Hby9XOn0NjRyx82Vfi7MhEREfGzoYawQGNMCnAtRxfmy1AsuBG6W6DoFZZMiSMvJYqHPzigTb1FREQmuaGGsB8DrwP7rLWfGGNygL2+K2sCyToHYjJh42MYY7jtnGz2VLfxQXG9vysTERERPxrqwvzfW2vnWWu/6f19v7X2y74tbYJwueCs2+Hg+1D2MVfMTyU+IpiH1a5CRERkUhvqwvx0Y8yLxpgaY0y1MeZ5Y0y6r4ubMM66HcI98M69hAYFcOOSLP68q4YDde3+rkxERET8ZKjTkY8AfwRSgTTgZe9zMhTBbjj7r5wO+mWfcOPSTIIDXDyq0TAREZFJa6ghLMFa+4i1ts97PAok+LCuieesOyAsDt69l8TIUK6Yn8rvCss41KzmrSIiIpPRUENYnTHmJmNMgPe4CdDK8uEIiXBGw4rfgvJCvnPBNAYG4D9e3+3vykRERMQPhhrCvo7TnuIQUAVcg7OVkQzHYu9o2Dv3kukJ57Zzs3l+Yznbypv9XZmIiIicYUO9O7LUWvtFa22CtTbRWnsVTuPWkzLGPOxdyL/9JOdjvYv9txpjPjbGzDmN+seXkEg4+y+h+E0o38C3Vk7F4w7mn1/dqb5hIiIik8xQR8IGc/dnnH8UuOQU538IbLbWzgNuAR4YQS3jx+JVEBYL7/4bUaFBfO/z0/n4QAOv7zjk78pERETkDBpJCDOnOmmtfQ9oOMUlecDb3mt3AdnGmKQR1DM+hETCsr+Eva9DxQauPyuD6UkR/PRPu+ju056SIiIik8VIQthI58+24J3SNMYsBrKAydF77PBo2Dv3Ehjg4u+/kEdJfQePf1ji78pERETkDDllCDPGtBpjWgY5WnF6ho3EvUCsMWYz8FfAJqDvJHWsMsYUGmMKa2trR/ixY0BoFJzzHdj7Bux5nfOnJ7BiRgL//ee91Ld1+7s6EREROQNOGcKstZHW2qhBjkhrbeBIPtha22Ktvc1auwBnTVgCMGj3UmvtQ9baAmttQULCBGlPtvRbkDATXv0+dLfx91+YRUdPPw+8rS05RUREJoORTEeOiDEmxhgT7P31duA9a22Lv+o54wKD4fL7obkM3vkpUxMjuXFJJk+uL2VTaaO/qxMREREf81kIM8Y8DXwEzDDGlBtjvmGMudMYc6f3klnADmPMLuBS4Du+qmXMyloGi26Fdb+Eys18/6IZJEeFcvezW+joGXRmVkRERCYIM976UxUUFNjCwkJ/lzF6Ohvh54shKhVuf5t1Jc3c8Ot13LA4k3+9eq6/qxMREZERMMZssNYWDHbOb9OR4hUWC5f+G1Rtho8fYmmOh1Xn5/DU+lLe2lnt7+pERETERxTCxoLZV8O0i+DPP4GmMu7+/HRmpUTxN89vpbZVd0uKiIhMRAphY4ExcNnPAAuv/YCQABcPXL+A1u4+7nl+q7Y0EhERmYAUwsaK2Cz43N/DntXwyW+YnhTJPZfM5O1dNTz1cam/qxMREZFRphA2liz5Jky7GFb/LZRv4NazszlvWjw/eaWIXYcmT/cOERGRyUAhbCxxueDqByEyBX7/NVxdjfzsK/OJDA3kG48WUqdu+iIiIhOGQthYEx4H1z4GbdXwwiqSIoL5zdcKqG/vZtXjhXT1apNvERGRiUAhbCxKy4dL7oXiN+H9/2Reegz3XbuAjaVNWqgvIiIyQSiEjVUFX4e518Kaf4F9a7hsbgo/uGg6f9hcyS/WFPu7OhERERkhhbCxyhi44n5nk+/nb4fGEr61cipXL0zjZ2/s4bVtVf6uUEREREZAIWwsC3bDtY/DQC888SVMRz0//dJcFmXFcvezm9lQ0uDvCkVEROQ0KYSNdQnT4avPQnM5PHkNoQOd/OrmRSRHhXLrw5+wpazJ3xWKiIjIaVAIGw8yl8JXHoWqrfDszcSHGp66Yykx7iBu/u16tlc0+7tCERERGSaFsPFixqVwxQOw78/w0l2kRoXw1O1LiQwN4qbfrqeoSs1cRURExhOFsPEk/2a44Eew7ffwxt+RERvGU3csITQwgJt+s5691a3+rlBERESGSCFsvDn3e872Rut+CW//mKy4cJ66Ywkul+GGX6+nuEZBTEREZDxQCBtvjIGL/xXyvwZr74PV95AT7+bpO5YA8JUHP2JjaaOfixQREZHPohA2HrlczvqwJd+E9Q/Cy99hanw4z39zGVFhQXz11+tYs6vG31WKiIjIKSiEjVfGwCU/hfN+ABsfgxfvJCsmhOfuPJupiRHc/nghvy8s83eVIiIichIKYeOZMXDBP8Dn/gG2PQvP3UpCmOGZVctYluPhr5/byi/fKdZekyIiImOQQthEcP4P4OKfQtHL8MSXiOhv4eFbz+KL81P599W7+fs/bKenb8DfVYqIiMgxFMImimV3wdUPQdl6+O3nCW4+wP3XLeDO5bk8ub6Um367nrq2bn9XKSIiIl4KYRPJ/Ovglj9CRwP85gJcZR9xz6UzeeD6BWwpa+KL/7NW3fVFRETGCIWwiSZrGdzxNrgT4LEvwpZnuHJBGs/deTYA1zz4IS9trvBzkSIiIqIQNhHF5cA33nAC2Yt/AW/+I3NT3Pzxr85lXloM33lmM//y6k6tExMREfEjhbCJKiwWbnoBCr4BHzwAj19JvG3iiduXcMuyLH79/gG+8quPKGvo8HelIiIik5JC2EQWEASX3wdX/woqNsCvziO4/CN+fOUcfnljPvtr27jsv9/ntW1V/q5URERk0lEImwzmXw93/BlCIuGxK2Dt/Vw2J5nXvn0euQkR3PXkRv7uxW109fb7u1IREZFJQyFsskjKgzvWwKzL4a0fwVPXkRHczu/vXMZfnJ/Dk+tL+eLPdfekiIjImaIQNpmERsFXHoNL/+PoR2AAACAASURBVB32vwP/u4yg4jf428tm8ehtZ9HU0ctVv/iAB97aS2+/Fu2LiIj4kkLYZGMMLPkLWPUORCTB09fBK3ezYkoEb3zvfL4wL4X/emsPX/7fD9lb3ervakVERCYshbDJKinPWSd29l9B4cPwq/OJadzOA9cv5Jc35lPe2MkX/mctv3p3H30aFRMRERl1CmGTWWAIXPQTuOUl6O2A31wIb/6Iy2bG8Pp3z2fF9AR++qddXPXLD9hWrrViIiIio0khTCBnOXzzQ1jwVfjgfvjfc0ioL+RXNy/ilzfmU93SzZW/WMtPXtlJe3efv6sVERGZEBTCxBEWA1f+3BkVG+iDRy/DvPYDLpsewVt3L+eGxZn8Zu0BLvqv91izq8bf1YqIiIx7CmFyvJwVcNdHsPQu+OS38IslRB94jX+5ag6/v3MZYcEB3PboJ9zxeKG67YuIiIyAQph8WrAbLvmps/9kWCw8ews8eQ1nRTby2rfP428umckHxXVccN+73PfmHjp71ORVRERkuIy11t81DEtBQYEtLCz0dxmTR38ffPwQrPlX6O+Bc78H536PQx3wr68V8cctlaTFhPEPl8/i4tnJGGP8XbGIiMiYYYzZYK0tGOycz0bCjDEPG2NqjDHbT3I+2hjzsjFmizFmhzHmNl/VIiMQEAjL7oK//MTptv/uvfDLJSRXvsl/X7+AZ1YtJSIkkDuf2Mj1D63TXZQiIiJD5MvpyEeBS05x/lvATmvtfGAF8J/GmGAf1iMjEZUC1zzsLNwPDIPf3QSPXcHS8Epe/fa5/PNVcyiuaeOKn6/le7/bTGVTp78rFhERGdN8FsKste8BDae6BIg0zvxVhPda9T8Y63JWwJ1r4bKfQfUOePA8Al/9DjfPCWPNX6/gmytyeXVbFSt/9g7/vnoXLV29/q5YRERkTPLpmjBjTDbwirV2ziDnIoE/AjOBSOA6a+2rJ3mfVcAqgMzMzEUlJSW+KlmGo7MR3vsZrH8QAkPhnO/A0rso73DxH6/v5qXNlcSEB3HXilxuWZZNaFCAvysWERE5o061JsyfIewa4BzgbiAXeBOYb61tOdV7amH+GFRXDG/9CHa9Au5EWPE3kP81tlV18B9v7Oa9PbUkR4Xy7Qum8ZWCdIICdFOuiIhMDn5ZmD8EtwEvWEcxcABnVEzGm/ipcP2T8I03wTMVXv0+/GIxc5ve5vFbC3hm1VJSY0L54YvbuOi/3uMPmyroHxhfd+WKiIiMNn+GsFLgAgBjTBIwA9jvx3pkpDIWw22vwVefdaYnn7sNHjqfpT3ref7OZfzmlgJCAl1893eb+fx/vctLmxXGRERk8vLZdKQx5mmcux7jgWrgR0AQgLX2QWNMKs4dlCmAAe611j7xWe+r6chxYqAftj3ntLRo2A+p+bDy7xjI+Ryrd1bzwFt72V3dSm6Cm29fMI3L56US4FKPMRERmVj8tibMFxTCxpn+PtjyNLz779BcChlLYPnfMDBlJX/aUc0Db+9hT3UbOQluvrk8l6sWpmnNmIiITBgKYeJ/fT2w6f/g/f+ElgpIWwTn/zUDUy/mTzuq+fmaYoqqWkiLCeMvludwbUGG7qYUEZFxTyFMxo6+btj8FKy9D5pKIWkunP8D7KwreGdPPT9fU8yGkkbiI4L5+rlTuHFJFtFhQf6uWkRE5LQohMnY09/rrBl7/2dQXwyeaXDOt7Fzr2V9WTu/WFPM+3vrcAcHcP3iTL5+7hTSYsL8XbWIiMiwKITJ2DXQDzv/AGvvh0NbITIFln4TFt3G9nrLr9/fzytbqzDA5fNSuOP8HGanRvu7ahERkSFRCJOxz1rYv8YJYwfehZBoKLgNFq+ifCCWh9ce5JlPSuno6WdZjoevnzuFz81M1B2VIiIypimEyfhSsRE+eACK/gjGBbO/BMvuojlmDs98UspjHx6ksrmLLE84t56dzVcKMogICfR31SIiIp+iECbjU+NBWP8QbHwceloh6xxYehd9Uy9mdVEtD689wMbSJiJDAvnyonRuXpZFbkKEv6sWERE5QiFMxreuZtj4f85G4c1lEJMJZ90B+TezqRYe+/Agr26rorffct60eL62LJuVmqoUEZExQCFMJob+Ptj9qjM6VrIWAsNg/nWweBW14VN55uNSnlxfyqGWLtJjw7hhcSbXFmSQEBni78pFRGSSUgiTiefQNvj4Idj6LPR1QeYyOOt2eqd/gbf2NPH4RyV8tL+eoADDRbOTuXFJJstyPBij0TERETlzFMJk4upogE1PQOHD0HgAwuMh/2ZYdBv7+jw8vb6U328op7mzl5x4N9edlcGXF6UTH6HRMRER8T2FMJn4BgZg/5/hk4dhz5+clhdTL4D8r9GVcxGv7azjyfWlbChpJNBl+HxeEtedlcF50xK0dkxERHxGIUwml+Zy547KTU84+1S6E2HhjZB/C3t7E/jdJ2U8v7Gcxo5e0mLC+HJ+GtcsyiDTE+7vykVEZIJRCJPJqb8Pit+CjY/BntVgByD7PFh4E93Tv8Bbe9t45pNS1hbXYS0smRLHVwoyuGxuMuHB6jsmIiIjpxAm0lIJm56EzU84/cdComDOl2DBTVRGzOaFTRU8t6Gcg/UduIMDuHRuCl/KT2PpFA8uTVeKiMhpUggTOWxgAEo/dKYqd/wB+johfjrMvx477zo+aQjnuQ1lvLbtEG3dfaRGh3LVwjS+lJ/O1EQ1ghURkeFRCBMZTFcL7HgBtjwDpR8BBnKWw/wb6My9jDf3tfHCxnLe31tH/4Blblo0Vy5I5Yr5qSRFhfq7ehERGQcUwkQ+S8N+J4xteRqaSiHIDbMuh3nXUpOwlD9ureGlzZVsq2jGZWBZrocrF6RxyZxkokKD/F29iIiMUQphIkM1MOCMim17Fna86GyZ5E6EOV+GuV9hX/B0XtpSxUubKyip7yA4wMWKGQlcMT+VC2YlakG/iIgcRyFM5HT0dcPeN5yu/HtWQ38PxE6BOV/GzvkyW3pSeXlLJa9sraS6pZuwoAAuzEvi8nkpLJ+eQGhQgL+/gYiI+JlCmMhIdTbBrldg23Nw4F2n3UXibJjzJQbyruaTlhhe3lrJa9sO0dDegzs4gAtmJXHZ3BRWzFAgExGZrBTCREZTW41zZ+X256BsvfNcynyYfTV9M69kXWMUr26rZPX2QzR29OIODuBzs5K4dE4yK2YkaMpSRGQSUQgT8ZXmcieQ7XgRKrz/X6YuhFlfpG/GFaxrjuXVbZW8vqOahvYeQoNcLJ+ewCVzkrlgVpIW9YuITHAKYSJnQmMJ7PwD7HwJKjY4zyXNgbwr6ZtxOR+3JbB6RzWv7zhEdUs3QQGGZbnxXJSXxEV5SSSq7YWIyISjECZypjWVQdHLTiArW+c855kGsy5nYMYVbOqfwus7nUBWUt8BwMLMGC6enczn85LITVBjWBGRiUAhTMSfWqqcRf1FL8PBtWD7ISoNZn4BO+ML7Amdxxu76nl95yG2V7QAkBPv5vN5SVyYl0R+ZiwB2jpJRGRcUggTGSs6GmDP604oK34L+rogNBqmXQQzLqMy4Vze2t/BmzurWbe/nt5+S5w7mBUzErhgZhLnTY/XOjIRkXFEIUxkLOrpgP1rYNdrsOdP0FEPriDIPhdmXEZb9oW8Wx3GW0XVrNldQ1NHL4Euw5KcOFbOSORzMxPJ0bSliMiYphAmMtYN9DvtLna/BrtXQ/1e5/nE2TD9YvqnXczG/lze3l3Pn3dVs6e6DYBsTzgrZiSycmYiS6bEqR+ZiMgYoxAmMt7U74Pdf3I69Zd86KwjC4uDqRfC9Iup8CzjzyW9/HlXDR/uq6e7b4DQIBdn58azfHoCy6cnkB3v9ve3EBGZ9BTCRMazzkbY92fY8wYUv+lMWxoXpC+GaRfSnX0BH3aksmZ3He/srqW0wbnbMtsTzvLpCZw/PYGlOR7cIWoSKyJypimEiUwUA/1QsRH2vg5734Sqzc7z7kRnlGzqBZTGLGFNWT/v7qnlw311dPUOEBRgWJQVy/nTEzh/WgJ5KVG4dMeliIjPKYSJTFRtNVD8tjNCVvw2dDUBBtLyIfcCurNXUNiXy3vFjby7p5Zdh1oB8LiDOXtqPOdNjeecafGkxYT593uIiExQCmEik8HhUbJ9bzuBrKLQ2Wg8JBqmnAe5K6lPPId3aiNYu6+etcV11LZ2A05fsnOnxXN2bjzLcjxEh6sNhojIaFAIE5mMOhth/zuwb41zNJc6z8dkQs5KbM5K9rnzeae8n7XFdXx8oIGOnn5cBuakRXN2bjznTPVQkBVHWLDuuhQROR0KYSKTnbXQsN9Z4L9vDRx8H7pbAAMp82DKcnqzlrPVNZP3Dnbw4b46NpU20TdgCQowLMyIZVmuh7NzPSzIjCEkUKFMRGQoFMJE5Hj9fVC5yRkp2/+O06NsoNdpFpt+FuQspzP9HD7umcKHJa18tK+e7RXNDFgICXSxKCuWpTkeluZ4mJ8RrVAmInISfglhxpiHgcuBGmvtnEHO/zVwo/fXQGAWkGCtbTjV+yqEifhATzuUroMD78KB96ByM2AhMAwyl0D2ebSlns26rkw+ONDM+v0NFB1qwXpDWX5mLEty4lgyxcPCzBg1jRUR8fJXCDsfaAMeHyyEnXDtFcD3rLWf+6z3VQgTOQM6G+HgB04gO7gWanY4zwe5IXMpZJ9Da/IS1nVl8tHBNtbtrz8SyoIDXMzPiGbxlDgWT/GQnxlDpPa7FJFJym/TkcaYbOCVIYSwp4A11tpff9Z7KoSJ+EF7PZSshQPvO6Gstsh5Pijcmb7MPpe2lCV80jOFj0rbWX+gge0VzfQPWFwG8lKjOCs7jsXZcRRkx5EQGeLf7yMicoaM6RBmjAkHyoGpnzUVCQphImNCe52zndLBtVDyAVRvd54PCIa0RZB1Nl0pS9jINNaV9/LxwQY2lTbR3TcAwJR4N4uyYjkrO5aC7Dhy4t0Yo+axIjLxjPUQdh1wk7X2ilNcswpYBZCZmbmopKRklCsVkRHpaHAW95d84ISzys3OfpfGBUlzIOtsetOWsDNoNutqAiksaaTwYAONHb0AxLmDyc+MZVFWLAXZscxNi9a6MhGZEMZ6CHsR+L219qmhvKdGwkTGge42KP/YWexf+hGUF0Kvs6clsdmQsRSbsYSyiHl80BLPhtJmNpY0sr+uHYCgAMPs1GgWZcWSnxlLflYMKdHq6i8i48+YDWHGmGjgAJBhrW0fynsqhImMQ/29ULUVSj90glnZemivdc6FRjubkWcsoTlhIRt6c1hf2c2mkia2lB+dwkyJDiU/M5aFmTEszIxldmqURstEZMzz192RTwMrgHigGvgREARgrX3Qe82twCXW2uuH+r4KYSITwOHmsaXroGwdlH1ydLH/4SnMjMX0pRawN3gW6xqj2FDaxKbSJiqaOgFntCwvNZqFGTEs8B5ZnnCtLRORMUXNWkVk7OtshPINR6cxKzZAT5tzLtzj3IWZXkBj3Hw29OVQWNXHptJGtpY309nbD0BseBDzvYFsfkYM89NjiHMH+/FLichkpxAmIuPPQD/U7oKyj6H8E+exfq/3pIGEmZC+iP7URZSE5fFxWyKbytvYXNbEnppWDv/VlhEXxvx0J5DNS49mTlo07pBAv30tEZlcFMJEZGLobHRGyMo3OMGsotB5Dpzu/qkLIG0RXUkLKTJT+bgxgq0VLWwuOzqNaQxMTYhgnjeUzU2PJi9F68tExDcUwkRkYjq8tqxioxPOKgqdGwD6u53z4R5IzYe0fJpj57KVHDbUBbG1vJmt5U3UtfUAEOAyTE+KZG5aFHPTY5ibFs3M5EgFMxEZMYUwEZk8+nqcbZYqNjpH5UZnWtM6d1kSlQapC7EpC6iPns2W/mw21QWwtaKZ7RXNNLQfDWbTEiOYm+ZMYc5Ji2ZWSiThwZrKFJGhUwgTkcmtuw0ObYXKTUeP+uKj56MzIGU+NmUBdVGz2DowhY11AWyvaGF7RTP13mDmMpCTEMHs1CjmpEYzOzWKvNQoYsK1+F9EBqcQJiJyoq5mp7N/1eajjw37j56PSoOUBdiUeTREzWKHncKG+hB2VLWyo7KZquauI5emxYSRlxrlhLIUJ5ilxYSpXYaIKISJiAxJZ5MzYla15ehRtxfw/j3pToDkeZAyj9aYPIqYwobWGHYeamNHZTMH6tqP3JUZFRpIXmoUeSnONOaslCimJUUQEqh1ZiKTiUKYiMjp6m6DQ9u84cwb0GqLYKDPOR8c4TSXTZ5Ld/xs9gfmsLkrmW01PeysbGHXoRa6ep31aIEuQ25CBDO9oWxWShSzkiNJiAzRqJnIBKUQJiIymvq6oabIG86OOXpanfPGBZ5pkDyXgaQ5HAqbyvb+DLY0hlB0qI2iqpbjpjPj3MHMTI5kZnIUM5MjmZEcyfSkSMKCNWomMt4phImI+NrAADQegOrtcGi7E8qqt0Nz2dFrwj3OqFnSHNrjZrLPZLGlM4kdtT0UHWpl9zGjZsZAVlw4M5IjmeENZ9OTIsn2hBMY4PLTlxSR4VIIExHxl44GqN7hPbY7R00R9HlHwkwAeHIhaTYDCXnUhueyayCDTa1R7K5uZ/ehVg7WtzPg/as6ONDF1IQIZiRHMi0pghlJTjhLiwnD5dKUpshYoxAmIjKWDPRD/T6nn1n1Tieg1eyAxoNHrwlyQ+JMSMyjN34m5UHZ7OhNY2tTCLuq29hb3XrclGZ4cADTEiOYlhTJ9CTncVpihO7SFPEzhTARkfGguxVqd3tD2c6jjx31R68Ji4PEPEicSWfMdEoDM9jem8a2hkD21rSyp7qN2tbuI5e7gwOYmhjB1ERn5GxaYgTTEiNJiw0jQCNnIj6nECYiMl5ZC+21zhRmTZETymp2Qs2uozcCALgTnZGzhJl0RE+lxJXJ9t4UdjQFsbemlb3VbdQcE85CAl3kJkR4A9rRI9vjJjhQa85ERotCmIjIRGMttFQ4Yay2yPu4yxlJOzachcdDwkxImEFnzFTKAjLZ2ZvM9uYwiuvaKa5po7yx88jlAS5DVlw4Od6AlpvgJjcxgtz4CKLDg/zwRUXGN4UwEZHJ4nA4q911NJjV7XEeu5qPXhcSDfHTIGEGPbFTqQrKZO9AClvbYyiu66K4po0Dde309h/9NyI+IpicBG8wS4ggx/uYHhuuqU2Rk1AIExGZ7KyFtmpnpKx2N9QdftwLbYeOXhcQDHG5ED+NAc806kOzOEAqO3oS2dVgKK5tY39tG40dvUdeEhzgIssTzpR4NzkJEeTEu8lJcDMl3k2cO1g3BsikphAmIiIn19nkhLG6Pd7D+3PDfrD9R6+LSHZGzzxT6YjKoSIglb39KWxtj2J/XTf769opqT9+9CwqNJAp3mA25ZgjO95NREigH76syJmlECYiIsPX1+O0zajbA/V7j4az+mLobDx6nSsI4nLAM5WBuBwawzIpIY2i3iSKWoI5UN/Bgdp2Ko9pqQEQHxFCTryb7PhwsjzecOZxfg8PVkCTieFUIUz/l4uIyOACgyFhunOcqL3+aDCr3+v0PasvxlX8Jp7+HjxAPkBwJHhyYNpUeqOnUBuSTslAMjt7E9jdHMSBunbW7K6ltrX8uLdPjAwhO95NtscJaNkeN1mecLI84USG6gYBmRg0EiYiIqNnoN/ZqqmuGBqcYHY4oNFcBnbg6LWhMc5uAXG59ERnUx2URqlNpqgnnl3NQZTUt3OwvuO4vmcAHncwmZ5wsj1uMuPCj4SzzDg38RFagyZji6YjRUTE//q6obHEG872HfN4wLvH5jH/HoVGO1OcsVPoic6mNiiVUpLZ05NAUWsYJQ2dlNS3U9XSxbH/jLmDA8iIOxzKwsk8HNTiwkmNCVMPNDnjFMJERGRs6+t21p817HeO+n3OhugNB6Cp9PgbBALDIDYb4qbQF51FY0g6Fa4k9vUmsLMjhgNNvZQ2dFDa0EFP39GRN5eBlOgwMuPCyYg7/Og9YsM1iiY+oRAmIiLjV3+vE8QaDhwNZkceD0Jf5zEXG4hOh9hsbEwWbeHpVAekUDKQwJ7eePa0BFPa2Elpw6enOcOCAsiICyMj1glm6bFhpMc6gS0jLpworUWT06CF+SIiMn4FBDlrxzy5nz53uP9Z48GjoazxADSWYIrfIrLtEJHAVOACcDZGj82CnGz6ojJoDE6h0iRxoC+eXV2x7GsxlDV0sP5AA23dfcd9VFRo4JFQlh57NKSlx4aRFhumkCbDphAmIiLjlzEQmewcmUs/fb6nwxlF8wYzmkq8Qa2EwP3vktDbTgIw//D1YXEQm4VNzaTbnU59UAqVJHCg38OujhgOtFj21bbz7p5aunoHjvuowyEtLTbMCWYxYUeCWlpMGDHhQZrulOMohImIyMQVHO5sbJ4489PnrIWOem84O+gNayXQVIqp3klo02rS+rtJA846/JrweIjJwKZn0hmeRkNQElUkcLDPw57uGIqbDSX17XxYXEd7T/9xHxceHEBqjBPO0rwhLS0mjNSYMFJjQkmOCiUwQDcOTCYKYSIiMjkZA+5450hf9OnzAwPQXuMEs+YyZxStqRSayjDVOwlvWk14fzfpHBPSQqMhOhM7K50etxPSDpkEyvo97O2OYm9bCBXNPWyraKahvee4j3MZSI4KJeWYYJYWE0ZKtPNzarRG0yYahTAREZHBuFxHpzpZ8unz1kJ7rTeYeY/mMiekNZYQcmAtKT2tpAALD78mIBii0iAjnb7INFpCkqlzJVBh4znQG8uernAOtsCWsiZWb+88bgsocG4eSPEGspTo0CNh7XBQS44O03ZQ44j+S4mIiJwOYyAi0TnSB735zdmXs7kMmsu9hxPSaC4j8OB7xLUdIs4OMB1Yefg1YbEQlY5NT6MzLIWmoERqTDzl/bEc6I1ld0coZS197NlTS21bNyc2OYgMDSQl2glmxz4mR4cqqI0x+q8gIiLiK2ExzpE8d/Dz/b3QWuUEtKYyaCmH5gpoqcA0VxBeuo7wriZSgQVHXmTAnQAJaQzkpNIemkxjYPzRoNYdzd7OIMpaethR2UxdW8+nPjYiJJDk6FAnnEU5AS0pyvk9yft7XHgwLpemPn1JIUxERMRfAoIgJtM5sk5yTU/7kWBGS4X353JoqcTVsJ/IlrVEdjeTCRw3HhceD/GpDExJpSM0iabAeGpNPBX9MRzsi6a408XB1j72VtdR09rFwAkjasEBLhKjQkiOcoKZE85CnMdjgltoUIBv/mwmAYUwERGRsSzYffKN1A/rboWWSm9Qqzz6c3MFrpZyIso/JqKzgXSOWZ8Gzgbr/7+9e4+ts67jOP7+rJfTrpe162UbG2MjThSIA124eVvARFQiJsQwlEhQQ0JMAOMN9A9ion8YjEECaBBRiARiEIWYuECGOg13ZOJgIGOb3aDtaYFtPd3WtevXP56HUdeWi+np76zn80qenOf5neecfc++6emnz7V1CeNLlzDSsIg9dZ28Nq+DvminZ6yN7QdqeHHfOM/17uWh54vsHz006Z9e0FjH4tYGulsLeVgrHA5t3S3ZfFdLgTqf+TmJQ5iZmdnRrtACXSdk03RG978Z0IZ6/+dx3lAvja8+TGOpj8XjY5w48XWaB03dxLLFjDUtZri+i921HQzQTt94Oz2jrbx0YB7bhsXWYoni0AiHjtisJmU3Xu9uycNa/tjdUqCrJQtu3a0NdDUXqur+ng5hZmZm1aCucfo7D7xhfDw743PoFdjbm4W0oT4Y6kVDvdTt3Ulb6Qna9r3KiiNfO68WmhcTnYsZaexmuL6TPTULGWAhvYda6RltZfuBYOvQOM+9spfB0sikXaAA7fPrDoe1rpZCNt9SyENbQx7cCjTNgZMLjv5PYGZmZjNj3jxoWZRNx5w6/XpjI3k468sC21A/lLJlDfXRsGc7DaVH6Nj/Oscf+VrVQHM30bmIg41dDNd1sKe2g0Ha6RtvY9doC9sPtPDS/nEeLZYYKI1MulQHQFN9zeGQ1pUHs8NT85vzHU31FXsRXIcwMzMze3dqC9k9ONunO5sgN3ogu7dnqT/fqvZGWOtHpT4KQ30USptYODzISqbYLNbQRixZxNj8LvbVdzJUu5DX1U6RBfSOLaDnYDM7DjTxfG+BjS+OMnRgbNJbSLBwfj2dE4JZZ3M9XS0FVi9r4/TjO2boP+XdcwgzMzOz8qhreGdh7dBYthv0cGDry+5WMNSPSv3UlYoseHUTC0pFlo3um/x61UBzJ+OLuhkpdLCvvoO9Ne28RhvF8VZeHmtl52gW2J4crKdYGmVkbJxLzjxuboYwSbcB5wHFiDh5mnXWAtcDdcBgRHy8XPWYmZlZhaqphdYl2fR2Rkp5WCtmW9VKA1lgK/Uzr1SksdRP4+6tdAwXWXlo8jXSUA3R1sn4/C4Otl4ATBlRZkU5t4T9GrgRuGOqJyW1ATcD50ZEj6TuMtZiZmZmc0GhOZve6gQDyG4rdWB3FtJK/XlQywKbSkVqhgdonN80OzVPo2whLCI2SlrxFqt8Abg3Inry9YvlqsXMzMyqjJTdAqqx/a2vsZZQytMF3gu0S/qLpKckfSlhLWZmZmazKuWB+bXAh4BzgEbgEUmPRsS/j1xR0mXAZQDLly+f1SLNzMzMyiHllrBdwPqIGI6IQWAjsHqqFSPilohYExFrurq6ZrVIMzMzs3JIGcLuAz4qqVbSfOB0YEvCeszMzMxmTTkvUXEXsBbolLQLuJbsUhRExM8jYouk9cAzwDhwa0RsLlc9ZmZmZpWknGdHXvQO1rkOuK5cNZiZmZlVqsq8mZKZmZnZHOcQZmZmZpaAQ5iZmZlZAg5hZmZmZgk4hJmZmZkl4BBmZmZmloBDmJmZmVkCiojUNbwrkgaA/8zgW3YCgzP4fjZz3JvK5L5ULvemMrkvlWs2enNcREx5z8WjLoTNNElPRsSa1HXYZO5NZXJfKpd7U5ncHjATfAAABSVJREFUl8qVujfeHWlmZmaWgEOYmZmZWQIOYXBL6gJsWu5NZXJfKpd7U5ncl8qVtDdVf0yYmZmZWQreEmZmZmaWQFWHMEnnSnpB0lZJV6eup1pJOlbSnyVtkfSspCvz8YWSHpT0Yv7YnrrWaiSpRtLTkv6YL7svFUBSm6R7JD2f/+yc6d5UBklfz7/LNku6S1KDezP7JN0mqShp84Sxafsg6Zo8D7wg6ZOzUWPVhjBJNcBNwKeAE4GLJJ2YtqqqNQZ8IyLeD5wBfC3vxdXAhohYBWzIl232XQlsmbDsvlSGnwLrI+J9wGqyHrk3iUlaClwBrImIk4EaYB3uTQq/Bs49YmzKPuS/c9YBJ+WvuTnPCWVVtSEMOA3YGhHbIuIgcDdwfuKaqlJE9EbEP/L5IbJfJkvJ+nF7vtrtwOfSVFi9JC0DPgPcOmHYfUlMUivwMeCXABFxMCJ2495UilqgUVItMB94Bfdm1kXERuC1I4an68P5wN0RMRIR24GtZDmhrKo5hC0Fdk5Y3pWPWUKSVgCnAo8BiyKiF7KgBnSnq6xqXQ98GxifMOa+pHc8MAD8Kt9VfKukJtyb5CLiZeDHQA/QC+yJiAdwbyrFdH1IkgmqOYRpijGfKpqQpGbgd8BVEbE3dT3VTtJ5QDEinkpdi01SC3wQ+FlEnAoM491bFSE/xuh8YCVwDNAk6eK0Vdk7kCQTVHMI2wUcO2F5GdkmY0tAUh1ZALszIu7Nh/slLcmfXwIUU9VXpT4MfFbSDrLd9WdL+g3uSyXYBeyKiMfy5XvIQpl7k94ngO0RMRARo8C9wFm4N5Viuj4kyQTVHMKeAFZJWimpnuyAvPsT11SVJIns2JYtEfGTCU/dD1ySz18C3DfbtVWziLgmIpZFxAqyn4+HIuJi3JfkIqIP2CnphHzoHOA53JtK0AOcIWl+/t12Dtlxru5NZZiuD/cD6yQVJK0EVgGPl7uYqr5Yq6RPkx3zUgPcFhE/TFxSVZL0EeBvwL9489ij75IdF/ZbYDnZF9vnI+LIgyxtFkhaC3wzIs6T1IH7kpykU8hOmKgHtgGXkv1h7d4kJun7wIVkZ34/DXwVaMa9mVWS7gLWAp1AP3At8Aem6YOk7wFfJuvbVRHxp7LXWM0hzMzMzCyVat4daWZmZpaMQ5iZmZlZAg5hZmZmZgk4hJmZmZkl4BBmZmZmloBDmJnNKZIOSdo0YZqxK8lLWiFp80y9n5lVt9rUBZiZzbD9EXFK6iLMzN6Ot4SZWVWQtEPSjyQ9nk/vycePk7RB0jP54/J8fJGk30v6Zz6dlb9VjaRfSHpW0gOSGpN9KDM7qjmEmdlc03jE7sgLJzy3NyJOA24ku1sG+fwdEfEB4E7ghnz8BuCvEbGa7L6Mz+bjq4CbIuIkYDdwQZk/j5nNUb5ivpnNKZJKEdE8xfgO4OyI2JbfML4vIjokDQJLImI0H++NiE5JA8CyiBiZ8B4rgAcjYlW+/B2gLiJ+UP5PZmZzjbeEmVk1iWnmp1tnKiMT5g/hY2vN7P/kEGZm1eTCCY+P5PMPA+vy+S8Cf8/nNwCXA0iqkdQ6W0WaWXXwX3BmNtc0Sto0YXl9RLxxmYqCpMfI/gC9KB+7ArhN0reAAeDSfPxK4BZJXyHb4nU50Fv26s2saviYMDOrCvkxYWsiYjB1LWZm4N2RZmZmZkl4S5iZmZlZAt4SZmZmZpaAQ5iZmZlZAg5hZmZmZgk4hJmZmZkl4BBmZmZmloBDmJmZmVkC/wV0B9fRVuxRygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learningCurve(history,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple outputs using StackedRNNCells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data using Numpy arrays\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') /  255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "# #Reserve 10000 samples for Validation\n",
    "# x_val = x_train[-10000:]\n",
    "# y_val = y_train[-10000:]\n",
    "# x_train = x_train[:-10000]\n",
    "# y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784, 1), (10000, 784, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000,784,1)\n",
    "x_test = x_test.reshape(10000,784,1)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 784, 10)\n"
     ]
    }
   ],
   "source": [
    "#Multiple Outputs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#Feature Extraction\n",
    "cells = [\n",
    "    tf.keras.layers.LSTMCell(10),\n",
    "    tf.keras.layers.LSTMCell(10),\n",
    "    tf.keras.layers.LSTMCell(10),\n",
    "]\n",
    "\n",
    "#Classification Output\n",
    "inputs = tf.keras.Input((28*28, 1))\n",
    "x = tf.keras.layers.RNN(cells, return_sequences=True)(inputs)\n",
    "print(x.get_shape())\n",
    "x = tf.keras.layers.Dense(40, activation='relu')(x)\n",
    "output_1 = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "#Sequence Output\n",
    "output_2 =  tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1,activation='linear'),input_shape=(28,28,1))(x)\n",
    "                                            \n",
    "#Ouput\n",
    "model = tf.keras.Model(inputs=inputs, outputs=[output_2])#output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 784, 1)]          0         \n",
      "_________________________________________________________________\n",
      "rnn_2 (RNN)                  (None, 784, 10)           2160      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 784, 40)           440       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 784, 1)            41        \n",
      "=================================================================\n",
      "Total params: 2,641\n",
      "Trainable params: 2,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001,),\n",
    "        metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 315s 7ms/sample - loss: 6.6189 - accuracy: 0.0985 - val_loss: 6.5876 - val_accuracy: 0.0995\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 308s 6ms/sample - loss: 6.5259 - accuracy: 0.0985 - val_loss: 6.4396 - val_accuracy: 0.0995\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 331s 7ms/sample - loss: 6.2390 - accuracy: 0.0985 - val_loss: 5.9075 - val_accuracy: 0.0995\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_split=0.2, batch_size = 100 , epochs=3, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-to-One LSTM for sequence prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 5)                 140       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5 samples\n",
      "Epoch 1/1000\n",
      "5/5 - 3s - loss: 0.2058\n",
      "Epoch 2/1000\n",
      "5/5 - 0s - loss: 0.2041\n",
      "Epoch 3/1000\n",
      "5/5 - 0s - loss: 0.2023\n",
      "Epoch 4/1000\n",
      "5/5 - 0s - loss: 0.2006\n",
      "Epoch 5/1000\n",
      "5/5 - 0s - loss: 0.1988\n",
      "Epoch 6/1000\n",
      "5/5 - 0s - loss: 0.1971\n",
      "Epoch 7/1000\n",
      "5/5 - 0s - loss: 0.1954\n",
      "Epoch 8/1000\n",
      "5/5 - 0s - loss: 0.1937\n",
      "Epoch 9/1000\n",
      "5/5 - 0s - loss: 0.1919\n",
      "Epoch 10/1000\n",
      "5/5 - 0s - loss: 0.1903\n",
      "Epoch 11/1000\n",
      "5/5 - 0s - loss: 0.1886\n",
      "Epoch 12/1000\n",
      "5/5 - 0s - loss: 0.1869\n",
      "Epoch 13/1000\n",
      "5/5 - 0s - loss: 0.1852\n",
      "Epoch 14/1000\n",
      "5/5 - 0s - loss: 0.1836\n",
      "Epoch 15/1000\n",
      "5/5 - 0s - loss: 0.1819\n",
      "Epoch 16/1000\n",
      "5/5 - 0s - loss: 0.1803\n",
      "Epoch 17/1000\n",
      "5/5 - 0s - loss: 0.1787\n",
      "Epoch 18/1000\n",
      "5/5 - 0s - loss: 0.1771\n",
      "Epoch 19/1000\n",
      "5/5 - 0s - loss: 0.1755\n",
      "Epoch 20/1000\n",
      "5/5 - 0s - loss: 0.1739\n",
      "Epoch 21/1000\n",
      "5/5 - 0s - loss: 0.1723\n",
      "Epoch 22/1000\n",
      "5/5 - 0s - loss: 0.1707\n",
      "Epoch 23/1000\n",
      "5/5 - 0s - loss: 0.1691\n",
      "Epoch 24/1000\n",
      "5/5 - 0s - loss: 0.1676\n",
      "Epoch 25/1000\n",
      "5/5 - 0s - loss: 0.1660\n",
      "Epoch 26/1000\n",
      "5/5 - 0s - loss: 0.1645\n",
      "Epoch 27/1000\n",
      "5/5 - 0s - loss: 0.1630\n",
      "Epoch 28/1000\n",
      "5/5 - 0s - loss: 0.1615\n",
      "Epoch 29/1000\n",
      "5/5 - 0s - loss: 0.1600\n",
      "Epoch 30/1000\n",
      "5/5 - 0s - loss: 0.1585\n",
      "Epoch 31/1000\n",
      "5/5 - 0s - loss: 0.1570\n",
      "Epoch 32/1000\n",
      "5/5 - 0s - loss: 0.1555\n",
      "Epoch 33/1000\n",
      "5/5 - 0s - loss: 0.1541\n",
      "Epoch 34/1000\n",
      "5/5 - 0s - loss: 0.1526\n",
      "Epoch 35/1000\n",
      "5/5 - 0s - loss: 0.1512\n",
      "Epoch 36/1000\n",
      "5/5 - 0s - loss: 0.1497\n",
      "Epoch 37/1000\n",
      "5/5 - 0s - loss: 0.1483\n",
      "Epoch 38/1000\n",
      "5/5 - 0s - loss: 0.1469\n",
      "Epoch 39/1000\n",
      "5/5 - 0s - loss: 0.1455\n",
      "Epoch 40/1000\n",
      "5/5 - 0s - loss: 0.1441\n",
      "Epoch 41/1000\n",
      "5/5 - 0s - loss: 0.1427\n",
      "Epoch 42/1000\n",
      "5/5 - 0s - loss: 0.1414\n",
      "Epoch 43/1000\n",
      "5/5 - 0s - loss: 0.1400\n",
      "Epoch 44/1000\n",
      "5/5 - 0s - loss: 0.1386\n",
      "Epoch 45/1000\n",
      "5/5 - 0s - loss: 0.1373\n",
      "Epoch 46/1000\n",
      "5/5 - 0s - loss: 0.1360\n",
      "Epoch 47/1000\n",
      "5/5 - 0s - loss: 0.1346\n",
      "Epoch 48/1000\n",
      "5/5 - 0s - loss: 0.1333\n",
      "Epoch 49/1000\n",
      "5/5 - 0s - loss: 0.1320\n",
      "Epoch 50/1000\n",
      "5/5 - 0s - loss: 0.1307\n",
      "Epoch 51/1000\n",
      "5/5 - 0s - loss: 0.1294\n",
      "Epoch 52/1000\n",
      "5/5 - 0s - loss: 0.1281\n",
      "Epoch 53/1000\n",
      "5/5 - 0s - loss: 0.1269\n",
      "Epoch 54/1000\n",
      "5/5 - 0s - loss: 0.1256\n",
      "Epoch 55/1000\n",
      "5/5 - 0s - loss: 0.1244\n",
      "Epoch 56/1000\n",
      "5/5 - 0s - loss: 0.1231\n",
      "Epoch 57/1000\n",
      "5/5 - 0s - loss: 0.1219\n",
      "Epoch 58/1000\n",
      "5/5 - 0s - loss: 0.1207\n",
      "Epoch 59/1000\n",
      "5/5 - 0s - loss: 0.1194\n",
      "Epoch 60/1000\n",
      "5/5 - 0s - loss: 0.1182\n",
      "Epoch 61/1000\n",
      "5/5 - 0s - loss: 0.1170\n",
      "Epoch 62/1000\n",
      "5/5 - 0s - loss: 0.1159\n",
      "Epoch 63/1000\n",
      "5/5 - 0s - loss: 0.1147\n",
      "Epoch 64/1000\n",
      "5/5 - 0s - loss: 0.1135\n",
      "Epoch 65/1000\n",
      "5/5 - 0s - loss: 0.1124\n",
      "Epoch 66/1000\n",
      "5/5 - 0s - loss: 0.1112\n",
      "Epoch 67/1000\n",
      "5/5 - 0s - loss: 0.1101\n",
      "Epoch 68/1000\n",
      "5/5 - 0s - loss: 0.1089\n",
      "Epoch 69/1000\n",
      "5/5 - 0s - loss: 0.1078\n",
      "Epoch 70/1000\n",
      "5/5 - 0s - loss: 0.1067\n",
      "Epoch 71/1000\n",
      "5/5 - 0s - loss: 0.1056\n",
      "Epoch 72/1000\n",
      "5/5 - 0s - loss: 0.1045\n",
      "Epoch 73/1000\n",
      "5/5 - 0s - loss: 0.1034\n",
      "Epoch 74/1000\n",
      "5/5 - 0s - loss: 0.1023\n",
      "Epoch 75/1000\n",
      "5/5 - 0s - loss: 0.1012\n",
      "Epoch 76/1000\n",
      "5/5 - 0s - loss: 0.1002\n",
      "Epoch 77/1000\n",
      "5/5 - 0s - loss: 0.0991\n",
      "Epoch 78/1000\n",
      "5/5 - 0s - loss: 0.0981\n",
      "Epoch 79/1000\n",
      "5/5 - 0s - loss: 0.0971\n",
      "Epoch 80/1000\n",
      "5/5 - 0s - loss: 0.0960\n",
      "Epoch 81/1000\n",
      "5/5 - 0s - loss: 0.0950\n",
      "Epoch 82/1000\n",
      "5/5 - 0s - loss: 0.0940\n",
      "Epoch 83/1000\n",
      "5/5 - 0s - loss: 0.0930\n",
      "Epoch 84/1000\n",
      "5/5 - 0s - loss: 0.0920\n",
      "Epoch 85/1000\n",
      "5/5 - 0s - loss: 0.0911\n",
      "Epoch 86/1000\n",
      "5/5 - 0s - loss: 0.0901\n",
      "Epoch 87/1000\n",
      "5/5 - 0s - loss: 0.0891\n",
      "Epoch 88/1000\n",
      "5/5 - 0s - loss: 0.0882\n",
      "Epoch 89/1000\n",
      "5/5 - 0s - loss: 0.0872\n",
      "Epoch 90/1000\n",
      "5/5 - 0s - loss: 0.0863\n",
      "Epoch 91/1000\n",
      "5/5 - 0s - loss: 0.0854\n",
      "Epoch 92/1000\n",
      "5/5 - 0s - loss: 0.0845\n",
      "Epoch 93/1000\n",
      "5/5 - 0s - loss: 0.0836\n",
      "Epoch 94/1000\n",
      "5/5 - 0s - loss: 0.0827\n",
      "Epoch 95/1000\n",
      "5/5 - 0s - loss: 0.0818\n",
      "Epoch 96/1000\n",
      "5/5 - 0s - loss: 0.0809\n",
      "Epoch 97/1000\n",
      "5/5 - 0s - loss: 0.0801\n",
      "Epoch 98/1000\n",
      "5/5 - 0s - loss: 0.0792\n",
      "Epoch 99/1000\n",
      "5/5 - 0s - loss: 0.0784\n",
      "Epoch 100/1000\n",
      "5/5 - 0s - loss: 0.0775\n",
      "Epoch 101/1000\n",
      "5/5 - 0s - loss: 0.0767\n",
      "Epoch 102/1000\n",
      "5/5 - 0s - loss: 0.0759\n",
      "Epoch 103/1000\n",
      "5/5 - 0s - loss: 0.0751\n",
      "Epoch 104/1000\n",
      "5/5 - 0s - loss: 0.0743\n",
      "Epoch 105/1000\n",
      "5/5 - 0s - loss: 0.0735\n",
      "Epoch 106/1000\n",
      "5/5 - 0s - loss: 0.0727\n",
      "Epoch 107/1000\n",
      "5/5 - 0s - loss: 0.0719\n",
      "Epoch 108/1000\n",
      "5/5 - 0s - loss: 0.0712\n",
      "Epoch 109/1000\n",
      "5/5 - 0s - loss: 0.0704\n",
      "Epoch 110/1000\n",
      "5/5 - 0s - loss: 0.0697\n",
      "Epoch 111/1000\n",
      "5/5 - 0s - loss: 0.0689\n",
      "Epoch 112/1000\n",
      "5/5 - 0s - loss: 0.0682\n",
      "Epoch 113/1000\n",
      "5/5 - 0s - loss: 0.0675\n",
      "Epoch 114/1000\n",
      "5/5 - 0s - loss: 0.0668\n",
      "Epoch 115/1000\n",
      "5/5 - 0s - loss: 0.0661\n",
      "Epoch 116/1000\n",
      "5/5 - 0s - loss: 0.0654\n",
      "Epoch 117/1000\n",
      "5/5 - 0s - loss: 0.0647\n",
      "Epoch 118/1000\n",
      "5/5 - 0s - loss: 0.0641\n",
      "Epoch 119/1000\n",
      "5/5 - 0s - loss: 0.0634\n",
      "Epoch 120/1000\n",
      "5/5 - 0s - loss: 0.0628\n",
      "Epoch 121/1000\n",
      "5/5 - 0s - loss: 0.0621\n",
      "Epoch 122/1000\n",
      "5/5 - 0s - loss: 0.0615\n",
      "Epoch 123/1000\n",
      "5/5 - 0s - loss: 0.0609\n",
      "Epoch 124/1000\n",
      "5/5 - 0s - loss: 0.0602\n",
      "Epoch 125/1000\n",
      "5/5 - 0s - loss: 0.0596\n",
      "Epoch 126/1000\n",
      "5/5 - 0s - loss: 0.0590\n",
      "Epoch 127/1000\n",
      "5/5 - 0s - loss: 0.0585\n",
      "Epoch 128/1000\n",
      "5/5 - 0s - loss: 0.0579\n",
      "Epoch 129/1000\n",
      "5/5 - 0s - loss: 0.0573\n",
      "Epoch 130/1000\n",
      "5/5 - 0s - loss: 0.0567\n",
      "Epoch 131/1000\n",
      "5/5 - 0s - loss: 0.0562\n",
      "Epoch 132/1000\n",
      "5/5 - 0s - loss: 0.0556\n",
      "Epoch 133/1000\n",
      "5/5 - 0s - loss: 0.0551\n",
      "Epoch 134/1000\n",
      "5/5 - 0s - loss: 0.0546\n",
      "Epoch 135/1000\n",
      "5/5 - 0s - loss: 0.0541\n",
      "Epoch 136/1000\n",
      "5/5 - 0s - loss: 0.0535\n",
      "Epoch 137/1000\n",
      "5/5 - 0s - loss: 0.0530\n",
      "Epoch 138/1000\n",
      "5/5 - 0s - loss: 0.0526\n",
      "Epoch 139/1000\n",
      "5/5 - 0s - loss: 0.0521\n",
      "Epoch 140/1000\n",
      "5/5 - 0s - loss: 0.0516\n",
      "Epoch 141/1000\n",
      "5/5 - 0s - loss: 0.0511\n",
      "Epoch 142/1000\n",
      "5/5 - 0s - loss: 0.0507\n",
      "Epoch 143/1000\n",
      "5/5 - 0s - loss: 0.0502\n",
      "Epoch 144/1000\n",
      "5/5 - 0s - loss: 0.0498\n",
      "Epoch 145/1000\n",
      "5/5 - 0s - loss: 0.0493\n",
      "Epoch 146/1000\n",
      "5/5 - 0s - loss: 0.0489\n",
      "Epoch 147/1000\n",
      "5/5 - 0s - loss: 0.0485\n",
      "Epoch 148/1000\n",
      "5/5 - 0s - loss: 0.0480\n",
      "Epoch 149/1000\n",
      "5/5 - 0s - loss: 0.0476\n",
      "Epoch 150/1000\n",
      "5/5 - 0s - loss: 0.0472\n",
      "Epoch 151/1000\n",
      "5/5 - 0s - loss: 0.0468\n",
      "Epoch 152/1000\n",
      "5/5 - 0s - loss: 0.0464\n",
      "Epoch 153/1000\n",
      "5/5 - 0s - loss: 0.0461\n",
      "Epoch 154/1000\n",
      "5/5 - 0s - loss: 0.0457\n",
      "Epoch 155/1000\n",
      "5/5 - 0s - loss: 0.0453\n",
      "Epoch 156/1000\n",
      "5/5 - 0s - loss: 0.0450\n",
      "Epoch 157/1000\n",
      "5/5 - 0s - loss: 0.0446\n",
      "Epoch 158/1000\n",
      "5/5 - 0s - loss: 0.0443\n",
      "Epoch 159/1000\n",
      "5/5 - 0s - loss: 0.0439\n",
      "Epoch 160/1000\n",
      "5/5 - 0s - loss: 0.0436\n",
      "Epoch 161/1000\n",
      "5/5 - 0s - loss: 0.0433\n",
      "Epoch 162/1000\n",
      "5/5 - 0s - loss: 0.0429\n",
      "Epoch 163/1000\n",
      "5/5 - 0s - loss: 0.0426\n",
      "Epoch 164/1000\n",
      "5/5 - 0s - loss: 0.0423\n",
      "Epoch 165/1000\n",
      "5/5 - 0s - loss: 0.0420\n",
      "Epoch 166/1000\n",
      "5/5 - 0s - loss: 0.0417\n",
      "Epoch 167/1000\n",
      "5/5 - 0s - loss: 0.0414\n",
      "Epoch 168/1000\n",
      "5/5 - 0s - loss: 0.0411\n",
      "Epoch 169/1000\n",
      "5/5 - 0s - loss: 0.0409\n",
      "Epoch 170/1000\n",
      "5/5 - 0s - loss: 0.0406\n",
      "Epoch 171/1000\n",
      "5/5 - 0s - loss: 0.0403\n",
      "Epoch 172/1000\n",
      "5/5 - 0s - loss: 0.0400\n",
      "Epoch 173/1000\n",
      "5/5 - 0s - loss: 0.0398\n",
      "Epoch 174/1000\n",
      "5/5 - 0s - loss: 0.0395\n",
      "Epoch 175/1000\n",
      "5/5 - 0s - loss: 0.0393\n",
      "Epoch 176/1000\n",
      "5/5 - 0s - loss: 0.0390\n",
      "Epoch 177/1000\n",
      "5/5 - 0s - loss: 0.0388\n",
      "Epoch 178/1000\n",
      "5/5 - 0s - loss: 0.0386\n",
      "Epoch 179/1000\n",
      "5/5 - 0s - loss: 0.0383\n",
      "Epoch 180/1000\n",
      "5/5 - 0s - loss: 0.0381\n",
      "Epoch 181/1000\n",
      "5/5 - 0s - loss: 0.0379\n",
      "Epoch 182/1000\n",
      "5/5 - 0s - loss: 0.0377\n",
      "Epoch 183/1000\n",
      "5/5 - 0s - loss: 0.0374\n",
      "Epoch 184/1000\n",
      "5/5 - 0s - loss: 0.0372\n",
      "Epoch 185/1000\n",
      "5/5 - 0s - loss: 0.0370\n",
      "Epoch 186/1000\n",
      "5/5 - 0s - loss: 0.0368\n",
      "Epoch 187/1000\n",
      "5/5 - 0s - loss: 0.0366\n",
      "Epoch 188/1000\n",
      "5/5 - 0s - loss: 0.0364\n",
      "Epoch 189/1000\n",
      "5/5 - 0s - loss: 0.0362\n",
      "Epoch 190/1000\n",
      "5/5 - 0s - loss: 0.0361\n",
      "Epoch 191/1000\n",
      "5/5 - 0s - loss: 0.0359\n",
      "Epoch 192/1000\n",
      "5/5 - 0s - loss: 0.0357\n",
      "Epoch 193/1000\n",
      "5/5 - 0s - loss: 0.0355\n",
      "Epoch 194/1000\n",
      "5/5 - 0s - loss: 0.0353\n",
      "Epoch 195/1000\n",
      "5/5 - 0s - loss: 0.0352\n",
      "Epoch 196/1000\n",
      "5/5 - 0s - loss: 0.0350\n",
      "Epoch 197/1000\n",
      "5/5 - 0s - loss: 0.0348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/1000\n",
      "5/5 - 0s - loss: 0.0347\n",
      "Epoch 199/1000\n",
      "5/5 - 0s - loss: 0.0345\n",
      "Epoch 200/1000\n",
      "5/5 - 0s - loss: 0.0344\n",
      "Epoch 201/1000\n",
      "5/5 - 0s - loss: 0.0342\n",
      "Epoch 202/1000\n",
      "5/5 - 0s - loss: 0.0340\n",
      "Epoch 203/1000\n",
      "5/5 - 0s - loss: 0.0339\n",
      "Epoch 204/1000\n",
      "5/5 - 0s - loss: 0.0338\n",
      "Epoch 205/1000\n",
      "5/5 - 0s - loss: 0.0336\n",
      "Epoch 206/1000\n",
      "5/5 - 0s - loss: 0.0335\n",
      "Epoch 207/1000\n",
      "5/5 - 0s - loss: 0.0333\n",
      "Epoch 208/1000\n",
      "5/5 - 0s - loss: 0.0332\n",
      "Epoch 209/1000\n",
      "5/5 - 0s - loss: 0.0330\n",
      "Epoch 210/1000\n",
      "5/5 - 0s - loss: 0.0329\n",
      "Epoch 211/1000\n",
      "5/5 - 0s - loss: 0.0328\n",
      "Epoch 212/1000\n",
      "5/5 - 0s - loss: 0.0326\n",
      "Epoch 213/1000\n",
      "5/5 - 0s - loss: 0.0325\n",
      "Epoch 214/1000\n",
      "5/5 - 0s - loss: 0.0324\n",
      "Epoch 215/1000\n",
      "5/5 - 0s - loss: 0.0323\n",
      "Epoch 216/1000\n",
      "5/5 - 0s - loss: 0.0321\n",
      "Epoch 217/1000\n",
      "5/5 - 0s - loss: 0.0320\n",
      "Epoch 218/1000\n",
      "5/5 - 0s - loss: 0.0319\n",
      "Epoch 219/1000\n",
      "5/5 - 0s - loss: 0.0318\n",
      "Epoch 220/1000\n",
      "5/5 - 0s - loss: 0.0317\n",
      "Epoch 221/1000\n",
      "5/5 - 0s - loss: 0.0315\n",
      "Epoch 222/1000\n",
      "5/5 - 0s - loss: 0.0314\n",
      "Epoch 223/1000\n",
      "5/5 - 0s - loss: 0.0313\n",
      "Epoch 224/1000\n",
      "5/5 - 0s - loss: 0.0312\n",
      "Epoch 225/1000\n",
      "5/5 - 0s - loss: 0.0311\n",
      "Epoch 226/1000\n",
      "5/5 - 0s - loss: 0.0310\n",
      "Epoch 227/1000\n",
      "5/5 - 0s - loss: 0.0309\n",
      "Epoch 228/1000\n",
      "5/5 - 0s - loss: 0.0307\n",
      "Epoch 229/1000\n",
      "5/5 - 0s - loss: 0.0306\n",
      "Epoch 230/1000\n",
      "5/5 - 0s - loss: 0.0305\n",
      "Epoch 231/1000\n",
      "5/5 - 0s - loss: 0.0304\n",
      "Epoch 232/1000\n",
      "5/5 - 0s - loss: 0.0303\n",
      "Epoch 233/1000\n",
      "5/5 - 0s - loss: 0.0302\n",
      "Epoch 234/1000\n",
      "5/5 - 0s - loss: 0.0301\n",
      "Epoch 235/1000\n",
      "5/5 - 0s - loss: 0.0300\n",
      "Epoch 236/1000\n",
      "5/5 - 0s - loss: 0.0299\n",
      "Epoch 237/1000\n",
      "5/5 - 0s - loss: 0.0298\n",
      "Epoch 238/1000\n",
      "5/5 - 0s - loss: 0.0297\n",
      "Epoch 239/1000\n",
      "5/5 - 0s - loss: 0.0296\n",
      "Epoch 240/1000\n",
      "5/5 - 0s - loss: 0.0295\n",
      "Epoch 241/1000\n",
      "5/5 - 0s - loss: 0.0294\n",
      "Epoch 242/1000\n",
      "5/5 - 0s - loss: 0.0293\n",
      "Epoch 243/1000\n",
      "5/5 - 0s - loss: 0.0292\n",
      "Epoch 244/1000\n",
      "5/5 - 0s - loss: 0.0291\n",
      "Epoch 245/1000\n",
      "5/5 - 0s - loss: 0.0290\n",
      "Epoch 246/1000\n",
      "5/5 - 0s - loss: 0.0289\n",
      "Epoch 247/1000\n",
      "5/5 - 0s - loss: 0.0288\n",
      "Epoch 248/1000\n",
      "5/5 - 0s - loss: 0.0287\n",
      "Epoch 249/1000\n",
      "5/5 - 0s - loss: 0.0286\n",
      "Epoch 250/1000\n",
      "5/5 - 0s - loss: 0.0285\n",
      "Epoch 251/1000\n",
      "5/5 - 0s - loss: 0.0284\n",
      "Epoch 252/1000\n",
      "5/5 - 0s - loss: 0.0283\n",
      "Epoch 253/1000\n",
      "5/5 - 0s - loss: 0.0282\n",
      "Epoch 254/1000\n",
      "5/5 - 0s - loss: 0.0281\n",
      "Epoch 255/1000\n",
      "5/5 - 0s - loss: 0.0280\n",
      "Epoch 256/1000\n",
      "5/5 - 0s - loss: 0.0279\n",
      "Epoch 257/1000\n",
      "5/5 - 0s - loss: 0.0278\n",
      "Epoch 258/1000\n",
      "5/5 - 0s - loss: 0.0278\n",
      "Epoch 259/1000\n",
      "5/5 - 0s - loss: 0.0277\n",
      "Epoch 260/1000\n",
      "5/5 - 0s - loss: 0.0276\n",
      "Epoch 261/1000\n",
      "5/5 - 0s - loss: 0.0275\n",
      "Epoch 262/1000\n",
      "5/5 - 0s - loss: 0.0274\n",
      "Epoch 263/1000\n",
      "5/5 - 0s - loss: 0.0273\n",
      "Epoch 264/1000\n",
      "5/5 - 0s - loss: 0.0272\n",
      "Epoch 265/1000\n",
      "5/5 - 0s - loss: 0.0271\n",
      "Epoch 266/1000\n",
      "5/5 - 0s - loss: 0.0270\n",
      "Epoch 267/1000\n",
      "5/5 - 0s - loss: 0.0269\n",
      "Epoch 268/1000\n",
      "5/5 - 0s - loss: 0.0268\n",
      "Epoch 269/1000\n",
      "5/5 - 0s - loss: 0.0267\n",
      "Epoch 270/1000\n",
      "5/5 - 0s - loss: 0.0266\n",
      "Epoch 271/1000\n",
      "5/5 - 0s - loss: 0.0265\n",
      "Epoch 272/1000\n",
      "5/5 - 0s - loss: 0.0265\n",
      "Epoch 273/1000\n",
      "5/5 - 0s - loss: 0.0264\n",
      "Epoch 274/1000\n",
      "5/5 - 0s - loss: 0.0263\n",
      "Epoch 275/1000\n",
      "5/5 - 0s - loss: 0.0262\n",
      "Epoch 276/1000\n",
      "5/5 - 0s - loss: 0.0261\n",
      "Epoch 277/1000\n",
      "5/5 - 0s - loss: 0.0260\n",
      "Epoch 278/1000\n",
      "5/5 - 0s - loss: 0.0259\n",
      "Epoch 279/1000\n",
      "5/5 - 0s - loss: 0.0258\n",
      "Epoch 280/1000\n",
      "5/5 - 0s - loss: 0.0257\n",
      "Epoch 281/1000\n",
      "5/5 - 0s - loss: 0.0256\n",
      "Epoch 282/1000\n",
      "5/5 - 0s - loss: 0.0255\n",
      "Epoch 283/1000\n",
      "5/5 - 0s - loss: 0.0255\n",
      "Epoch 284/1000\n",
      "5/5 - 0s - loss: 0.0254\n",
      "Epoch 285/1000\n",
      "5/5 - 0s - loss: 0.0253\n",
      "Epoch 286/1000\n",
      "5/5 - 0s - loss: 0.0252\n",
      "Epoch 287/1000\n",
      "5/5 - 0s - loss: 0.0251\n",
      "Epoch 288/1000\n",
      "5/5 - 0s - loss: 0.0250\n",
      "Epoch 289/1000\n",
      "5/5 - 0s - loss: 0.0249\n",
      "Epoch 290/1000\n",
      "5/5 - 0s - loss: 0.0248\n",
      "Epoch 291/1000\n",
      "5/5 - 0s - loss: 0.0247\n",
      "Epoch 292/1000\n",
      "5/5 - 0s - loss: 0.0246\n",
      "Epoch 293/1000\n",
      "5/5 - 0s - loss: 0.0245\n",
      "Epoch 294/1000\n",
      "5/5 - 0s - loss: 0.0245\n",
      "Epoch 295/1000\n",
      "5/5 - 0s - loss: 0.0244\n",
      "Epoch 296/1000\n",
      "5/5 - 0s - loss: 0.0243\n",
      "Epoch 297/1000\n",
      "5/5 - 0s - loss: 0.0242\n",
      "Epoch 298/1000\n",
      "5/5 - 0s - loss: 0.0241\n",
      "Epoch 299/1000\n",
      "5/5 - 0s - loss: 0.0240\n",
      "Epoch 300/1000\n",
      "5/5 - 0s - loss: 0.0239\n",
      "Epoch 301/1000\n",
      "5/5 - 0s - loss: 0.0238\n",
      "Epoch 302/1000\n",
      "5/5 - 0s - loss: 0.0237\n",
      "Epoch 303/1000\n",
      "5/5 - 0s - loss: 0.0236\n",
      "Epoch 304/1000\n",
      "5/5 - 0s - loss: 0.0236\n",
      "Epoch 305/1000\n",
      "5/5 - 0s - loss: 0.0235\n",
      "Epoch 306/1000\n",
      "5/5 - 0s - loss: 0.0234\n",
      "Epoch 307/1000\n",
      "5/5 - 0s - loss: 0.0233\n",
      "Epoch 308/1000\n",
      "5/5 - 0s - loss: 0.0232\n",
      "Epoch 309/1000\n",
      "5/5 - 0s - loss: 0.0231\n",
      "Epoch 310/1000\n",
      "5/5 - 0s - loss: 0.0230\n",
      "Epoch 311/1000\n",
      "5/5 - 0s - loss: 0.0229\n",
      "Epoch 312/1000\n",
      "5/5 - 0s - loss: 0.0228\n",
      "Epoch 313/1000\n",
      "5/5 - 0s - loss: 0.0227\n",
      "Epoch 314/1000\n",
      "5/5 - 0s - loss: 0.0227\n",
      "Epoch 315/1000\n",
      "5/5 - 0s - loss: 0.0226\n",
      "Epoch 316/1000\n",
      "5/5 - 0s - loss: 0.0225\n",
      "Epoch 317/1000\n",
      "5/5 - 0s - loss: 0.0224\n",
      "Epoch 318/1000\n",
      "5/5 - 0s - loss: 0.0223\n",
      "Epoch 319/1000\n",
      "5/5 - 0s - loss: 0.0222\n",
      "Epoch 320/1000\n",
      "5/5 - 0s - loss: 0.0221\n",
      "Epoch 321/1000\n",
      "5/5 - 0s - loss: 0.0220\n",
      "Epoch 322/1000\n",
      "5/5 - 0s - loss: 0.0219\n",
      "Epoch 323/1000\n",
      "5/5 - 0s - loss: 0.0219\n",
      "Epoch 324/1000\n",
      "5/5 - 0s - loss: 0.0218\n",
      "Epoch 325/1000\n",
      "5/5 - 0s - loss: 0.0217\n",
      "Epoch 326/1000\n",
      "5/5 - 0s - loss: 0.0216\n",
      "Epoch 327/1000\n",
      "5/5 - 0s - loss: 0.0215\n",
      "Epoch 328/1000\n",
      "5/5 - 0s - loss: 0.0214\n",
      "Epoch 329/1000\n",
      "5/5 - 0s - loss: 0.0213\n",
      "Epoch 330/1000\n",
      "5/5 - 0s - loss: 0.0212\n",
      "Epoch 331/1000\n",
      "5/5 - 0s - loss: 0.0211\n",
      "Epoch 332/1000\n",
      "5/5 - 0s - loss: 0.0211\n",
      "Epoch 333/1000\n",
      "5/5 - 0s - loss: 0.0210\n",
      "Epoch 334/1000\n",
      "5/5 - 0s - loss: 0.0209\n",
      "Epoch 335/1000\n",
      "5/5 - 0s - loss: 0.0208\n",
      "Epoch 336/1000\n",
      "5/5 - 0s - loss: 0.0207\n",
      "Epoch 337/1000\n",
      "5/5 - 0s - loss: 0.0206\n",
      "Epoch 338/1000\n",
      "5/5 - 0s - loss: 0.0205\n",
      "Epoch 339/1000\n",
      "5/5 - 0s - loss: 0.0204\n",
      "Epoch 340/1000\n",
      "5/5 - 0s - loss: 0.0204\n",
      "Epoch 341/1000\n",
      "5/5 - 0s - loss: 0.0203\n",
      "Epoch 342/1000\n",
      "5/5 - 0s - loss: 0.0202\n",
      "Epoch 343/1000\n",
      "5/5 - 0s - loss: 0.0201\n",
      "Epoch 344/1000\n",
      "5/5 - 0s - loss: 0.0200\n",
      "Epoch 345/1000\n",
      "5/5 - 0s - loss: 0.0199\n",
      "Epoch 346/1000\n",
      "5/5 - 0s - loss: 0.0198\n",
      "Epoch 347/1000\n",
      "5/5 - 0s - loss: 0.0197\n",
      "Epoch 348/1000\n",
      "5/5 - 0s - loss: 0.0197\n",
      "Epoch 349/1000\n",
      "5/5 - 0s - loss: 0.0196\n",
      "Epoch 350/1000\n",
      "5/5 - 0s - loss: 0.0195\n",
      "Epoch 351/1000\n",
      "5/5 - 0s - loss: 0.0194\n",
      "Epoch 352/1000\n",
      "5/5 - 0s - loss: 0.0193\n",
      "Epoch 353/1000\n",
      "5/5 - 0s - loss: 0.0192\n",
      "Epoch 354/1000\n",
      "5/5 - 0s - loss: 0.0191\n",
      "Epoch 355/1000\n",
      "5/5 - 0s - loss: 0.0190\n",
      "Epoch 356/1000\n",
      "5/5 - 0s - loss: 0.0190\n",
      "Epoch 357/1000\n",
      "5/5 - 0s - loss: 0.0189\n",
      "Epoch 358/1000\n",
      "5/5 - 0s - loss: 0.0188\n",
      "Epoch 359/1000\n",
      "5/5 - 0s - loss: 0.0187\n",
      "Epoch 360/1000\n",
      "5/5 - 0s - loss: 0.0186\n",
      "Epoch 361/1000\n",
      "5/5 - 0s - loss: 0.0185\n",
      "Epoch 362/1000\n",
      "5/5 - 0s - loss: 0.0184\n",
      "Epoch 363/1000\n",
      "5/5 - 0s - loss: 0.0184\n",
      "Epoch 364/1000\n",
      "5/5 - 0s - loss: 0.0183\n",
      "Epoch 365/1000\n",
      "5/5 - 0s - loss: 0.0182\n",
      "Epoch 366/1000\n",
      "5/5 - 0s - loss: 0.0181\n",
      "Epoch 367/1000\n",
      "5/5 - 0s - loss: 0.0180\n",
      "Epoch 368/1000\n",
      "5/5 - 0s - loss: 0.0179\n",
      "Epoch 369/1000\n",
      "5/5 - 0s - loss: 0.0178\n",
      "Epoch 370/1000\n",
      "5/5 - 0s - loss: 0.0178\n",
      "Epoch 371/1000\n",
      "5/5 - 0s - loss: 0.0177\n",
      "Epoch 372/1000\n",
      "5/5 - 0s - loss: 0.0176\n",
      "Epoch 373/1000\n",
      "5/5 - 0s - loss: 0.0175\n",
      "Epoch 374/1000\n",
      "5/5 - 0s - loss: 0.0174\n",
      "Epoch 375/1000\n",
      "5/5 - 0s - loss: 0.0173\n",
      "Epoch 376/1000\n",
      "5/5 - 0s - loss: 0.0173\n",
      "Epoch 377/1000\n",
      "5/5 - 0s - loss: 0.0172\n",
      "Epoch 378/1000\n",
      "5/5 - 0s - loss: 0.0171\n",
      "Epoch 379/1000\n",
      "5/5 - 0s - loss: 0.0170\n",
      "Epoch 380/1000\n",
      "5/5 - 0s - loss: 0.0169\n",
      "Epoch 381/1000\n",
      "5/5 - 0s - loss: 0.0168\n",
      "Epoch 382/1000\n",
      "5/5 - 0s - loss: 0.0168\n",
      "Epoch 383/1000\n",
      "5/5 - 0s - loss: 0.0167\n",
      "Epoch 384/1000\n",
      "5/5 - 0s - loss: 0.0166\n",
      "Epoch 385/1000\n",
      "5/5 - 0s - loss: 0.0165\n",
      "Epoch 386/1000\n",
      "5/5 - 0s - loss: 0.0164\n",
      "Epoch 387/1000\n",
      "5/5 - 0s - loss: 0.0163\n",
      "Epoch 388/1000\n",
      "5/5 - 0s - loss: 0.0163\n",
      "Epoch 389/1000\n",
      "5/5 - 0s - loss: 0.0162\n",
      "Epoch 390/1000\n",
      "5/5 - 0s - loss: 0.0161\n",
      "Epoch 391/1000\n",
      "5/5 - 0s - loss: 0.0160\n",
      "Epoch 392/1000\n",
      "5/5 - 0s - loss: 0.0159\n",
      "Epoch 393/1000\n",
      "5/5 - 0s - loss: 0.0158\n",
      "Epoch 394/1000\n",
      "5/5 - 0s - loss: 0.0158\n",
      "Epoch 395/1000\n",
      "5/5 - 0s - loss: 0.0157\n",
      "Epoch 396/1000\n",
      "5/5 - 0s - loss: 0.0156\n",
      "Epoch 397/1000\n",
      "5/5 - 0s - loss: 0.0155\n",
      "Epoch 398/1000\n",
      "5/5 - 0s - loss: 0.0154\n",
      "Epoch 399/1000\n",
      "5/5 - 0s - loss: 0.0154\n",
      "Epoch 400/1000\n",
      "5/5 - 0s - loss: 0.0153\n",
      "Epoch 401/1000\n",
      "5/5 - 0s - loss: 0.0152\n",
      "Epoch 402/1000\n",
      "5/5 - 0s - loss: 0.0151\n",
      "Epoch 403/1000\n",
      "5/5 - 0s - loss: 0.0150\n",
      "Epoch 404/1000\n",
      "5/5 - 0s - loss: 0.0150\n",
      "Epoch 405/1000\n",
      "5/5 - 0s - loss: 0.0149\n",
      "Epoch 406/1000\n",
      "5/5 - 0s - loss: 0.0148\n",
      "Epoch 407/1000\n",
      "5/5 - 0s - loss: 0.0147\n",
      "Epoch 408/1000\n",
      "5/5 - 0s - loss: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409/1000\n",
      "5/5 - 0s - loss: 0.0146\n",
      "Epoch 410/1000\n",
      "5/5 - 0s - loss: 0.0145\n",
      "Epoch 411/1000\n",
      "5/5 - 0s - loss: 0.0144\n",
      "Epoch 412/1000\n",
      "5/5 - 0s - loss: 0.0143\n",
      "Epoch 413/1000\n",
      "5/5 - 0s - loss: 0.0142\n",
      "Epoch 414/1000\n",
      "5/5 - 0s - loss: 0.0142\n",
      "Epoch 415/1000\n",
      "5/5 - 0s - loss: 0.0141\n",
      "Epoch 416/1000\n",
      "5/5 - 0s - loss: 0.0140\n",
      "Epoch 417/1000\n",
      "5/5 - 0s - loss: 0.0139\n",
      "Epoch 418/1000\n",
      "5/5 - 0s - loss: 0.0139\n",
      "Epoch 419/1000\n",
      "5/5 - 0s - loss: 0.0138\n",
      "Epoch 420/1000\n",
      "5/5 - 0s - loss: 0.0137\n",
      "Epoch 421/1000\n",
      "5/5 - 0s - loss: 0.0136\n",
      "Epoch 422/1000\n",
      "5/5 - 0s - loss: 0.0135\n",
      "Epoch 423/1000\n",
      "5/5 - 0s - loss: 0.0135\n",
      "Epoch 424/1000\n",
      "5/5 - 0s - loss: 0.0134\n",
      "Epoch 425/1000\n",
      "5/5 - 0s - loss: 0.0133\n",
      "Epoch 426/1000\n",
      "5/5 - 0s - loss: 0.0132\n",
      "Epoch 427/1000\n",
      "5/5 - 0s - loss: 0.0132\n",
      "Epoch 428/1000\n",
      "5/5 - 0s - loss: 0.0131\n",
      "Epoch 429/1000\n",
      "5/5 - 0s - loss: 0.0130\n",
      "Epoch 430/1000\n",
      "5/5 - 0s - loss: 0.0129\n",
      "Epoch 431/1000\n",
      "5/5 - 0s - loss: 0.0129\n",
      "Epoch 432/1000\n",
      "5/5 - 0s - loss: 0.0128\n",
      "Epoch 433/1000\n",
      "5/5 - 0s - loss: 0.0127\n",
      "Epoch 434/1000\n",
      "5/5 - 0s - loss: 0.0126\n",
      "Epoch 435/1000\n",
      "5/5 - 0s - loss: 0.0126\n",
      "Epoch 436/1000\n",
      "5/5 - 0s - loss: 0.0125\n",
      "Epoch 437/1000\n",
      "5/5 - 0s - loss: 0.0124\n",
      "Epoch 438/1000\n",
      "5/5 - 0s - loss: 0.0123\n",
      "Epoch 439/1000\n",
      "5/5 - 0s - loss: 0.0123\n",
      "Epoch 440/1000\n",
      "5/5 - 0s - loss: 0.0122\n",
      "Epoch 441/1000\n",
      "5/5 - 0s - loss: 0.0121\n",
      "Epoch 442/1000\n",
      "5/5 - 0s - loss: 0.0120\n",
      "Epoch 443/1000\n",
      "5/5 - 0s - loss: 0.0120\n",
      "Epoch 444/1000\n",
      "5/5 - 0s - loss: 0.0119\n",
      "Epoch 445/1000\n",
      "5/5 - 0s - loss: 0.0118\n",
      "Epoch 446/1000\n",
      "5/5 - 0s - loss: 0.0118\n",
      "Epoch 447/1000\n",
      "5/5 - 0s - loss: 0.0117\n",
      "Epoch 448/1000\n",
      "5/5 - 0s - loss: 0.0116\n",
      "Epoch 449/1000\n",
      "5/5 - 0s - loss: 0.0115\n",
      "Epoch 450/1000\n",
      "5/5 - 0s - loss: 0.0115\n",
      "Epoch 451/1000\n",
      "5/5 - 0s - loss: 0.0114\n",
      "Epoch 452/1000\n",
      "5/5 - 0s - loss: 0.0113\n",
      "Epoch 453/1000\n",
      "5/5 - 0s - loss: 0.0113\n",
      "Epoch 454/1000\n",
      "5/5 - 0s - loss: 0.0112\n",
      "Epoch 455/1000\n",
      "5/5 - 0s - loss: 0.0111\n",
      "Epoch 456/1000\n",
      "5/5 - 0s - loss: 0.0110\n",
      "Epoch 457/1000\n",
      "5/5 - 0s - loss: 0.0110\n",
      "Epoch 458/1000\n",
      "5/5 - 0s - loss: 0.0109\n",
      "Epoch 459/1000\n",
      "5/5 - 0s - loss: 0.0108\n",
      "Epoch 460/1000\n",
      "5/5 - 0s - loss: 0.0108\n",
      "Epoch 461/1000\n",
      "5/5 - 0s - loss: 0.0107\n",
      "Epoch 462/1000\n",
      "5/5 - 0s - loss: 0.0106\n",
      "Epoch 463/1000\n",
      "5/5 - 0s - loss: 0.0106\n",
      "Epoch 464/1000\n",
      "5/5 - 0s - loss: 0.0105\n",
      "Epoch 465/1000\n",
      "5/5 - 0s - loss: 0.0104\n",
      "Epoch 466/1000\n",
      "5/5 - 0s - loss: 0.0104\n",
      "Epoch 467/1000\n",
      "5/5 - 0s - loss: 0.0103\n",
      "Epoch 468/1000\n",
      "5/5 - 0s - loss: 0.0102\n",
      "Epoch 469/1000\n",
      "5/5 - 0s - loss: 0.0102\n",
      "Epoch 470/1000\n",
      "5/5 - 0s - loss: 0.0101\n",
      "Epoch 471/1000\n",
      "5/5 - 0s - loss: 0.0100\n",
      "Epoch 472/1000\n",
      "5/5 - 0s - loss: 0.0100\n",
      "Epoch 473/1000\n",
      "5/5 - 0s - loss: 0.0099\n",
      "Epoch 474/1000\n",
      "5/5 - 0s - loss: 0.0098\n",
      "Epoch 475/1000\n",
      "5/5 - 0s - loss: 0.0098\n",
      "Epoch 476/1000\n",
      "5/5 - 0s - loss: 0.0097\n",
      "Epoch 477/1000\n",
      "5/5 - 0s - loss: 0.0096\n",
      "Epoch 478/1000\n",
      "5/5 - 0s - loss: 0.0096\n",
      "Epoch 479/1000\n",
      "5/5 - 0s - loss: 0.0095\n",
      "Epoch 480/1000\n",
      "5/5 - 0s - loss: 0.0094\n",
      "Epoch 481/1000\n",
      "5/5 - 0s - loss: 0.0094\n",
      "Epoch 482/1000\n",
      "5/5 - 0s - loss: 0.0093\n",
      "Epoch 483/1000\n",
      "5/5 - 0s - loss: 0.0092\n",
      "Epoch 484/1000\n",
      "5/5 - 0s - loss: 0.0092\n",
      "Epoch 485/1000\n",
      "5/5 - 0s - loss: 0.0091\n",
      "Epoch 486/1000\n",
      "5/5 - 0s - loss: 0.0091\n",
      "Epoch 487/1000\n",
      "5/5 - 0s - loss: 0.0090\n",
      "Epoch 488/1000\n",
      "5/5 - 0s - loss: 0.0089\n",
      "Epoch 489/1000\n",
      "5/5 - 0s - loss: 0.0089\n",
      "Epoch 490/1000\n",
      "5/5 - 0s - loss: 0.0088\n",
      "Epoch 491/1000\n",
      "5/5 - 0s - loss: 0.0087\n",
      "Epoch 492/1000\n",
      "5/5 - 0s - loss: 0.0087\n",
      "Epoch 493/1000\n",
      "5/5 - 0s - loss: 0.0086\n",
      "Epoch 494/1000\n",
      "5/5 - 0s - loss: 0.0086\n",
      "Epoch 495/1000\n",
      "5/5 - 0s - loss: 0.0085\n",
      "Epoch 496/1000\n",
      "5/5 - 0s - loss: 0.0084\n",
      "Epoch 497/1000\n",
      "5/5 - 0s - loss: 0.0084\n",
      "Epoch 498/1000\n",
      "5/5 - 0s - loss: 0.0083\n",
      "Epoch 499/1000\n",
      "5/5 - 0s - loss: 0.0083\n",
      "Epoch 500/1000\n",
      "5/5 - 0s - loss: 0.0082\n",
      "Epoch 501/1000\n",
      "5/5 - 0s - loss: 0.0081\n",
      "Epoch 502/1000\n",
      "5/5 - 0s - loss: 0.0081\n",
      "Epoch 503/1000\n",
      "5/5 - 0s - loss: 0.0080\n",
      "Epoch 504/1000\n",
      "5/5 - 0s - loss: 0.0080\n",
      "Epoch 505/1000\n",
      "5/5 - 0s - loss: 0.0079\n",
      "Epoch 506/1000\n",
      "5/5 - 0s - loss: 0.0078\n",
      "Epoch 507/1000\n",
      "5/5 - 0s - loss: 0.0078\n",
      "Epoch 508/1000\n",
      "5/5 - 0s - loss: 0.0077\n",
      "Epoch 509/1000\n",
      "5/5 - 0s - loss: 0.0077\n",
      "Epoch 510/1000\n",
      "5/5 - 0s - loss: 0.0076\n",
      "Epoch 511/1000\n",
      "5/5 - 0s - loss: 0.0076\n",
      "Epoch 512/1000\n",
      "5/5 - 0s - loss: 0.0075\n",
      "Epoch 513/1000\n",
      "5/5 - 0s - loss: 0.0074\n",
      "Epoch 514/1000\n",
      "5/5 - 0s - loss: 0.0074\n",
      "Epoch 515/1000\n",
      "5/5 - 0s - loss: 0.0073\n",
      "Epoch 516/1000\n",
      "5/5 - 0s - loss: 0.0073\n",
      "Epoch 517/1000\n",
      "5/5 - 0s - loss: 0.0072\n",
      "Epoch 518/1000\n",
      "5/5 - 0s - loss: 0.0072\n",
      "Epoch 519/1000\n",
      "5/5 - 0s - loss: 0.0071\n",
      "Epoch 520/1000\n",
      "5/5 - 0s - loss: 0.0071\n",
      "Epoch 521/1000\n",
      "5/5 - 0s - loss: 0.0070\n",
      "Epoch 522/1000\n",
      "5/5 - 0s - loss: 0.0070\n",
      "Epoch 523/1000\n",
      "5/5 - 0s - loss: 0.0069\n",
      "Epoch 524/1000\n",
      "5/5 - 0s - loss: 0.0068\n",
      "Epoch 525/1000\n",
      "5/5 - 0s - loss: 0.0068\n",
      "Epoch 526/1000\n",
      "5/5 - 0s - loss: 0.0067\n",
      "Epoch 527/1000\n",
      "5/5 - 0s - loss: 0.0067\n",
      "Epoch 528/1000\n",
      "5/5 - 0s - loss: 0.0066\n",
      "Epoch 529/1000\n",
      "5/5 - 0s - loss: 0.0066\n",
      "Epoch 530/1000\n",
      "5/5 - 0s - loss: 0.0065\n",
      "Epoch 531/1000\n",
      "5/5 - 0s - loss: 0.0065\n",
      "Epoch 532/1000\n",
      "5/5 - 0s - loss: 0.0064\n",
      "Epoch 533/1000\n",
      "5/5 - 0s - loss: 0.0064\n",
      "Epoch 534/1000\n",
      "5/5 - 0s - loss: 0.0063\n",
      "Epoch 535/1000\n",
      "5/5 - 0s - loss: 0.0063\n",
      "Epoch 536/1000\n",
      "5/5 - 0s - loss: 0.0062\n",
      "Epoch 537/1000\n",
      "5/5 - 0s - loss: 0.0062\n",
      "Epoch 538/1000\n",
      "5/5 - 0s - loss: 0.0061\n",
      "Epoch 539/1000\n",
      "5/5 - 0s - loss: 0.0061\n",
      "Epoch 540/1000\n",
      "5/5 - 0s - loss: 0.0060\n",
      "Epoch 541/1000\n",
      "5/5 - 0s - loss: 0.0060\n",
      "Epoch 542/1000\n",
      "5/5 - 0s - loss: 0.0059\n",
      "Epoch 543/1000\n",
      "5/5 - 0s - loss: 0.0059\n",
      "Epoch 544/1000\n",
      "5/5 - 0s - loss: 0.0058\n",
      "Epoch 545/1000\n",
      "5/5 - 0s - loss: 0.0058\n",
      "Epoch 546/1000\n",
      "5/5 - 0s - loss: 0.0057\n",
      "Epoch 547/1000\n",
      "5/5 - 0s - loss: 0.0057\n",
      "Epoch 548/1000\n",
      "5/5 - 0s - loss: 0.0056\n",
      "Epoch 549/1000\n",
      "5/5 - 0s - loss: 0.0056\n",
      "Epoch 550/1000\n",
      "5/5 - 0s - loss: 0.0055\n",
      "Epoch 551/1000\n",
      "5/5 - 0s - loss: 0.0055\n",
      "Epoch 552/1000\n",
      "5/5 - 0s - loss: 0.0055\n",
      "Epoch 553/1000\n",
      "5/5 - 0s - loss: 0.0054\n",
      "Epoch 554/1000\n",
      "5/5 - 0s - loss: 0.0054\n",
      "Epoch 555/1000\n",
      "5/5 - 0s - loss: 0.0053\n",
      "Epoch 556/1000\n",
      "5/5 - 0s - loss: 0.0053\n",
      "Epoch 557/1000\n",
      "5/5 - 0s - loss: 0.0052\n",
      "Epoch 558/1000\n",
      "5/5 - 0s - loss: 0.0052\n",
      "Epoch 559/1000\n",
      "5/5 - 0s - loss: 0.0051\n",
      "Epoch 560/1000\n",
      "5/5 - 0s - loss: 0.0051\n",
      "Epoch 561/1000\n",
      "5/5 - 0s - loss: 0.0051\n",
      "Epoch 562/1000\n",
      "5/5 - 0s - loss: 0.0050\n",
      "Epoch 563/1000\n",
      "5/5 - 0s - loss: 0.0050\n",
      "Epoch 564/1000\n",
      "5/5 - 0s - loss: 0.0049\n",
      "Epoch 565/1000\n",
      "5/5 - 0s - loss: 0.0049\n",
      "Epoch 566/1000\n",
      "5/5 - 0s - loss: 0.0048\n",
      "Epoch 567/1000\n",
      "5/5 - 0s - loss: 0.0048\n",
      "Epoch 568/1000\n",
      "5/5 - 0s - loss: 0.0048\n",
      "Epoch 569/1000\n",
      "5/5 - 0s - loss: 0.0047\n",
      "Epoch 570/1000\n",
      "5/5 - 0s - loss: 0.0047\n",
      "Epoch 571/1000\n",
      "5/5 - 0s - loss: 0.0046\n",
      "Epoch 572/1000\n",
      "5/5 - 0s - loss: 0.0046\n",
      "Epoch 573/1000\n",
      "5/5 - 0s - loss: 0.0045\n",
      "Epoch 574/1000\n",
      "5/5 - 0s - loss: 0.0045\n",
      "Epoch 575/1000\n",
      "5/5 - 0s - loss: 0.0045\n",
      "Epoch 576/1000\n",
      "5/5 - 0s - loss: 0.0044\n",
      "Epoch 577/1000\n",
      "5/5 - 0s - loss: 0.0044\n",
      "Epoch 578/1000\n",
      "5/5 - 0s - loss: 0.0044\n",
      "Epoch 579/1000\n",
      "5/5 - 0s - loss: 0.0043\n",
      "Epoch 580/1000\n",
      "5/5 - 0s - loss: 0.0043\n",
      "Epoch 581/1000\n",
      "5/5 - 0s - loss: 0.0042\n",
      "Epoch 582/1000\n",
      "5/5 - 0s - loss: 0.0042\n",
      "Epoch 583/1000\n",
      "5/5 - 0s - loss: 0.0042\n",
      "Epoch 584/1000\n",
      "5/5 - 0s - loss: 0.0041\n",
      "Epoch 585/1000\n",
      "5/5 - 0s - loss: 0.0041\n",
      "Epoch 586/1000\n",
      "5/5 - 0s - loss: 0.0040\n",
      "Epoch 587/1000\n",
      "5/5 - 0s - loss: 0.0040\n",
      "Epoch 588/1000\n",
      "5/5 - 0s - loss: 0.0040\n",
      "Epoch 589/1000\n",
      "5/5 - 0s - loss: 0.0039\n",
      "Epoch 590/1000\n",
      "5/5 - 0s - loss: 0.0039\n",
      "Epoch 591/1000\n",
      "5/5 - 0s - loss: 0.0039\n",
      "Epoch 592/1000\n",
      "5/5 - 0s - loss: 0.0038\n",
      "Epoch 593/1000\n",
      "5/5 - 0s - loss: 0.0038\n",
      "Epoch 594/1000\n",
      "5/5 - 0s - loss: 0.0038\n",
      "Epoch 595/1000\n",
      "5/5 - 0s - loss: 0.0037\n",
      "Epoch 596/1000\n",
      "5/5 - 0s - loss: 0.0037\n",
      "Epoch 597/1000\n",
      "5/5 - 0s - loss: 0.0037\n",
      "Epoch 598/1000\n",
      "5/5 - 0s - loss: 0.0036\n",
      "Epoch 599/1000\n",
      "5/5 - 0s - loss: 0.0036\n",
      "Epoch 600/1000\n",
      "5/5 - 0s - loss: 0.0035\n",
      "Epoch 601/1000\n",
      "5/5 - 0s - loss: 0.0035\n",
      "Epoch 602/1000\n",
      "5/5 - 0s - loss: 0.0035\n",
      "Epoch 603/1000\n",
      "5/5 - 0s - loss: 0.0034\n",
      "Epoch 604/1000\n",
      "5/5 - 0s - loss: 0.0034\n",
      "Epoch 605/1000\n",
      "5/5 - 0s - loss: 0.0034\n",
      "Epoch 606/1000\n",
      "5/5 - 0s - loss: 0.0034\n",
      "Epoch 607/1000\n",
      "5/5 - 0s - loss: 0.0033\n",
      "Epoch 608/1000\n",
      "5/5 - 0s - loss: 0.0033\n",
      "Epoch 609/1000\n",
      "5/5 - 0s - loss: 0.0033\n",
      "Epoch 610/1000\n",
      "5/5 - 0s - loss: 0.0032\n",
      "Epoch 611/1000\n",
      "5/5 - 0s - loss: 0.0032\n",
      "Epoch 612/1000\n",
      "5/5 - 0s - loss: 0.0032\n",
      "Epoch 613/1000\n",
      "5/5 - 0s - loss: 0.0031\n",
      "Epoch 614/1000\n",
      "5/5 - 0s - loss: 0.0031\n",
      "Epoch 615/1000\n",
      "5/5 - 0s - loss: 0.0031\n",
      "Epoch 616/1000\n",
      "5/5 - 0s - loss: 0.0030\n",
      "Epoch 617/1000\n",
      "5/5 - 0s - loss: 0.0030\n",
      "Epoch 618/1000\n",
      "5/5 - 0s - loss: 0.0030\n",
      "Epoch 619/1000\n",
      "5/5 - 0s - loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 620/1000\n",
      "5/5 - 0s - loss: 0.0029\n",
      "Epoch 621/1000\n",
      "5/5 - 0s - loss: 0.0029\n",
      "Epoch 622/1000\n",
      "5/5 - 0s - loss: 0.0029\n",
      "Epoch 623/1000\n",
      "5/5 - 0s - loss: 0.0028\n",
      "Epoch 624/1000\n",
      "5/5 - 0s - loss: 0.0028\n",
      "Epoch 625/1000\n",
      "5/5 - 0s - loss: 0.0028\n",
      "Epoch 626/1000\n",
      "5/5 - 0s - loss: 0.0028\n",
      "Epoch 627/1000\n",
      "5/5 - 0s - loss: 0.0027\n",
      "Epoch 628/1000\n",
      "5/5 - 0s - loss: 0.0027\n",
      "Epoch 629/1000\n",
      "5/5 - 0s - loss: 0.0027\n",
      "Epoch 630/1000\n",
      "5/5 - 0s - loss: 0.0026\n",
      "Epoch 631/1000\n",
      "5/5 - 0s - loss: 0.0026\n",
      "Epoch 632/1000\n",
      "5/5 - 0s - loss: 0.0026\n",
      "Epoch 633/1000\n",
      "5/5 - 0s - loss: 0.0026\n",
      "Epoch 634/1000\n",
      "5/5 - 0s - loss: 0.0025\n",
      "Epoch 635/1000\n",
      "5/5 - 0s - loss: 0.0025\n",
      "Epoch 636/1000\n",
      "5/5 - 0s - loss: 0.0025\n",
      "Epoch 637/1000\n",
      "5/5 - 0s - loss: 0.0025\n",
      "Epoch 638/1000\n",
      "5/5 - 0s - loss: 0.0024\n",
      "Epoch 639/1000\n",
      "5/5 - 0s - loss: 0.0024\n",
      "Epoch 640/1000\n",
      "5/5 - 0s - loss: 0.0024\n",
      "Epoch 641/1000\n",
      "5/5 - 0s - loss: 0.0024\n",
      "Epoch 642/1000\n",
      "5/5 - 0s - loss: 0.0023\n",
      "Epoch 643/1000\n",
      "5/5 - 0s - loss: 0.0023\n",
      "Epoch 644/1000\n",
      "5/5 - 0s - loss: 0.0023\n",
      "Epoch 645/1000\n",
      "5/5 - 0s - loss: 0.0023\n",
      "Epoch 646/1000\n",
      "5/5 - 0s - loss: 0.0022\n",
      "Epoch 647/1000\n",
      "5/5 - 0s - loss: 0.0022\n",
      "Epoch 648/1000\n",
      "5/5 - 0s - loss: 0.0022\n",
      "Epoch 649/1000\n",
      "5/5 - 0s - loss: 0.0022\n",
      "Epoch 650/1000\n",
      "5/5 - 0s - loss: 0.0021\n",
      "Epoch 651/1000\n",
      "5/5 - 0s - loss: 0.0021\n",
      "Epoch 652/1000\n",
      "5/5 - 0s - loss: 0.0021\n",
      "Epoch 653/1000\n",
      "5/5 - 0s - loss: 0.0021\n",
      "Epoch 654/1000\n",
      "5/5 - 0s - loss: 0.0021\n",
      "Epoch 655/1000\n",
      "5/5 - 0s - loss: 0.0020\n",
      "Epoch 656/1000\n",
      "5/5 - 0s - loss: 0.0020\n",
      "Epoch 657/1000\n",
      "5/5 - 0s - loss: 0.0020\n",
      "Epoch 658/1000\n",
      "5/5 - 0s - loss: 0.0020\n",
      "Epoch 659/1000\n",
      "5/5 - 0s - loss: 0.0020\n",
      "Epoch 660/1000\n",
      "5/5 - 0s - loss: 0.0019\n",
      "Epoch 661/1000\n",
      "5/5 - 0s - loss: 0.0019\n",
      "Epoch 662/1000\n",
      "5/5 - 0s - loss: 0.0019\n",
      "Epoch 663/1000\n",
      "5/5 - 0s - loss: 0.0019\n",
      "Epoch 664/1000\n",
      "5/5 - 0s - loss: 0.0019\n",
      "Epoch 665/1000\n",
      "5/5 - 0s - loss: 0.0018\n",
      "Epoch 666/1000\n",
      "5/5 - 0s - loss: 0.0018\n",
      "Epoch 667/1000\n",
      "5/5 - 0s - loss: 0.0018\n",
      "Epoch 668/1000\n",
      "5/5 - 0s - loss: 0.0018\n",
      "Epoch 669/1000\n",
      "5/5 - 0s - loss: 0.0018\n",
      "Epoch 670/1000\n",
      "5/5 - 0s - loss: 0.0017\n",
      "Epoch 671/1000\n",
      "5/5 - 0s - loss: 0.0017\n",
      "Epoch 672/1000\n",
      "5/5 - 0s - loss: 0.0017\n",
      "Epoch 673/1000\n",
      "5/5 - 0s - loss: 0.0017\n",
      "Epoch 674/1000\n",
      "5/5 - 0s - loss: 0.0017\n",
      "Epoch 675/1000\n",
      "5/5 - 0s - loss: 0.0016\n",
      "Epoch 676/1000\n",
      "5/5 - 0s - loss: 0.0016\n",
      "Epoch 677/1000\n",
      "5/5 - 0s - loss: 0.0016\n",
      "Epoch 678/1000\n",
      "5/5 - 0s - loss: 0.0016\n",
      "Epoch 679/1000\n",
      "5/5 - 0s - loss: 0.0016\n",
      "Epoch 680/1000\n",
      "5/5 - 0s - loss: 0.0016\n",
      "Epoch 681/1000\n",
      "5/5 - 0s - loss: 0.0015\n",
      "Epoch 682/1000\n",
      "5/5 - 0s - loss: 0.0015\n",
      "Epoch 683/1000\n",
      "5/5 - 0s - loss: 0.0015\n",
      "Epoch 684/1000\n",
      "5/5 - 0s - loss: 0.0015\n",
      "Epoch 685/1000\n",
      "5/5 - 0s - loss: 0.0015\n",
      "Epoch 686/1000\n",
      "5/5 - 0s - loss: 0.0015\n",
      "Epoch 687/1000\n",
      "5/5 - 0s - loss: 0.0014\n",
      "Epoch 688/1000\n",
      "5/5 - 0s - loss: 0.0014\n",
      "Epoch 689/1000\n",
      "5/5 - 0s - loss: 0.0014\n",
      "Epoch 690/1000\n",
      "5/5 - 0s - loss: 0.0014\n",
      "Epoch 691/1000\n",
      "5/5 - 0s - loss: 0.0014\n",
      "Epoch 692/1000\n",
      "5/5 - 0s - loss: 0.0014\n",
      "Epoch 693/1000\n",
      "5/5 - 0s - loss: 0.0013\n",
      "Epoch 694/1000\n",
      "5/5 - 0s - loss: 0.0013\n",
      "Epoch 695/1000\n",
      "5/5 - 0s - loss: 0.0013\n",
      "Epoch 696/1000\n",
      "5/5 - 0s - loss: 0.0013\n",
      "Epoch 697/1000\n",
      "5/5 - 0s - loss: 0.0013\n",
      "Epoch 698/1000\n",
      "5/5 - 0s - loss: 0.0013\n",
      "Epoch 699/1000\n",
      "5/5 - 0s - loss: 0.0013\n",
      "Epoch 700/1000\n",
      "5/5 - 0s - loss: 0.0012\n",
      "Epoch 701/1000\n",
      "5/5 - 0s - loss: 0.0012\n",
      "Epoch 702/1000\n",
      "5/5 - 0s - loss: 0.0012\n",
      "Epoch 703/1000\n",
      "5/5 - 0s - loss: 0.0012\n",
      "Epoch 704/1000\n",
      "5/5 - 0s - loss: 0.0012\n",
      "Epoch 705/1000\n",
      "5/5 - 0s - loss: 0.0012\n",
      "Epoch 706/1000\n",
      "5/5 - 0s - loss: 0.0012\n",
      "Epoch 707/1000\n",
      "5/5 - 0s - loss: 0.0011\n",
      "Epoch 708/1000\n",
      "5/5 - 0s - loss: 0.0011\n",
      "Epoch 709/1000\n",
      "5/5 - 0s - loss: 0.0011\n",
      "Epoch 710/1000\n",
      "5/5 - 0s - loss: 0.0011\n",
      "Epoch 711/1000\n",
      "5/5 - 0s - loss: 0.0011\n",
      "Epoch 712/1000\n",
      "5/5 - 0s - loss: 0.0011\n",
      "Epoch 713/1000\n",
      "5/5 - 0s - loss: 0.0011\n",
      "Epoch 714/1000\n",
      "5/5 - 0s - loss: 0.0011\n",
      "Epoch 715/1000\n",
      "5/5 - 0s - loss: 0.0010\n",
      "Epoch 716/1000\n",
      "5/5 - 0s - loss: 0.0010\n",
      "Epoch 717/1000\n",
      "5/5 - 0s - loss: 0.0010\n",
      "Epoch 718/1000\n",
      "5/5 - 0s - loss: 0.0010\n",
      "Epoch 719/1000\n",
      "5/5 - 0s - loss: 0.0010\n",
      "Epoch 720/1000\n",
      "5/5 - 0s - loss: 9.8972e-04\n",
      "Epoch 721/1000\n",
      "5/5 - 0s - loss: 9.7846e-04\n",
      "Epoch 722/1000\n",
      "5/5 - 0s - loss: 9.6732e-04\n",
      "Epoch 723/1000\n",
      "5/5 - 0s - loss: 9.5631e-04\n",
      "Epoch 724/1000\n",
      "5/5 - 0s - loss: 9.4541e-04\n",
      "Epoch 725/1000\n",
      "5/5 - 0s - loss: 9.3464e-04\n",
      "Epoch 726/1000\n",
      "5/5 - 0s - loss: 9.2398e-04\n",
      "Epoch 727/1000\n",
      "5/5 - 0s - loss: 9.1345e-04\n",
      "Epoch 728/1000\n",
      "5/5 - 0s - loss: 9.0303e-04\n",
      "Epoch 729/1000\n",
      "5/5 - 0s - loss: 8.9273e-04\n",
      "Epoch 730/1000\n",
      "5/5 - 0s - loss: 8.8255e-04\n",
      "Epoch 731/1000\n",
      "5/5 - 0s - loss: 8.7248e-04\n",
      "Epoch 732/1000\n",
      "5/5 - 0s - loss: 8.6252e-04\n",
      "Epoch 733/1000\n",
      "5/5 - 0s - loss: 8.5268e-04\n",
      "Epoch 734/1000\n",
      "5/5 - 0s - loss: 8.4295e-04\n",
      "Epoch 735/1000\n",
      "5/5 - 0s - loss: 8.3333e-04\n",
      "Epoch 736/1000\n",
      "5/5 - 0s - loss: 8.2382e-04\n",
      "Epoch 737/1000\n",
      "5/5 - 0s - loss: 8.1442e-04\n",
      "Epoch 738/1000\n",
      "5/5 - 0s - loss: 8.0513e-04\n",
      "Epoch 739/1000\n",
      "5/5 - 0s - loss: 7.9594e-04\n",
      "Epoch 740/1000\n",
      "5/5 - 0s - loss: 7.8687e-04\n",
      "Epoch 741/1000\n",
      "5/5 - 0s - loss: 7.7789e-04\n",
      "Epoch 742/1000\n",
      "5/5 - 0s - loss: 7.6902e-04\n",
      "Epoch 743/1000\n",
      "5/5 - 0s - loss: 7.6026e-04\n",
      "Epoch 744/1000\n",
      "5/5 - 0s - loss: 7.5159e-04\n",
      "Epoch 745/1000\n",
      "5/5 - 0s - loss: 7.4303e-04\n",
      "Epoch 746/1000\n",
      "5/5 - 0s - loss: 7.3457e-04\n",
      "Epoch 747/1000\n",
      "5/5 - 0s - loss: 7.2621e-04\n",
      "Epoch 748/1000\n",
      "5/5 - 0s - loss: 7.1794e-04\n",
      "Epoch 749/1000\n",
      "5/5 - 0s - loss: 7.0978e-04\n",
      "Epoch 750/1000\n",
      "5/5 - 0s - loss: 7.0171e-04\n",
      "Epoch 751/1000\n",
      "5/5 - 0s - loss: 6.9374e-04\n",
      "Epoch 752/1000\n",
      "5/5 - 0s - loss: 6.8586e-04\n",
      "Epoch 753/1000\n",
      "5/5 - 0s - loss: 6.7808e-04\n",
      "Epoch 754/1000\n",
      "5/5 - 0s - loss: 6.7039e-04\n",
      "Epoch 755/1000\n",
      "5/5 - 0s - loss: 6.6279e-04\n",
      "Epoch 756/1000\n",
      "5/5 - 0s - loss: 6.5528e-04\n",
      "Epoch 757/1000\n",
      "5/5 - 0s - loss: 6.4787e-04\n",
      "Epoch 758/1000\n",
      "5/5 - 0s - loss: 6.4054e-04\n",
      "Epoch 759/1000\n",
      "5/5 - 0s - loss: 6.3331e-04\n",
      "Epoch 760/1000\n",
      "5/5 - 0s - loss: 6.2616e-04\n",
      "Epoch 761/1000\n",
      "5/5 - 0s - loss: 6.1910e-04\n",
      "Epoch 762/1000\n",
      "5/5 - 0s - loss: 6.1212e-04\n",
      "Epoch 763/1000\n",
      "5/5 - 0s - loss: 6.0523e-04\n",
      "Epoch 764/1000\n",
      "5/5 - 0s - loss: 5.9843e-04\n",
      "Epoch 765/1000\n",
      "5/5 - 0s - loss: 5.9171e-04\n",
      "Epoch 766/1000\n",
      "5/5 - 0s - loss: 5.8507e-04\n",
      "Epoch 767/1000\n",
      "5/5 - 0s - loss: 5.7851e-04\n",
      "Epoch 768/1000\n",
      "5/5 - 0s - loss: 5.7204e-04\n",
      "Epoch 769/1000\n",
      "5/5 - 0s - loss: 5.6565e-04\n",
      "Epoch 770/1000\n",
      "5/5 - 0s - loss: 5.5933e-04\n",
      "Epoch 771/1000\n",
      "5/5 - 0s - loss: 5.5310e-04\n",
      "Epoch 772/1000\n",
      "5/5 - 0s - loss: 5.4694e-04\n",
      "Epoch 773/1000\n",
      "5/5 - 0s - loss: 5.4086e-04\n",
      "Epoch 774/1000\n",
      "5/5 - 0s - loss: 5.3485e-04\n",
      "Epoch 775/1000\n",
      "5/5 - 0s - loss: 5.2893e-04\n",
      "Epoch 776/1000\n",
      "5/5 - 0s - loss: 5.2307e-04\n",
      "Epoch 777/1000\n",
      "5/5 - 0s - loss: 5.1729e-04\n",
      "Epoch 778/1000\n",
      "5/5 - 0s - loss: 5.1159e-04\n",
      "Epoch 779/1000\n",
      "5/5 - 0s - loss: 5.0596e-04\n",
      "Epoch 780/1000\n",
      "5/5 - 0s - loss: 5.0040e-04\n",
      "Epoch 781/1000\n",
      "5/5 - 0s - loss: 4.9491e-04\n",
      "Epoch 782/1000\n",
      "5/5 - 0s - loss: 4.8949e-04\n",
      "Epoch 783/1000\n",
      "5/5 - 0s - loss: 4.8414e-04\n",
      "Epoch 784/1000\n",
      "5/5 - 0s - loss: 4.7886e-04\n",
      "Epoch 785/1000\n",
      "5/5 - 0s - loss: 4.7364e-04\n",
      "Epoch 786/1000\n",
      "5/5 - 0s - loss: 4.6850e-04\n",
      "Epoch 787/1000\n",
      "5/5 - 0s - loss: 4.6342e-04\n",
      "Epoch 788/1000\n",
      "5/5 - 0s - loss: 4.5841e-04\n",
      "Epoch 789/1000\n",
      "5/5 - 0s - loss: 4.5346e-04\n",
      "Epoch 790/1000\n",
      "5/5 - 0s - loss: 4.4858e-04\n",
      "Epoch 791/1000\n",
      "5/5 - 0s - loss: 4.4376e-04\n",
      "Epoch 792/1000\n",
      "5/5 - 0s - loss: 4.3900e-04\n",
      "Epoch 793/1000\n",
      "5/5 - 0s - loss: 4.3431e-04\n",
      "Epoch 794/1000\n",
      "5/5 - 0s - loss: 4.2968e-04\n",
      "Epoch 795/1000\n",
      "5/5 - 0s - loss: 4.2511e-04\n",
      "Epoch 796/1000\n",
      "5/5 - 0s - loss: 4.2060e-04\n",
      "Epoch 797/1000\n",
      "5/5 - 0s - loss: 4.1615e-04\n",
      "Epoch 798/1000\n",
      "5/5 - 0s - loss: 4.1175e-04\n",
      "Epoch 799/1000\n",
      "5/5 - 0s - loss: 4.0742e-04\n",
      "Epoch 800/1000\n",
      "5/5 - 0s - loss: 4.0315e-04\n",
      "Epoch 801/1000\n",
      "5/5 - 0s - loss: 3.9893e-04\n",
      "Epoch 802/1000\n",
      "5/5 - 0s - loss: 3.9477e-04\n",
      "Epoch 803/1000\n",
      "5/5 - 0s - loss: 3.9066e-04\n",
      "Epoch 804/1000\n",
      "5/5 - 0s - loss: 3.8661e-04\n",
      "Epoch 805/1000\n",
      "5/5 - 0s - loss: 3.8261e-04\n",
      "Epoch 806/1000\n",
      "5/5 - 0s - loss: 3.7867e-04\n",
      "Epoch 807/1000\n",
      "5/5 - 0s - loss: 3.7478e-04\n",
      "Epoch 808/1000\n",
      "5/5 - 0s - loss: 3.7094e-04\n",
      "Epoch 809/1000\n",
      "5/5 - 0s - loss: 3.6716e-04\n",
      "Epoch 810/1000\n",
      "5/5 - 0s - loss: 3.6342e-04\n",
      "Epoch 811/1000\n",
      "5/5 - 0s - loss: 3.5974e-04\n",
      "Epoch 812/1000\n",
      "5/5 - 0s - loss: 3.5611e-04\n",
      "Epoch 813/1000\n",
      "5/5 - 0s - loss: 3.5253e-04\n",
      "Epoch 814/1000\n",
      "5/5 - 0s - loss: 3.4899e-04\n",
      "Epoch 815/1000\n",
      "5/5 - 0s - loss: 3.4551e-04\n",
      "Epoch 816/1000\n",
      "5/5 - 0s - loss: 3.4207e-04\n",
      "Epoch 817/1000\n",
      "5/5 - 0s - loss: 3.3868e-04\n",
      "Epoch 818/1000\n",
      "5/5 - 0s - loss: 3.3534e-04\n",
      "Epoch 819/1000\n",
      "5/5 - 0s - loss: 3.3204e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/1000\n",
      "5/5 - 0s - loss: 3.2879e-04\n",
      "Epoch 821/1000\n",
      "5/5 - 0s - loss: 3.2559e-04\n",
      "Epoch 822/1000\n",
      "5/5 - 0s - loss: 3.2243e-04\n",
      "Epoch 823/1000\n",
      "5/5 - 0s - loss: 3.1931e-04\n",
      "Epoch 824/1000\n",
      "5/5 - 0s - loss: 3.1624e-04\n",
      "Epoch 825/1000\n",
      "5/5 - 0s - loss: 3.1320e-04\n",
      "Epoch 826/1000\n",
      "5/5 - 0s - loss: 3.1022e-04\n",
      "Epoch 827/1000\n",
      "5/5 - 0s - loss: 3.0727e-04\n",
      "Epoch 828/1000\n",
      "5/5 - 0s - loss: 3.0436e-04\n",
      "Epoch 829/1000\n",
      "5/5 - 0s - loss: 3.0150e-04\n",
      "Epoch 830/1000\n",
      "5/5 - 0s - loss: 2.9868e-04\n",
      "Epoch 831/1000\n",
      "5/5 - 0s - loss: 2.9589e-04\n",
      "Epoch 832/1000\n",
      "5/5 - 0s - loss: 2.9315e-04\n",
      "Epoch 833/1000\n",
      "5/5 - 0s - loss: 2.9044e-04\n",
      "Epoch 834/1000\n",
      "5/5 - 0s - loss: 2.8778e-04\n",
      "Epoch 835/1000\n",
      "5/5 - 0s - loss: 2.8515e-04\n",
      "Epoch 836/1000\n",
      "5/5 - 0s - loss: 2.8256e-04\n",
      "Epoch 837/1000\n",
      "5/5 - 0s - loss: 2.8000e-04\n",
      "Epoch 838/1000\n",
      "5/5 - 0s - loss: 2.7748e-04\n",
      "Epoch 839/1000\n",
      "5/5 - 0s - loss: 2.7500e-04\n",
      "Epoch 840/1000\n",
      "5/5 - 0s - loss: 2.7256e-04\n",
      "Epoch 841/1000\n",
      "5/5 - 0s - loss: 2.7015e-04\n",
      "Epoch 842/1000\n",
      "5/5 - 0s - loss: 2.6777e-04\n",
      "Epoch 843/1000\n",
      "5/5 - 0s - loss: 2.6543e-04\n",
      "Epoch 844/1000\n",
      "5/5 - 0s - loss: 2.6312e-04\n",
      "Epoch 845/1000\n",
      "5/5 - 0s - loss: 2.6084e-04\n",
      "Epoch 846/1000\n",
      "5/5 - 0s - loss: 2.5860e-04\n",
      "Epoch 847/1000\n",
      "5/5 - 0s - loss: 2.5639e-04\n",
      "Epoch 848/1000\n",
      "5/5 - 0s - loss: 2.5422e-04\n",
      "Epoch 849/1000\n",
      "5/5 - 0s - loss: 2.5207e-04\n",
      "Epoch 850/1000\n",
      "5/5 - 0s - loss: 2.4996e-04\n",
      "Epoch 851/1000\n",
      "5/5 - 0s - loss: 2.4787e-04\n",
      "Epoch 852/1000\n",
      "5/5 - 0s - loss: 2.4582e-04\n",
      "Epoch 853/1000\n",
      "5/5 - 0s - loss: 2.4380e-04\n",
      "Epoch 854/1000\n",
      "5/5 - 0s - loss: 2.4180e-04\n",
      "Epoch 855/1000\n",
      "5/5 - 0s - loss: 2.3984e-04\n",
      "Epoch 856/1000\n",
      "5/5 - 0s - loss: 2.3791e-04\n",
      "Epoch 857/1000\n",
      "5/5 - 0s - loss: 2.3600e-04\n",
      "Epoch 858/1000\n",
      "5/5 - 0s - loss: 2.3412e-04\n",
      "Epoch 859/1000\n",
      "5/5 - 0s - loss: 2.3227e-04\n",
      "Epoch 860/1000\n",
      "5/5 - 0s - loss: 2.3045e-04\n",
      "Epoch 861/1000\n",
      "5/5 - 0s - loss: 2.2865e-04\n",
      "Epoch 862/1000\n",
      "5/5 - 0s - loss: 2.2688e-04\n",
      "Epoch 863/1000\n",
      "5/5 - 0s - loss: 2.2514e-04\n",
      "Epoch 864/1000\n",
      "5/5 - 0s - loss: 2.2342e-04\n",
      "Epoch 865/1000\n",
      "5/5 - 0s - loss: 2.2173e-04\n",
      "Epoch 866/1000\n",
      "5/5 - 0s - loss: 2.2007e-04\n",
      "Epoch 867/1000\n",
      "5/5 - 0s - loss: 2.1842e-04\n",
      "Epoch 868/1000\n",
      "5/5 - 0s - loss: 2.1681e-04\n",
      "Epoch 869/1000\n",
      "5/5 - 0s - loss: 2.1522e-04\n",
      "Epoch 870/1000\n",
      "5/5 - 0s - loss: 2.1365e-04\n",
      "Epoch 871/1000\n",
      "5/5 - 0s - loss: 2.1210e-04\n",
      "Epoch 872/1000\n",
      "5/5 - 0s - loss: 2.1058e-04\n",
      "Epoch 873/1000\n",
      "5/5 - 0s - loss: 2.0908e-04\n",
      "Epoch 874/1000\n",
      "5/5 - 0s - loss: 2.0760e-04\n",
      "Epoch 875/1000\n",
      "5/5 - 0s - loss: 2.0615e-04\n",
      "Epoch 876/1000\n",
      "5/5 - 0s - loss: 2.0472e-04\n",
      "Epoch 877/1000\n",
      "5/5 - 0s - loss: 2.0331e-04\n",
      "Epoch 878/1000\n",
      "5/5 - 0s - loss: 2.0192e-04\n",
      "Epoch 879/1000\n",
      "5/5 - 0s - loss: 2.0055e-04\n",
      "Epoch 880/1000\n",
      "5/5 - 0s - loss: 1.9921e-04\n",
      "Epoch 881/1000\n",
      "5/5 - 0s - loss: 1.9788e-04\n",
      "Epoch 882/1000\n",
      "5/5 - 0s - loss: 1.9657e-04\n",
      "Epoch 883/1000\n",
      "5/5 - 0s - loss: 1.9529e-04\n",
      "Epoch 884/1000\n",
      "5/5 - 0s - loss: 1.9402e-04\n",
      "Epoch 885/1000\n",
      "5/5 - 0s - loss: 1.9277e-04\n",
      "Epoch 886/1000\n",
      "5/5 - 0s - loss: 1.9154e-04\n",
      "Epoch 887/1000\n",
      "5/5 - 0s - loss: 1.9033e-04\n",
      "Epoch 888/1000\n",
      "5/5 - 0s - loss: 1.8914e-04\n",
      "Epoch 889/1000\n",
      "5/5 - 0s - loss: 1.8797e-04\n",
      "Epoch 890/1000\n",
      "5/5 - 0s - loss: 1.8682e-04\n",
      "Epoch 891/1000\n",
      "5/5 - 0s - loss: 1.8568e-04\n",
      "Epoch 892/1000\n",
      "5/5 - 0s - loss: 1.8456e-04\n",
      "Epoch 893/1000\n",
      "5/5 - 0s - loss: 1.8346e-04\n",
      "Epoch 894/1000\n",
      "5/5 - 0s - loss: 1.8237e-04\n",
      "Epoch 895/1000\n",
      "5/5 - 0s - loss: 1.8130e-04\n",
      "Epoch 896/1000\n",
      "5/5 - 0s - loss: 1.8025e-04\n",
      "Epoch 897/1000\n",
      "5/5 - 0s - loss: 1.7922e-04\n",
      "Epoch 898/1000\n",
      "5/5 - 0s - loss: 1.7820e-04\n",
      "Epoch 899/1000\n",
      "5/5 - 0s - loss: 1.7719e-04\n",
      "Epoch 900/1000\n",
      "5/5 - 0s - loss: 1.7621e-04\n",
      "Epoch 901/1000\n",
      "5/5 - 0s - loss: 1.7523e-04\n",
      "Epoch 902/1000\n",
      "5/5 - 0s - loss: 1.7427e-04\n",
      "Epoch 903/1000\n",
      "5/5 - 0s - loss: 1.7333e-04\n",
      "Epoch 904/1000\n",
      "5/5 - 0s - loss: 1.7240e-04\n",
      "Epoch 905/1000\n",
      "5/5 - 0s - loss: 1.7149e-04\n",
      "Epoch 906/1000\n",
      "5/5 - 0s - loss: 1.7059e-04\n",
      "Epoch 907/1000\n",
      "5/5 - 0s - loss: 1.6971e-04\n",
      "Epoch 908/1000\n",
      "5/5 - 0s - loss: 1.6883e-04\n",
      "Epoch 909/1000\n",
      "5/5 - 0s - loss: 1.6798e-04\n",
      "Epoch 910/1000\n",
      "5/5 - 0s - loss: 1.6713e-04\n",
      "Epoch 911/1000\n",
      "5/5 - 0s - loss: 1.6630e-04\n",
      "Epoch 912/1000\n",
      "5/5 - 0s - loss: 1.6548e-04\n",
      "Epoch 913/1000\n",
      "5/5 - 0s - loss: 1.6468e-04\n",
      "Epoch 914/1000\n",
      "5/5 - 0s - loss: 1.6388e-04\n",
      "Epoch 915/1000\n",
      "5/5 - 0s - loss: 1.6310e-04\n",
      "Epoch 916/1000\n",
      "5/5 - 0s - loss: 1.6234e-04\n",
      "Epoch 917/1000\n",
      "5/5 - 0s - loss: 1.6158e-04\n",
      "Epoch 918/1000\n",
      "5/5 - 0s - loss: 1.6084e-04\n",
      "Epoch 919/1000\n",
      "5/5 - 0s - loss: 1.6010e-04\n",
      "Epoch 920/1000\n",
      "5/5 - 0s - loss: 1.5938e-04\n",
      "Epoch 921/1000\n",
      "5/5 - 0s - loss: 1.5867e-04\n",
      "Epoch 922/1000\n",
      "5/5 - 0s - loss: 1.5797e-04\n",
      "Epoch 923/1000\n",
      "5/5 - 0s - loss: 1.5729e-04\n",
      "Epoch 924/1000\n",
      "5/5 - 0s - loss: 1.5661e-04\n",
      "Epoch 925/1000\n",
      "5/5 - 0s - loss: 1.5594e-04\n",
      "Epoch 926/1000\n",
      "5/5 - 0s - loss: 1.5529e-04\n",
      "Epoch 927/1000\n",
      "5/5 - 0s - loss: 1.5464e-04\n",
      "Epoch 928/1000\n",
      "5/5 - 0s - loss: 1.5401e-04\n",
      "Epoch 929/1000\n",
      "5/5 - 0s - loss: 1.5338e-04\n",
      "Epoch 930/1000\n",
      "5/5 - 0s - loss: 1.5277e-04\n",
      "Epoch 931/1000\n",
      "5/5 - 0s - loss: 1.5216e-04\n",
      "Epoch 932/1000\n",
      "5/5 - 0s - loss: 1.5157e-04\n",
      "Epoch 933/1000\n",
      "5/5 - 0s - loss: 1.5098e-04\n",
      "Epoch 934/1000\n",
      "5/5 - 0s - loss: 1.5040e-04\n",
      "Epoch 935/1000\n",
      "5/5 - 0s - loss: 1.4984e-04\n",
      "Epoch 936/1000\n",
      "5/5 - 0s - loss: 1.4928e-04\n",
      "Epoch 937/1000\n",
      "5/5 - 0s - loss: 1.4873e-04\n",
      "Epoch 938/1000\n",
      "5/5 - 0s - loss: 1.4819e-04\n",
      "Epoch 939/1000\n",
      "5/5 - 0s - loss: 1.4765e-04\n",
      "Epoch 940/1000\n",
      "5/5 - 0s - loss: 1.4713e-04\n",
      "Epoch 941/1000\n",
      "5/5 - 0s - loss: 1.4661e-04\n",
      "Epoch 942/1000\n",
      "5/5 - 0s - loss: 1.4610e-04\n",
      "Epoch 943/1000\n",
      "5/5 - 0s - loss: 1.4561e-04\n",
      "Epoch 944/1000\n",
      "5/5 - 0s - loss: 1.4511e-04\n",
      "Epoch 945/1000\n",
      "5/5 - 0s - loss: 1.4463e-04\n",
      "Epoch 946/1000\n",
      "5/5 - 0s - loss: 1.4415e-04\n",
      "Epoch 947/1000\n",
      "5/5 - 0s - loss: 1.4368e-04\n",
      "Epoch 948/1000\n",
      "5/5 - 0s - loss: 1.4322e-04\n",
      "Epoch 949/1000\n",
      "5/5 - 0s - loss: 1.4277e-04\n",
      "Epoch 950/1000\n",
      "5/5 - 0s - loss: 1.4232e-04\n",
      "Epoch 951/1000\n",
      "5/5 - 0s - loss: 1.4188e-04\n",
      "Epoch 952/1000\n",
      "5/5 - 0s - loss: 1.4145e-04\n",
      "Epoch 953/1000\n",
      "5/5 - 0s - loss: 1.4102e-04\n",
      "Epoch 954/1000\n",
      "5/5 - 0s - loss: 1.4060e-04\n",
      "Epoch 955/1000\n",
      "5/5 - 0s - loss: 1.4019e-04\n",
      "Epoch 956/1000\n",
      "5/5 - 0s - loss: 1.3978e-04\n",
      "Epoch 957/1000\n",
      "5/5 - 0s - loss: 1.3938e-04\n",
      "Epoch 958/1000\n",
      "5/5 - 0s - loss: 1.3899e-04\n",
      "Epoch 959/1000\n",
      "5/5 - 0s - loss: 1.3860e-04\n",
      "Epoch 960/1000\n",
      "5/5 - 0s - loss: 1.3822e-04\n",
      "Epoch 961/1000\n",
      "5/5 - 0s - loss: 1.3784e-04\n",
      "Epoch 962/1000\n",
      "5/5 - 0s - loss: 1.3747e-04\n",
      "Epoch 963/1000\n",
      "5/5 - 0s - loss: 1.3711e-04\n",
      "Epoch 964/1000\n",
      "5/5 - 0s - loss: 1.3675e-04\n",
      "Epoch 965/1000\n",
      "5/5 - 0s - loss: 1.3640e-04\n",
      "Epoch 966/1000\n",
      "5/5 - 0s - loss: 1.3605e-04\n",
      "Epoch 967/1000\n",
      "5/5 - 0s - loss: 1.3571e-04\n",
      "Epoch 968/1000\n",
      "5/5 - 0s - loss: 1.3537e-04\n",
      "Epoch 969/1000\n",
      "5/5 - 0s - loss: 1.3504e-04\n",
      "Epoch 970/1000\n",
      "5/5 - 0s - loss: 1.3472e-04\n",
      "Epoch 971/1000\n",
      "5/5 - 0s - loss: 1.3440e-04\n",
      "Epoch 972/1000\n",
      "5/5 - 0s - loss: 1.3408e-04\n",
      "Epoch 973/1000\n",
      "5/5 - 0s - loss: 1.3377e-04\n",
      "Epoch 974/1000\n",
      "5/5 - 0s - loss: 1.3346e-04\n",
      "Epoch 975/1000\n",
      "5/5 - 0s - loss: 1.3316e-04\n",
      "Epoch 976/1000\n",
      "5/5 - 0s - loss: 1.3286e-04\n",
      "Epoch 977/1000\n",
      "5/5 - 0s - loss: 1.3257e-04\n",
      "Epoch 978/1000\n",
      "5/5 - 0s - loss: 1.3228e-04\n",
      "Epoch 979/1000\n",
      "5/5 - 0s - loss: 1.3200e-04\n",
      "Epoch 980/1000\n",
      "5/5 - 0s - loss: 1.3172e-04\n",
      "Epoch 981/1000\n",
      "5/5 - 0s - loss: 1.3145e-04\n",
      "Epoch 982/1000\n",
      "5/5 - 0s - loss: 1.3118e-04\n",
      "Epoch 983/1000\n",
      "5/5 - 0s - loss: 1.3091e-04\n",
      "Epoch 984/1000\n",
      "5/5 - 0s - loss: 1.3065e-04\n",
      "Epoch 985/1000\n",
      "5/5 - 0s - loss: 1.3039e-04\n",
      "Epoch 986/1000\n",
      "5/5 - 0s - loss: 1.3014e-04\n",
      "Epoch 987/1000\n",
      "5/5 - 0s - loss: 1.2989e-04\n",
      "Epoch 988/1000\n",
      "5/5 - 0s - loss: 1.2964e-04\n",
      "Epoch 989/1000\n",
      "5/5 - 0s - loss: 1.2940e-04\n",
      "Epoch 990/1000\n",
      "5/5 - 0s - loss: 1.2916e-04\n",
      "Epoch 991/1000\n",
      "5/5 - 0s - loss: 1.2892e-04\n",
      "Epoch 992/1000\n",
      "5/5 - 0s - loss: 1.2869e-04\n",
      "Epoch 993/1000\n",
      "5/5 - 0s - loss: 1.2846e-04\n",
      "Epoch 994/1000\n",
      "5/5 - 0s - loss: 1.2824e-04\n",
      "Epoch 995/1000\n",
      "5/5 - 0s - loss: 1.2802e-04\n",
      "Epoch 996/1000\n",
      "5/5 - 0s - loss: 1.2780e-04\n",
      "Epoch 997/1000\n",
      "5/5 - 0s - loss: 1.2758e-04\n",
      "Epoch 998/1000\n",
      "5/5 - 0s - loss: 1.2737e-04\n",
      "Epoch 999/1000\n",
      "5/5 - 0s - loss: 1.2716e-04\n",
      "Epoch 1000/1000\n",
      "5/5 - 0s - loss: 1.2696e-04\n",
      "0.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# LSTM help solve the exploding problem given weights\n",
    "# Input gate - controls memory update\n",
    "# Forget  gate - reset to zero\n",
    "#Output gate - makes info visible\n",
    "# Sigmoid - helps with the smooth curve and tanh helps with gradient distribution.\n",
    "\n",
    "from numpy import array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "#Prepare sequence\n",
    "length = 5\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "x = seq.reshape(len(seq), 1,1)\n",
    "y = seq.reshape(len(seq),1)\n",
    "\n",
    "#Define LSTM configuration\n",
    "n_neurons = length\n",
    "n_batch = length\n",
    "n_epochs = 1000\n",
    "\n",
    "#create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(1,1)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "\n",
    "#Train LSTM\n",
    "model.fit(x,y, epochs=n_epochs, batch_size=n_batch, verbose=2)\n",
    "\n",
    "#Evaluate\n",
    "result = model.predict(x, batch_size=n_batch, verbose=0)\n",
    "for value in result:\n",
    "    print('%.1f'% value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x, batch_size=n_batch, verbose=0)\n",
    "for value in result:\n",
    "    print('%.1f'% value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many-to-One LSTM fro sequence prediction(without TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 5)                 140       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 30        \n",
      "=================================================================\n",
      "Total params: 170\n",
      "Trainable params: 170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1 samples\n",
      "Epoch 1/500\n",
      "1/1 - 3s - loss: 0.3037\n",
      "Epoch 2/500\n",
      "1/1 - 0s - loss: 0.3007\n",
      "Epoch 3/500\n",
      "1/1 - 0s - loss: 0.2978\n",
      "Epoch 4/500\n",
      "1/1 - 0s - loss: 0.2949\n",
      "Epoch 5/500\n",
      "1/1 - 0s - loss: 0.2920\n",
      "Epoch 6/500\n",
      "1/1 - 0s - loss: 0.2891\n",
      "Epoch 7/500\n",
      "1/1 - 0s - loss: 0.2863\n",
      "Epoch 8/500\n",
      "1/1 - 0s - loss: 0.2836\n",
      "Epoch 9/500\n",
      "1/1 - 0s - loss: 0.2808\n",
      "Epoch 10/500\n",
      "1/1 - 0s - loss: 0.2781\n",
      "Epoch 11/500\n",
      "1/1 - 0s - loss: 0.2755\n",
      "Epoch 12/500\n",
      "1/1 - 0s - loss: 0.2729\n",
      "Epoch 13/500\n",
      "1/1 - 0s - loss: 0.2703\n",
      "Epoch 14/500\n",
      "1/1 - 0s - loss: 0.2677\n",
      "Epoch 15/500\n",
      "1/1 - 0s - loss: 0.2652\n",
      "Epoch 16/500\n",
      "1/1 - 0s - loss: 0.2628\n",
      "Epoch 17/500\n",
      "1/1 - 0s - loss: 0.2603\n",
      "Epoch 18/500\n",
      "1/1 - 0s - loss: 0.2579\n",
      "Epoch 19/500\n",
      "1/1 - 0s - loss: 0.2556\n",
      "Epoch 20/500\n",
      "1/1 - 0s - loss: 0.2532\n",
      "Epoch 21/500\n",
      "1/1 - 0s - loss: 0.2509\n",
      "Epoch 22/500\n",
      "1/1 - 0s - loss: 0.2487\n",
      "Epoch 23/500\n",
      "1/1 - 0s - loss: 0.2464\n",
      "Epoch 24/500\n",
      "1/1 - 0s - loss: 0.2442\n",
      "Epoch 25/500\n",
      "1/1 - 0s - loss: 0.2421\n",
      "Epoch 26/500\n",
      "1/1 - 0s - loss: 0.2399\n",
      "Epoch 27/500\n",
      "1/1 - 0s - loss: 0.2378\n",
      "Epoch 28/500\n",
      "1/1 - 0s - loss: 0.2357\n",
      "Epoch 29/500\n",
      "1/1 - 0s - loss: 0.2337\n",
      "Epoch 30/500\n",
      "1/1 - 0s - loss: 0.2317\n",
      "Epoch 31/500\n",
      "1/1 - 0s - loss: 0.2297\n",
      "Epoch 32/500\n",
      "1/1 - 0s - loss: 0.2277\n",
      "Epoch 33/500\n",
      "1/1 - 0s - loss: 0.2258\n",
      "Epoch 34/500\n",
      "1/1 - 0s - loss: 0.2239\n",
      "Epoch 35/500\n",
      "1/1 - 0s - loss: 0.2220\n",
      "Epoch 36/500\n",
      "1/1 - 0s - loss: 0.2201\n",
      "Epoch 37/500\n",
      "1/1 - 0s - loss: 0.2183\n",
      "Epoch 38/500\n",
      "1/1 - 0s - loss: 0.2165\n",
      "Epoch 39/500\n",
      "1/1 - 0s - loss: 0.2147\n",
      "Epoch 40/500\n",
      "1/1 - 0s - loss: 0.2129\n",
      "Epoch 41/500\n",
      "1/1 - 0s - loss: 0.2111\n",
      "Epoch 42/500\n",
      "1/1 - 0s - loss: 0.2094\n",
      "Epoch 43/500\n",
      "1/1 - 0s - loss: 0.2077\n",
      "Epoch 44/500\n",
      "1/1 - 0s - loss: 0.2060\n",
      "Epoch 45/500\n",
      "1/1 - 0s - loss: 0.2043\n",
      "Epoch 46/500\n",
      "1/1 - 0s - loss: 0.2027\n",
      "Epoch 47/500\n",
      "1/1 - 0s - loss: 0.2011\n",
      "Epoch 48/500\n",
      "1/1 - 0s - loss: 0.1994\n",
      "Epoch 49/500\n",
      "1/1 - 0s - loss: 0.1978\n",
      "Epoch 50/500\n",
      "1/1 - 0s - loss: 0.1963\n",
      "Epoch 51/500\n",
      "1/1 - 0s - loss: 0.1947\n",
      "Epoch 52/500\n",
      "1/1 - 0s - loss: 0.1931\n",
      "Epoch 53/500\n",
      "1/1 - 0s - loss: 0.1916\n",
      "Epoch 54/500\n",
      "1/1 - 0s - loss: 0.1901\n",
      "Epoch 55/500\n",
      "1/1 - 0s - loss: 0.1886\n",
      "Epoch 56/500\n",
      "1/1 - 0s - loss: 0.1871\n",
      "Epoch 57/500\n",
      "1/1 - 0s - loss: 0.1856\n",
      "Epoch 58/500\n",
      "1/1 - 0s - loss: 0.1841\n",
      "Epoch 59/500\n",
      "1/1 - 0s - loss: 0.1827\n",
      "Epoch 60/500\n",
      "1/1 - 0s - loss: 0.1812\n",
      "Epoch 61/500\n",
      "1/1 - 0s - loss: 0.1798\n",
      "Epoch 62/500\n",
      "1/1 - 0s - loss: 0.1784\n",
      "Epoch 63/500\n",
      "1/1 - 0s - loss: 0.1770\n",
      "Epoch 64/500\n",
      "1/1 - 0s - loss: 0.1756\n",
      "Epoch 65/500\n",
      "1/1 - 0s - loss: 0.1742\n",
      "Epoch 66/500\n",
      "1/1 - 0s - loss: 0.1728\n",
      "Epoch 67/500\n",
      "1/1 - 0s - loss: 0.1714\n",
      "Epoch 68/500\n",
      "1/1 - 0s - loss: 0.1701\n",
      "Epoch 69/500\n",
      "1/1 - 0s - loss: 0.1687\n",
      "Epoch 70/500\n",
      "1/1 - 0s - loss: 0.1674\n",
      "Epoch 71/500\n",
      "1/1 - 0s - loss: 0.1660\n",
      "Epoch 72/500\n",
      "1/1 - 0s - loss: 0.1647\n",
      "Epoch 73/500\n",
      "1/1 - 0s - loss: 0.1634\n",
      "Epoch 74/500\n",
      "1/1 - 0s - loss: 0.1621\n",
      "Epoch 75/500\n",
      "1/1 - 0s - loss: 0.1608\n",
      "Epoch 76/500\n",
      "1/1 - 0s - loss: 0.1595\n",
      "Epoch 77/500\n",
      "1/1 - 0s - loss: 0.1582\n",
      "Epoch 78/500\n",
      "1/1 - 0s - loss: 0.1569\n",
      "Epoch 79/500\n",
      "1/1 - 0s - loss: 0.1556\n",
      "Epoch 80/500\n",
      "1/1 - 0s - loss: 0.1543\n",
      "Epoch 81/500\n",
      "1/1 - 0s - loss: 0.1531\n",
      "Epoch 82/500\n",
      "1/1 - 0s - loss: 0.1518\n",
      "Epoch 83/500\n",
      "1/1 - 0s - loss: 0.1506\n",
      "Epoch 84/500\n",
      "1/1 - 0s - loss: 0.1493\n",
      "Epoch 85/500\n",
      "1/1 - 0s - loss: 0.1481\n",
      "Epoch 86/500\n",
      "1/1 - 0s - loss: 0.1468\n",
      "Epoch 87/500\n",
      "1/1 - 0s - loss: 0.1456\n",
      "Epoch 88/500\n",
      "1/1 - 0s - loss: 0.1444\n",
      "Epoch 89/500\n",
      "1/1 - 0s - loss: 0.1431\n",
      "Epoch 90/500\n",
      "1/1 - 0s - loss: 0.1419\n",
      "Epoch 91/500\n",
      "1/1 - 0s - loss: 0.1407\n",
      "Epoch 92/500\n",
      "1/1 - 0s - loss: 0.1395\n",
      "Epoch 93/500\n",
      "1/1 - 0s - loss: 0.1383\n",
      "Epoch 94/500\n",
      "1/1 - 0s - loss: 0.1371\n",
      "Epoch 95/500\n",
      "1/1 - 0s - loss: 0.1359\n",
      "Epoch 96/500\n",
      "1/1 - 0s - loss: 0.1347\n",
      "Epoch 97/500\n",
      "1/1 - 0s - loss: 0.1335\n",
      "Epoch 98/500\n",
      "1/1 - 0s - loss: 0.1323\n",
      "Epoch 99/500\n",
      "1/1 - 0s - loss: 0.1311\n",
      "Epoch 100/500\n",
      "1/1 - 0s - loss: 0.1299\n",
      "Epoch 101/500\n",
      "1/1 - 0s - loss: 0.1288\n",
      "Epoch 102/500\n",
      "1/1 - 0s - loss: 0.1276\n",
      "Epoch 103/500\n",
      "1/1 - 0s - loss: 0.1264\n",
      "Epoch 104/500\n",
      "1/1 - 0s - loss: 0.1252\n",
      "Epoch 105/500\n",
      "1/1 - 0s - loss: 0.1241\n",
      "Epoch 106/500\n",
      "1/1 - 0s - loss: 0.1229\n",
      "Epoch 107/500\n",
      "1/1 - 0s - loss: 0.1217\n",
      "Epoch 108/500\n",
      "1/1 - 0s - loss: 0.1206\n",
      "Epoch 109/500\n",
      "1/1 - 0s - loss: 0.1194\n",
      "Epoch 110/500\n",
      "1/1 - 0s - loss: 0.1183\n",
      "Epoch 111/500\n",
      "1/1 - 0s - loss: 0.1171\n",
      "Epoch 112/500\n",
      "1/1 - 0s - loss: 0.1160\n",
      "Epoch 113/500\n",
      "1/1 - 0s - loss: 0.1148\n",
      "Epoch 114/500\n",
      "1/1 - 0s - loss: 0.1137\n",
      "Epoch 115/500\n",
      "1/1 - 0s - loss: 0.1125\n",
      "Epoch 116/500\n",
      "1/1 - 0s - loss: 0.1114\n",
      "Epoch 117/500\n",
      "1/1 - 0s - loss: 0.1102\n",
      "Epoch 118/500\n",
      "1/1 - 0s - loss: 0.1091\n",
      "Epoch 119/500\n",
      "1/1 - 0s - loss: 0.1080\n",
      "Epoch 120/500\n",
      "1/1 - 0s - loss: 0.1068\n",
      "Epoch 121/500\n",
      "1/1 - 0s - loss: 0.1057\n",
      "Epoch 122/500\n",
      "1/1 - 0s - loss: 0.1046\n",
      "Epoch 123/500\n",
      "1/1 - 0s - loss: 0.1034\n",
      "Epoch 124/500\n",
      "1/1 - 0s - loss: 0.1023\n",
      "Epoch 125/500\n",
      "1/1 - 0s - loss: 0.1012\n",
      "Epoch 126/500\n",
      "1/1 - 0s - loss: 0.1001\n",
      "Epoch 127/500\n",
      "1/1 - 0s - loss: 0.0989\n",
      "Epoch 128/500\n",
      "1/1 - 0s - loss: 0.0978\n",
      "Epoch 129/500\n",
      "1/1 - 0s - loss: 0.0967\n",
      "Epoch 130/500\n",
      "1/1 - 0s - loss: 0.0956\n",
      "Epoch 131/500\n",
      "1/1 - 0s - loss: 0.0945\n",
      "Epoch 132/500\n",
      "1/1 - 0s - loss: 0.0934\n",
      "Epoch 133/500\n",
      "1/1 - 0s - loss: 0.0923\n",
      "Epoch 134/500\n",
      "1/1 - 0s - loss: 0.0911\n",
      "Epoch 135/500\n",
      "1/1 - 0s - loss: 0.0900\n",
      "Epoch 136/500\n",
      "1/1 - 0s - loss: 0.0889\n",
      "Epoch 137/500\n",
      "1/1 - 0s - loss: 0.0878\n",
      "Epoch 138/500\n",
      "1/1 - 0s - loss: 0.0867\n",
      "Epoch 139/500\n",
      "1/1 - 0s - loss: 0.0856\n",
      "Epoch 140/500\n",
      "1/1 - 0s - loss: 0.0845\n",
      "Epoch 141/500\n",
      "1/1 - 0s - loss: 0.0834\n",
      "Epoch 142/500\n",
      "1/1 - 0s - loss: 0.0823\n",
      "Epoch 143/500\n",
      "1/1 - 0s - loss: 0.0812\n",
      "Epoch 144/500\n",
      "1/1 - 0s - loss: 0.0802\n",
      "Epoch 145/500\n",
      "1/1 - 0s - loss: 0.0791\n",
      "Epoch 146/500\n",
      "1/1 - 0s - loss: 0.0780\n",
      "Epoch 147/500\n",
      "1/1 - 0s - loss: 0.0769\n",
      "Epoch 148/500\n",
      "1/1 - 0s - loss: 0.0758\n",
      "Epoch 149/500\n",
      "1/1 - 0s - loss: 0.0747\n",
      "Epoch 150/500\n",
      "1/1 - 0s - loss: 0.0737\n",
      "Epoch 151/500\n",
      "1/1 - 0s - loss: 0.0726\n",
      "Epoch 152/500\n",
      "1/1 - 0s - loss: 0.0715\n",
      "Epoch 153/500\n",
      "1/1 - 0s - loss: 0.0704\n",
      "Epoch 154/500\n",
      "1/1 - 0s - loss: 0.0694\n",
      "Epoch 155/500\n",
      "1/1 - 0s - loss: 0.0683\n",
      "Epoch 156/500\n",
      "1/1 - 0s - loss: 0.0672\n",
      "Epoch 157/500\n",
      "1/1 - 0s - loss: 0.0662\n",
      "Epoch 158/500\n",
      "1/1 - 0s - loss: 0.0651\n",
      "Epoch 159/500\n",
      "1/1 - 0s - loss: 0.0641\n",
      "Epoch 160/500\n",
      "1/1 - 0s - loss: 0.0630\n",
      "Epoch 161/500\n",
      "1/1 - 0s - loss: 0.0620\n",
      "Epoch 162/500\n",
      "1/1 - 0s - loss: 0.0609\n",
      "Epoch 163/500\n",
      "1/1 - 0s - loss: 0.0599\n",
      "Epoch 164/500\n",
      "1/1 - 0s - loss: 0.0588\n",
      "Epoch 165/500\n",
      "1/1 - 0s - loss: 0.0578\n",
      "Epoch 166/500\n",
      "1/1 - 0s - loss: 0.0568\n",
      "Epoch 167/500\n",
      "1/1 - 0s - loss: 0.0557\n",
      "Epoch 168/500\n",
      "1/1 - 0s - loss: 0.0547\n",
      "Epoch 169/500\n",
      "1/1 - 0s - loss: 0.0537\n",
      "Epoch 170/500\n",
      "1/1 - 0s - loss: 0.0527\n",
      "Epoch 171/500\n",
      "1/1 - 0s - loss: 0.0517\n",
      "Epoch 172/500\n",
      "1/1 - 0s - loss: 0.0507\n",
      "Epoch 173/500\n",
      "1/1 - 0s - loss: 0.0497\n",
      "Epoch 174/500\n",
      "1/1 - 0s - loss: 0.0487\n",
      "Epoch 175/500\n",
      "1/1 - 0s - loss: 0.0477\n",
      "Epoch 176/500\n",
      "1/1 - 0s - loss: 0.0467\n",
      "Epoch 177/500\n",
      "1/1 - 0s - loss: 0.0457\n",
      "Epoch 178/500\n",
      "1/1 - 0s - loss: 0.0448\n",
      "Epoch 179/500\n",
      "1/1 - 0s - loss: 0.0438\n",
      "Epoch 180/500\n",
      "1/1 - 0s - loss: 0.0429\n",
      "Epoch 181/500\n",
      "1/1 - 0s - loss: 0.0419\n",
      "Epoch 182/500\n",
      "1/1 - 0s - loss: 0.0410\n",
      "Epoch 183/500\n",
      "1/1 - 0s - loss: 0.0400\n",
      "Epoch 184/500\n",
      "1/1 - 0s - loss: 0.0391\n",
      "Epoch 185/500\n",
      "1/1 - 0s - loss: 0.0382\n",
      "Epoch 186/500\n",
      "1/1 - 0s - loss: 0.0372\n",
      "Epoch 187/500\n",
      "1/1 - 0s - loss: 0.0363\n",
      "Epoch 188/500\n",
      "1/1 - 0s - loss: 0.0354\n",
      "Epoch 189/500\n",
      "1/1 - 0s - loss: 0.0346\n",
      "Epoch 190/500\n",
      "1/1 - 0s - loss: 0.0337\n",
      "Epoch 191/500\n",
      "1/1 - 0s - loss: 0.0328\n",
      "Epoch 192/500\n",
      "1/1 - 0s - loss: 0.0319\n",
      "Epoch 193/500\n",
      "1/1 - 0s - loss: 0.0311\n",
      "Epoch 194/500\n",
      "1/1 - 0s - loss: 0.0302\n",
      "Epoch 195/500\n",
      "1/1 - 0s - loss: 0.0294\n",
      "Epoch 196/500\n",
      "1/1 - 0s - loss: 0.0286\n",
      "Epoch 197/500\n",
      "1/1 - 0s - loss: 0.0278\n",
      "Epoch 198/500\n",
      "1/1 - 0s - loss: 0.0270\n",
      "Epoch 199/500\n",
      "1/1 - 0s - loss: 0.0262\n",
      "Epoch 200/500\n",
      "1/1 - 0s - loss: 0.0254\n",
      "Epoch 201/500\n",
      "1/1 - 0s - loss: 0.0246\n",
      "Epoch 202/500\n",
      "1/1 - 0s - loss: 0.0238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/500\n",
      "1/1 - 0s - loss: 0.0231\n",
      "Epoch 204/500\n",
      "1/1 - 0s - loss: 0.0224\n",
      "Epoch 205/500\n",
      "1/1 - 0s - loss: 0.0216\n",
      "Epoch 206/500\n",
      "1/1 - 0s - loss: 0.0209\n",
      "Epoch 207/500\n",
      "1/1 - 0s - loss: 0.0202\n",
      "Epoch 208/500\n",
      "1/1 - 0s - loss: 0.0195\n",
      "Epoch 209/500\n",
      "1/1 - 0s - loss: 0.0189\n",
      "Epoch 210/500\n",
      "1/1 - 0s - loss: 0.0182\n",
      "Epoch 211/500\n",
      "1/1 - 0s - loss: 0.0176\n",
      "Epoch 212/500\n",
      "1/1 - 0s - loss: 0.0169\n",
      "Epoch 213/500\n",
      "1/1 - 0s - loss: 0.0163\n",
      "Epoch 214/500\n",
      "1/1 - 0s - loss: 0.0157\n",
      "Epoch 215/500\n",
      "1/1 - 0s - loss: 0.0151\n",
      "Epoch 216/500\n",
      "1/1 - 0s - loss: 0.0145\n",
      "Epoch 217/500\n",
      "1/1 - 0s - loss: 0.0140\n",
      "Epoch 218/500\n",
      "1/1 - 0s - loss: 0.0134\n",
      "Epoch 219/500\n",
      "1/1 - 0s - loss: 0.0129\n",
      "Epoch 220/500\n",
      "1/1 - 0s - loss: 0.0123\n",
      "Epoch 221/500\n",
      "1/1 - 0s - loss: 0.0118\n",
      "Epoch 222/500\n",
      "1/1 - 0s - loss: 0.0113\n",
      "Epoch 223/500\n",
      "1/1 - 0s - loss: 0.0109\n",
      "Epoch 224/500\n",
      "1/1 - 0s - loss: 0.0104\n",
      "Epoch 225/500\n",
      "1/1 - 0s - loss: 0.0099\n",
      "Epoch 226/500\n",
      "1/1 - 0s - loss: 0.0095\n",
      "Epoch 227/500\n",
      "1/1 - 0s - loss: 0.0091\n",
      "Epoch 228/500\n",
      "1/1 - 0s - loss: 0.0086\n",
      "Epoch 229/500\n",
      "1/1 - 0s - loss: 0.0082\n",
      "Epoch 230/500\n",
      "1/1 - 0s - loss: 0.0078\n",
      "Epoch 231/500\n",
      "1/1 - 0s - loss: 0.0075\n",
      "Epoch 232/500\n",
      "1/1 - 0s - loss: 0.0071\n",
      "Epoch 233/500\n",
      "1/1 - 0s - loss: 0.0068\n",
      "Epoch 234/500\n",
      "1/1 - 0s - loss: 0.0064\n",
      "Epoch 235/500\n",
      "1/1 - 0s - loss: 0.0061\n",
      "Epoch 236/500\n",
      "1/1 - 0s - loss: 0.0058\n",
      "Epoch 237/500\n",
      "1/1 - 0s - loss: 0.0055\n",
      "Epoch 238/500\n",
      "1/1 - 0s - loss: 0.0052\n",
      "Epoch 239/500\n",
      "1/1 - 0s - loss: 0.0049\n",
      "Epoch 240/500\n",
      "1/1 - 0s - loss: 0.0047\n",
      "Epoch 241/500\n",
      "1/1 - 0s - loss: 0.0044\n",
      "Epoch 242/500\n",
      "1/1 - 0s - loss: 0.0042\n",
      "Epoch 243/500\n",
      "1/1 - 0s - loss: 0.0039\n",
      "Epoch 244/500\n",
      "1/1 - 0s - loss: 0.0037\n",
      "Epoch 245/500\n",
      "1/1 - 0s - loss: 0.0035\n",
      "Epoch 246/500\n",
      "1/1 - 0s - loss: 0.0033\n",
      "Epoch 247/500\n",
      "1/1 - 0s - loss: 0.0031\n",
      "Epoch 248/500\n",
      "1/1 - 0s - loss: 0.0029\n",
      "Epoch 249/500\n",
      "1/1 - 0s - loss: 0.0027\n",
      "Epoch 250/500\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 251/500\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 252/500\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 253/500\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 254/500\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 255/500\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 256/500\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 257/500\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 258/500\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 259/500\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 260/500\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 261/500\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 262/500\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 263/500\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 264/500\n",
      "1/1 - 0s - loss: 9.8047e-04\n",
      "Epoch 265/500\n",
      "1/1 - 0s - loss: 9.0966e-04\n",
      "Epoch 266/500\n",
      "1/1 - 0s - loss: 8.4324e-04\n",
      "Epoch 267/500\n",
      "1/1 - 0s - loss: 7.8101e-04\n",
      "Epoch 268/500\n",
      "1/1 - 0s - loss: 7.2275e-04\n",
      "Epoch 269/500\n",
      "1/1 - 0s - loss: 6.6825e-04\n",
      "Epoch 270/500\n",
      "1/1 - 0s - loss: 6.1732e-04\n",
      "Epoch 271/500\n",
      "1/1 - 0s - loss: 5.6977e-04\n",
      "Epoch 272/500\n",
      "1/1 - 0s - loss: 5.2541e-04\n",
      "Epoch 273/500\n",
      "1/1 - 0s - loss: 4.8408e-04\n",
      "Epoch 274/500\n",
      "1/1 - 0s - loss: 4.4559e-04\n",
      "Epoch 275/500\n",
      "1/1 - 0s - loss: 4.0979e-04\n",
      "Epoch 276/500\n",
      "1/1 - 0s - loss: 3.7652e-04\n",
      "Epoch 277/500\n",
      "1/1 - 0s - loss: 3.4563e-04\n",
      "Epoch 278/500\n",
      "1/1 - 0s - loss: 3.1698e-04\n",
      "Epoch 279/500\n",
      "1/1 - 0s - loss: 2.9044e-04\n",
      "Epoch 280/500\n",
      "1/1 - 0s - loss: 2.6586e-04\n",
      "Epoch 281/500\n",
      "1/1 - 0s - loss: 2.4313e-04\n",
      "Epoch 282/500\n",
      "1/1 - 0s - loss: 2.2213e-04\n",
      "Epoch 283/500\n",
      "1/1 - 0s - loss: 2.0274e-04\n",
      "Epoch 284/500\n",
      "1/1 - 0s - loss: 1.8487e-04\n",
      "Epoch 285/500\n",
      "1/1 - 0s - loss: 1.6841e-04\n",
      "Epoch 286/500\n",
      "1/1 - 0s - loss: 1.5326e-04\n",
      "Epoch 287/500\n",
      "1/1 - 0s - loss: 1.3933e-04\n",
      "Epoch 288/500\n",
      "1/1 - 0s - loss: 1.2654e-04\n",
      "Epoch 289/500\n",
      "1/1 - 0s - loss: 1.1481e-04\n",
      "Epoch 290/500\n",
      "1/1 - 0s - loss: 1.0406e-04\n",
      "Epoch 291/500\n",
      "1/1 - 0s - loss: 9.4217e-05\n",
      "Epoch 292/500\n",
      "1/1 - 0s - loss: 8.5218e-05\n",
      "Epoch 293/500\n",
      "1/1 - 0s - loss: 7.6998e-05\n",
      "Epoch 294/500\n",
      "1/1 - 0s - loss: 6.9497e-05\n",
      "Epoch 295/500\n",
      "1/1 - 0s - loss: 6.2660e-05\n",
      "Epoch 296/500\n",
      "1/1 - 0s - loss: 5.6435e-05\n",
      "Epoch 297/500\n",
      "1/1 - 0s - loss: 5.0774e-05\n",
      "Epoch 298/500\n",
      "1/1 - 0s - loss: 4.5632e-05\n",
      "Epoch 299/500\n",
      "1/1 - 0s - loss: 4.0966e-05\n",
      "Epoch 300/500\n",
      "1/1 - 0s - loss: 3.6736e-05\n",
      "Epoch 301/500\n",
      "1/1 - 0s - loss: 3.2907e-05\n",
      "Epoch 302/500\n",
      "1/1 - 0s - loss: 2.9445e-05\n",
      "Epoch 303/500\n",
      "1/1 - 0s - loss: 2.6317e-05\n",
      "Epoch 304/500\n",
      "1/1 - 0s - loss: 2.3496e-05\n",
      "Epoch 305/500\n",
      "1/1 - 0s - loss: 2.0953e-05\n",
      "Epoch 306/500\n",
      "1/1 - 0s - loss: 1.8665e-05\n",
      "Epoch 307/500\n",
      "1/1 - 0s - loss: 1.6607e-05\n",
      "Epoch 308/500\n",
      "1/1 - 0s - loss: 1.4760e-05\n",
      "Epoch 309/500\n",
      "1/1 - 0s - loss: 1.3104e-05\n",
      "Epoch 310/500\n",
      "1/1 - 0s - loss: 1.1620e-05\n",
      "Epoch 311/500\n",
      "1/1 - 0s - loss: 1.0292e-05\n",
      "Epoch 312/500\n",
      "1/1 - 0s - loss: 9.1060e-06\n",
      "Epoch 313/500\n",
      "1/1 - 0s - loss: 8.0472e-06\n",
      "Epoch 314/500\n",
      "1/1 - 0s - loss: 7.1033e-06\n",
      "Epoch 315/500\n",
      "1/1 - 0s - loss: 6.2633e-06\n",
      "Epoch 316/500\n",
      "1/1 - 0s - loss: 5.5164e-06\n",
      "Epoch 317/500\n",
      "1/1 - 0s - loss: 4.8531e-06\n",
      "Epoch 318/500\n",
      "1/1 - 0s - loss: 4.2647e-06\n",
      "Epoch 319/500\n",
      "1/1 - 0s - loss: 3.7436e-06\n",
      "Epoch 320/500\n",
      "1/1 - 0s - loss: 3.2826e-06\n",
      "Epoch 321/500\n",
      "1/1 - 0s - loss: 2.8752e-06\n",
      "Epoch 322/500\n",
      "1/1 - 0s - loss: 2.5157e-06\n",
      "Epoch 323/500\n",
      "1/1 - 0s - loss: 2.1989e-06\n",
      "Epoch 324/500\n",
      "1/1 - 0s - loss: 1.9200e-06\n",
      "Epoch 325/500\n",
      "1/1 - 0s - loss: 1.6748e-06\n",
      "Epoch 326/500\n",
      "1/1 - 0s - loss: 1.4595e-06\n",
      "Epoch 327/500\n",
      "1/1 - 0s - loss: 1.2706e-06\n",
      "Epoch 328/500\n",
      "1/1 - 0s - loss: 1.1054e-06\n",
      "Epoch 329/500\n",
      "1/1 - 0s - loss: 9.6073e-07\n",
      "Epoch 330/500\n",
      "1/1 - 0s - loss: 8.3433e-07\n",
      "Epoch 331/500\n",
      "1/1 - 0s - loss: 7.2406e-07\n",
      "Epoch 332/500\n",
      "1/1 - 0s - loss: 6.2791e-07\n",
      "Epoch 333/500\n",
      "1/1 - 0s - loss: 5.4418e-07\n",
      "Epoch 334/500\n",
      "1/1 - 0s - loss: 4.7138e-07\n",
      "Epoch 335/500\n",
      "1/1 - 0s - loss: 4.0818e-07\n",
      "Epoch 336/500\n",
      "1/1 - 0s - loss: 3.5336e-07\n",
      "Epoch 337/500\n",
      "1/1 - 0s - loss: 3.0581e-07\n",
      "Epoch 338/500\n",
      "1/1 - 0s - loss: 2.6465e-07\n",
      "Epoch 339/500\n",
      "1/1 - 0s - loss: 2.2903e-07\n",
      "Epoch 340/500\n",
      "1/1 - 0s - loss: 1.9823e-07\n",
      "Epoch 341/500\n",
      "1/1 - 0s - loss: 1.7165e-07\n",
      "Epoch 342/500\n",
      "1/1 - 0s - loss: 1.4873e-07\n",
      "Epoch 343/500\n",
      "1/1 - 0s - loss: 1.2897e-07\n",
      "Epoch 344/500\n",
      "1/1 - 0s - loss: 1.1193e-07\n",
      "Epoch 345/500\n",
      "1/1 - 0s - loss: 9.7232e-08\n",
      "Epoch 346/500\n",
      "1/1 - 0s - loss: 8.4606e-08\n",
      "Epoch 347/500\n",
      "1/1 - 0s - loss: 7.3708e-08\n",
      "Epoch 348/500\n",
      "1/1 - 0s - loss: 6.4358e-08\n",
      "Epoch 349/500\n",
      "1/1 - 0s - loss: 5.6281e-08\n",
      "Epoch 350/500\n",
      "1/1 - 0s - loss: 4.9324e-08\n",
      "Epoch 351/500\n",
      "1/1 - 0s - loss: 4.3348e-08\n",
      "Epoch 352/500\n",
      "1/1 - 0s - loss: 3.8201e-08\n",
      "Epoch 353/500\n",
      "1/1 - 0s - loss: 3.3740e-08\n",
      "Epoch 354/500\n",
      "1/1 - 0s - loss: 2.9898e-08\n",
      "Epoch 355/500\n",
      "1/1 - 0s - loss: 2.6567e-08\n",
      "Epoch 356/500\n",
      "1/1 - 0s - loss: 2.3688e-08\n",
      "Epoch 357/500\n",
      "1/1 - 0s - loss: 2.1178e-08\n",
      "Epoch 358/500\n",
      "1/1 - 0s - loss: 1.9004e-08\n",
      "Epoch 359/500\n",
      "1/1 - 0s - loss: 1.7099e-08\n",
      "Epoch 360/500\n",
      "1/1 - 0s - loss: 1.5433e-08\n",
      "Epoch 361/500\n",
      "1/1 - 0s - loss: 1.3972e-08\n",
      "Epoch 362/500\n",
      "1/1 - 0s - loss: 1.2689e-08\n",
      "Epoch 363/500\n",
      "1/1 - 0s - loss: 1.1553e-08\n",
      "Epoch 364/500\n",
      "1/1 - 0s - loss: 1.0541e-08\n",
      "Epoch 365/500\n",
      "1/1 - 0s - loss: 9.6440e-09\n",
      "Epoch 366/500\n",
      "1/1 - 0s - loss: 8.8388e-09\n",
      "Epoch 367/500\n",
      "1/1 - 0s - loss: 8.1220e-09\n",
      "Epoch 368/500\n",
      "1/1 - 0s - loss: 7.4658e-09\n",
      "Epoch 369/500\n",
      "1/1 - 0s - loss: 6.8748e-09\n",
      "Epoch 370/500\n",
      "1/1 - 0s - loss: 6.3459e-09\n",
      "Epoch 371/500\n",
      "1/1 - 0s - loss: 5.8596e-09\n",
      "Epoch 372/500\n",
      "1/1 - 0s - loss: 5.4162e-09\n",
      "Epoch 373/500\n",
      "1/1 - 0s - loss: 5.0084e-09\n",
      "Epoch 374/500\n",
      "1/1 - 0s - loss: 4.6339e-09\n",
      "Epoch 375/500\n",
      "1/1 - 0s - loss: 4.2938e-09\n",
      "Epoch 376/500\n",
      "1/1 - 0s - loss: 3.9750e-09\n",
      "Epoch 377/500\n",
      "1/1 - 0s - loss: 3.6783e-09\n",
      "Epoch 378/500\n",
      "1/1 - 0s - loss: 3.4102e-09\n",
      "Epoch 379/500\n",
      "1/1 - 0s - loss: 3.1538e-09\n",
      "Epoch 380/500\n",
      "1/1 - 0s - loss: 2.9209e-09\n",
      "Epoch 381/500\n",
      "1/1 - 0s - loss: 2.7016e-09\n",
      "Epoch 382/500\n",
      "1/1 - 0s - loss: 2.5003e-09\n",
      "Epoch 383/500\n",
      "1/1 - 0s - loss: 2.3092e-09\n",
      "Epoch 384/500\n",
      "1/1 - 0s - loss: 2.1376e-09\n",
      "Epoch 385/500\n",
      "1/1 - 0s - loss: 1.9730e-09\n",
      "Epoch 386/500\n",
      "1/1 - 0s - loss: 1.8215e-09\n",
      "Epoch 387/500\n",
      "1/1 - 0s - loss: 1.6829e-09\n",
      "Epoch 388/500\n",
      "1/1 - 0s - loss: 1.5513e-09\n",
      "Epoch 389/500\n",
      "1/1 - 0s - loss: 1.4307e-09\n",
      "Epoch 390/500\n",
      "1/1 - 0s - loss: 1.3152e-09\n",
      "Epoch 391/500\n",
      "1/1 - 0s - loss: 1.2109e-09\n",
      "Epoch 392/500\n",
      "1/1 - 0s - loss: 1.1176e-09\n",
      "Epoch 393/500\n",
      "1/1 - 0s - loss: 1.0263e-09\n",
      "Epoch 394/500\n",
      "1/1 - 0s - loss: 9.4283e-10\n",
      "Epoch 395/500\n",
      "1/1 - 0s - loss: 8.6347e-10\n",
      "Epoch 396/500\n",
      "1/1 - 0s - loss: 7.9318e-10\n",
      "Epoch 397/500\n",
      "1/1 - 0s - loss: 7.2982e-10\n",
      "Epoch 398/500\n",
      "1/1 - 0s - loss: 6.6777e-10\n",
      "Epoch 399/500\n",
      "1/1 - 0s - loss: 6.0998e-10\n",
      "Epoch 400/500\n",
      "1/1 - 0s - loss: 5.5923e-10\n",
      "Epoch 401/500\n",
      "1/1 - 0s - loss: 5.1248e-10\n",
      "Epoch 402/500\n",
      "1/1 - 0s - loss: 4.6731e-10\n",
      "Epoch 403/500\n",
      "1/1 - 0s - loss: 4.2682e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/500\n",
      "1/1 - 0s - loss: 3.8796e-10\n",
      "Epoch 405/500\n",
      "1/1 - 0s - loss: 3.5462e-10\n",
      "Epoch 406/500\n",
      "1/1 - 0s - loss: 3.2295e-10\n",
      "Epoch 407/500\n",
      "1/1 - 0s - loss: 2.9290e-10\n",
      "Epoch 408/500\n",
      "1/1 - 0s - loss: 2.6716e-10\n",
      "Epoch 409/500\n",
      "1/1 - 0s - loss: 2.4259e-10\n",
      "Epoch 410/500\n",
      "1/1 - 0s - loss: 2.2032e-10\n",
      "Epoch 411/500\n",
      "1/1 - 0s - loss: 2.0019e-10\n",
      "Epoch 412/500\n",
      "1/1 - 0s - loss: 1.8196e-10\n",
      "Epoch 413/500\n",
      "1/1 - 0s - loss: 1.6495e-10\n",
      "Epoch 414/500\n",
      "1/1 - 0s - loss: 1.4909e-10\n",
      "Epoch 415/500\n",
      "1/1 - 0s - loss: 1.3487e-10\n",
      "Epoch 416/500\n",
      "1/1 - 0s - loss: 1.2139e-10\n",
      "Epoch 417/500\n",
      "1/1 - 0s - loss: 1.1040e-10\n",
      "Epoch 418/500\n",
      "1/1 - 0s - loss: 9.9271e-11\n",
      "Epoch 419/500\n",
      "1/1 - 0s - loss: 8.8714e-11\n",
      "Epoch 420/500\n",
      "1/1 - 0s - loss: 8.0599e-11\n",
      "Epoch 421/500\n",
      "1/1 - 0s - loss: 7.2342e-11\n",
      "Epoch 422/500\n",
      "1/1 - 0s - loss: 6.5286e-11\n",
      "Epoch 423/500\n",
      "1/1 - 0s - loss: 5.7744e-11\n",
      "Epoch 424/500\n",
      "1/1 - 0s - loss: 5.2427e-11\n",
      "Epoch 425/500\n",
      "1/1 - 0s - loss: 4.6717e-11\n",
      "Epoch 426/500\n",
      "1/1 - 0s - loss: 4.1946e-11\n",
      "Epoch 427/500\n",
      "1/1 - 0s - loss: 3.7399e-11\n",
      "Epoch 428/500\n",
      "1/1 - 0s - loss: 3.3411e-11\n",
      "Epoch 429/500\n",
      "1/1 - 0s - loss: 2.9305e-11\n",
      "Epoch 430/500\n",
      "1/1 - 0s - loss: 2.6313e-11\n",
      "Epoch 431/500\n",
      "1/1 - 0s - loss: 2.3301e-11\n",
      "Epoch 432/500\n",
      "1/1 - 0s - loss: 2.0662e-11\n",
      "Epoch 433/500\n",
      "1/1 - 0s - loss: 1.8139e-11\n",
      "Epoch 434/500\n",
      "1/1 - 0s - loss: 1.6212e-11\n",
      "Epoch 435/500\n",
      "1/1 - 0s - loss: 1.4064e-11\n",
      "Epoch 436/500\n",
      "1/1 - 0s - loss: 1.2337e-11\n",
      "Epoch 437/500\n",
      "1/1 - 0s - loss: 1.1015e-11\n",
      "Epoch 438/500\n",
      "1/1 - 0s - loss: 9.5808e-12\n",
      "Epoch 439/500\n",
      "1/1 - 0s - loss: 8.2907e-12\n",
      "Epoch 440/500\n",
      "1/1 - 0s - loss: 7.2613e-12\n",
      "Epoch 441/500\n",
      "1/1 - 0s - loss: 6.3179e-12\n",
      "Epoch 442/500\n",
      "1/1 - 0s - loss: 5.4867e-12\n",
      "Epoch 443/500\n",
      "1/1 - 0s - loss: 4.7689e-12\n",
      "Epoch 444/500\n",
      "1/1 - 0s - loss: 4.0589e-12\n",
      "Epoch 445/500\n",
      "1/1 - 0s - loss: 3.4931e-12\n",
      "Epoch 446/500\n",
      "1/1 - 0s - loss: 2.9257e-12\n",
      "Epoch 447/500\n",
      "1/1 - 0s - loss: 2.4839e-12\n",
      "Epoch 448/500\n",
      "1/1 - 0s - loss: 2.0789e-12\n",
      "Epoch 449/500\n",
      "1/1 - 0s - loss: 1.8466e-12\n",
      "Epoch 450/500\n",
      "1/1 - 0s - loss: 1.5926e-12\n",
      "Epoch 451/500\n",
      "1/1 - 0s - loss: 1.3627e-12\n",
      "Epoch 452/500\n",
      "1/1 - 0s - loss: 1.0945e-12\n",
      "Epoch 453/500\n",
      "1/1 - 0s - loss: 9.4347e-13\n",
      "Epoch 454/500\n",
      "1/1 - 0s - loss: 7.6460e-13\n",
      "Epoch 455/500\n",
      "1/1 - 0s - loss: 6.6148e-13\n",
      "Epoch 456/500\n",
      "1/1 - 0s - loss: 5.5019e-13\n",
      "Epoch 457/500\n",
      "1/1 - 0s - loss: 4.4871e-13\n",
      "Epoch 458/500\n",
      "1/1 - 0s - loss: 3.6714e-13\n",
      "Epoch 459/500\n",
      "1/1 - 0s - loss: 3.2628e-13\n",
      "Epoch 460/500\n",
      "1/1 - 0s - loss: 2.9085e-13\n",
      "Epoch 461/500\n",
      "1/1 - 0s - loss: 2.5069e-13\n",
      "Epoch 462/500\n",
      "1/1 - 0s - loss: 2.0212e-13\n",
      "Epoch 463/500\n",
      "1/1 - 0s - loss: 1.9575e-13\n",
      "Epoch 464/500\n",
      "1/1 - 0s - loss: 1.9349e-13\n",
      "Epoch 465/500\n",
      "1/1 - 0s - loss: 1.6733e-13\n",
      "Epoch 466/500\n",
      "1/1 - 0s - loss: 1.6094e-13\n",
      "Epoch 467/500\n",
      "1/1 - 0s - loss: 1.4083e-13\n",
      "Epoch 468/500\n",
      "1/1 - 0s - loss: 1.1395e-13\n",
      "Epoch 469/500\n",
      "1/1 - 0s - loss: 1.1179e-13\n",
      "Epoch 470/500\n",
      "1/1 - 0s - loss: 1.1285e-13\n",
      "Epoch 471/500\n",
      "1/1 - 0s - loss: 9.9798e-14\n",
      "Epoch 472/500\n",
      "1/1 - 0s - loss: 9.9798e-14\n",
      "Epoch 473/500\n",
      "1/1 - 0s - loss: 9.3670e-14\n",
      "Epoch 474/500\n",
      "1/1 - 0s - loss: 9.8821e-14\n",
      "Epoch 475/500\n",
      "1/1 - 0s - loss: 6.6225e-14\n",
      "Epoch 476/500\n",
      "1/1 - 0s - loss: 7.1676e-14\n",
      "Epoch 477/500\n",
      "1/1 - 0s - loss: 7.1676e-14\n",
      "Epoch 478/500\n",
      "1/1 - 0s - loss: 7.4873e-14\n",
      "Epoch 479/500\n",
      "1/1 - 0s - loss: 6.3283e-14\n",
      "Epoch 480/500\n",
      "1/1 - 0s - loss: 4.8228e-14\n",
      "Epoch 481/500\n",
      "1/1 - 0s - loss: 4.7873e-14\n",
      "Epoch 482/500\n",
      "1/1 - 0s - loss: 4.7873e-14\n",
      "Epoch 483/500\n",
      "1/1 - 0s - loss: 4.6152e-14\n",
      "Epoch 484/500\n",
      "1/1 - 0s - loss: 4.6152e-14\n",
      "Epoch 485/500\n",
      "1/1 - 0s - loss: 4.6152e-14\n",
      "Epoch 486/500\n",
      "1/1 - 0s - loss: 4.5386e-14\n",
      "Epoch 487/500\n",
      "1/1 - 0s - loss: 4.5386e-14\n",
      "Epoch 488/500\n",
      "1/1 - 0s - loss: 4.5386e-14\n",
      "Epoch 489/500\n",
      "1/1 - 0s - loss: 4.0901e-14\n",
      "Epoch 490/500\n",
      "1/1 - 0s - loss: 4.0901e-14\n",
      "Epoch 491/500\n",
      "1/1 - 0s - loss: 4.0901e-14\n",
      "Epoch 492/500\n",
      "1/1 - 0s - loss: 4.0901e-14\n",
      "Epoch 493/500\n",
      "1/1 - 0s - loss: 4.0901e-14\n",
      "Epoch 494/500\n",
      "1/1 - 0s - loss: 3.7348e-14\n",
      "Epoch 495/500\n",
      "1/1 - 0s - loss: 4.0901e-14\n",
      "Epoch 496/500\n",
      "1/1 - 0s - loss: 4.0901e-14\n",
      "Epoch 497/500\n",
      "1/1 - 0s - loss: 4.0645e-14\n",
      "Epoch 498/500\n",
      "1/1 - 0s - loss: 4.0645e-14\n",
      "Epoch 499/500\n",
      "1/1 - 0s - loss: 4.0645e-14\n",
      "Epoch 500/500\n",
      "1/1 - 0s - loss: 4.0645e-14\n",
      "-0.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "#prepare sequence\n",
    "length = 5\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(1, length, 1)\n",
    "y = seq.reshape(1, length)\n",
    "\n",
    "#LSTM configuration\n",
    "n_neurons = length\n",
    "n_batch = 1\n",
    "n_epoch = 500\n",
    "\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(length, 1)))\n",
    "model.add(Dense(length))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "\n",
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=2)\n",
    "\n",
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "for value in result[0,:]:\n",
    "\tprint('%.1f' % value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many-to-Many LSTM for Sequence Prediction (with TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 5, 5)              140       \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 5, 1)              6         \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1 samples\n",
      "Epoch 1/1000\n",
      "1/1 - 3s - loss: 0.2285\n",
      "Epoch 2/1000\n",
      "1/1 - 0s - loss: 0.2258\n",
      "Epoch 3/1000\n",
      "1/1 - 0s - loss: 0.2231\n",
      "Epoch 4/1000\n",
      "1/1 - 0s - loss: 0.2204\n",
      "Epoch 5/1000\n",
      "1/1 - 0s - loss: 0.2177\n",
      "Epoch 6/1000\n",
      "1/1 - 0s - loss: 0.2151\n",
      "Epoch 7/1000\n",
      "1/1 - 0s - loss: 0.2125\n",
      "Epoch 8/1000\n",
      "1/1 - 0s - loss: 0.2099\n",
      "Epoch 9/1000\n",
      "1/1 - 0s - loss: 0.2073\n",
      "Epoch 10/1000\n",
      "1/1 - 0s - loss: 0.2048\n",
      "Epoch 11/1000\n",
      "1/1 - 0s - loss: 0.2022\n",
      "Epoch 12/1000\n",
      "1/1 - 0s - loss: 0.1997\n",
      "Epoch 13/1000\n",
      "1/1 - 0s - loss: 0.1972\n",
      "Epoch 14/1000\n",
      "1/1 - 0s - loss: 0.1947\n",
      "Epoch 15/1000\n",
      "1/1 - 0s - loss: 0.1922\n",
      "Epoch 16/1000\n",
      "1/1 - 0s - loss: 0.1898\n",
      "Epoch 17/1000\n",
      "1/1 - 0s - loss: 0.1874\n",
      "Epoch 18/1000\n",
      "1/1 - 0s - loss: 0.1849\n",
      "Epoch 19/1000\n",
      "1/1 - 0s - loss: 0.1825\n",
      "Epoch 20/1000\n",
      "1/1 - 0s - loss: 0.1801\n",
      "Epoch 21/1000\n",
      "1/1 - 0s - loss: 0.1777\n",
      "Epoch 22/1000\n",
      "1/1 - 0s - loss: 0.1754\n",
      "Epoch 23/1000\n",
      "1/1 - 0s - loss: 0.1730\n",
      "Epoch 24/1000\n",
      "1/1 - 0s - loss: 0.1707\n",
      "Epoch 25/1000\n",
      "1/1 - 0s - loss: 0.1683\n",
      "Epoch 26/1000\n",
      "1/1 - 0s - loss: 0.1660\n",
      "Epoch 27/1000\n",
      "1/1 - 0s - loss: 0.1637\n",
      "Epoch 28/1000\n",
      "1/1 - 0s - loss: 0.1614\n",
      "Epoch 29/1000\n",
      "1/1 - 0s - loss: 0.1591\n",
      "Epoch 30/1000\n",
      "1/1 - 0s - loss: 0.1569\n",
      "Epoch 31/1000\n",
      "1/1 - 0s - loss: 0.1546\n",
      "Epoch 32/1000\n",
      "1/1 - 0s - loss: 0.1523\n",
      "Epoch 33/1000\n",
      "1/1 - 0s - loss: 0.1501\n",
      "Epoch 34/1000\n",
      "1/1 - 0s - loss: 0.1479\n",
      "Epoch 35/1000\n",
      "1/1 - 0s - loss: 0.1457\n",
      "Epoch 36/1000\n",
      "1/1 - 0s - loss: 0.1435\n",
      "Epoch 37/1000\n",
      "1/1 - 0s - loss: 0.1413\n",
      "Epoch 38/1000\n",
      "1/1 - 0s - loss: 0.1391\n",
      "Epoch 39/1000\n",
      "1/1 - 0s - loss: 0.1369\n",
      "Epoch 40/1000\n",
      "1/1 - 0s - loss: 0.1347\n",
      "Epoch 41/1000\n",
      "1/1 - 0s - loss: 0.1326\n",
      "Epoch 42/1000\n",
      "1/1 - 0s - loss: 0.1304\n",
      "Epoch 43/1000\n",
      "1/1 - 0s - loss: 0.1283\n",
      "Epoch 44/1000\n",
      "1/1 - 0s - loss: 0.1262\n",
      "Epoch 45/1000\n",
      "1/1 - 0s - loss: 0.1241\n",
      "Epoch 46/1000\n",
      "1/1 - 0s - loss: 0.1220\n",
      "Epoch 47/1000\n",
      "1/1 - 0s - loss: 0.1199\n",
      "Epoch 48/1000\n",
      "1/1 - 0s - loss: 0.1178\n",
      "Epoch 49/1000\n",
      "1/1 - 0s - loss: 0.1158\n",
      "Epoch 50/1000\n",
      "1/1 - 0s - loss: 0.1137\n",
      "Epoch 51/1000\n",
      "1/1 - 0s - loss: 0.1117\n",
      "Epoch 52/1000\n",
      "1/1 - 0s - loss: 0.1097\n",
      "Epoch 53/1000\n",
      "1/1 - 0s - loss: 0.1077\n",
      "Epoch 54/1000\n",
      "1/1 - 0s - loss: 0.1057\n",
      "Epoch 55/1000\n",
      "1/1 - 0s - loss: 0.1037\n",
      "Epoch 56/1000\n",
      "1/1 - 0s - loss: 0.1017\n",
      "Epoch 57/1000\n",
      "1/1 - 0s - loss: 0.0998\n",
      "Epoch 58/1000\n",
      "1/1 - 0s - loss: 0.0978\n",
      "Epoch 59/1000\n",
      "1/1 - 0s - loss: 0.0959\n",
      "Epoch 60/1000\n",
      "1/1 - 0s - loss: 0.0940\n",
      "Epoch 61/1000\n",
      "1/1 - 0s - loss: 0.0921\n",
      "Epoch 62/1000\n",
      "1/1 - 0s - loss: 0.0902\n",
      "Epoch 63/1000\n",
      "1/1 - 0s - loss: 0.0883\n",
      "Epoch 64/1000\n",
      "1/1 - 0s - loss: 0.0864\n",
      "Epoch 65/1000\n",
      "1/1 - 0s - loss: 0.0846\n",
      "Epoch 66/1000\n",
      "1/1 - 0s - loss: 0.0827\n",
      "Epoch 67/1000\n",
      "1/1 - 0s - loss: 0.0809\n",
      "Epoch 68/1000\n",
      "1/1 - 0s - loss: 0.0791\n",
      "Epoch 69/1000\n",
      "1/1 - 0s - loss: 0.0773\n",
      "Epoch 70/1000\n",
      "1/1 - 0s - loss: 0.0756\n",
      "Epoch 71/1000\n",
      "1/1 - 0s - loss: 0.0738\n",
      "Epoch 72/1000\n",
      "1/1 - 0s - loss: 0.0721\n",
      "Epoch 73/1000\n",
      "1/1 - 0s - loss: 0.0704\n",
      "Epoch 74/1000\n",
      "1/1 - 0s - loss: 0.0687\n",
      "Epoch 75/1000\n",
      "1/1 - 0s - loss: 0.0670\n",
      "Epoch 76/1000\n",
      "1/1 - 0s - loss: 0.0653\n",
      "Epoch 77/1000\n",
      "1/1 - 0s - loss: 0.0637\n",
      "Epoch 78/1000\n",
      "1/1 - 0s - loss: 0.0621\n",
      "Epoch 79/1000\n",
      "1/1 - 0s - loss: 0.0605\n",
      "Epoch 80/1000\n",
      "1/1 - 0s - loss: 0.0589\n",
      "Epoch 81/1000\n",
      "1/1 - 0s - loss: 0.0573\n",
      "Epoch 82/1000\n",
      "1/1 - 0s - loss: 0.0558\n",
      "Epoch 83/1000\n",
      "1/1 - 0s - loss: 0.0543\n",
      "Epoch 84/1000\n",
      "1/1 - 0s - loss: 0.0528\n",
      "Epoch 85/1000\n",
      "1/1 - 0s - loss: 0.0513\n",
      "Epoch 86/1000\n",
      "1/1 - 0s - loss: 0.0498\n",
      "Epoch 87/1000\n",
      "1/1 - 0s - loss: 0.0484\n",
      "Epoch 88/1000\n",
      "1/1 - 0s - loss: 0.0470\n",
      "Epoch 89/1000\n",
      "1/1 - 0s - loss: 0.0456\n",
      "Epoch 90/1000\n",
      "1/1 - 0s - loss: 0.0442\n",
      "Epoch 91/1000\n",
      "1/1 - 0s - loss: 0.0429\n",
      "Epoch 92/1000\n",
      "1/1 - 0s - loss: 0.0416\n",
      "Epoch 93/1000\n",
      "1/1 - 0s - loss: 0.0403\n",
      "Epoch 94/1000\n",
      "1/1 - 0s - loss: 0.0390\n",
      "Epoch 95/1000\n",
      "1/1 - 0s - loss: 0.0378\n",
      "Epoch 96/1000\n",
      "1/1 - 0s - loss: 0.0366\n",
      "Epoch 97/1000\n",
      "1/1 - 0s - loss: 0.0354\n",
      "Epoch 98/1000\n",
      "1/1 - 0s - loss: 0.0342\n",
      "Epoch 99/1000\n",
      "1/1 - 0s - loss: 0.0331\n",
      "Epoch 100/1000\n",
      "1/1 - 0s - loss: 0.0320\n",
      "Epoch 101/1000\n",
      "1/1 - 0s - loss: 0.0309\n",
      "Epoch 102/1000\n",
      "1/1 - 0s - loss: 0.0299\n",
      "Epoch 103/1000\n",
      "1/1 - 0s - loss: 0.0289\n",
      "Epoch 104/1000\n",
      "1/1 - 0s - loss: 0.0279\n",
      "Epoch 105/1000\n",
      "1/1 - 0s - loss: 0.0269\n",
      "Epoch 106/1000\n",
      "1/1 - 0s - loss: 0.0260\n",
      "Epoch 107/1000\n",
      "1/1 - 0s - loss: 0.0250\n",
      "Epoch 108/1000\n",
      "1/1 - 0s - loss: 0.0242\n",
      "Epoch 109/1000\n",
      "1/1 - 0s - loss: 0.0233\n",
      "Epoch 110/1000\n",
      "1/1 - 0s - loss: 0.0225\n",
      "Epoch 111/1000\n",
      "1/1 - 0s - loss: 0.0217\n",
      "Epoch 112/1000\n",
      "1/1 - 0s - loss: 0.0209\n",
      "Epoch 113/1000\n",
      "1/1 - 0s - loss: 0.0202\n",
      "Epoch 114/1000\n",
      "1/1 - 0s - loss: 0.0195\n",
      "Epoch 115/1000\n",
      "1/1 - 0s - loss: 0.0188\n",
      "Epoch 116/1000\n",
      "1/1 - 0s - loss: 0.0182\n",
      "Epoch 117/1000\n",
      "1/1 - 0s - loss: 0.0175\n",
      "Epoch 118/1000\n",
      "1/1 - 0s - loss: 0.0169\n",
      "Epoch 119/1000\n",
      "1/1 - 0s - loss: 0.0164\n",
      "Epoch 120/1000\n",
      "1/1 - 0s - loss: 0.0158\n",
      "Epoch 121/1000\n",
      "1/1 - 0s - loss: 0.0153\n",
      "Epoch 122/1000\n",
      "1/1 - 0s - loss: 0.0148\n",
      "Epoch 123/1000\n",
      "1/1 - 0s - loss: 0.0143\n",
      "Epoch 124/1000\n",
      "1/1 - 0s - loss: 0.0139\n",
      "Epoch 125/1000\n",
      "1/1 - 0s - loss: 0.0135\n",
      "Epoch 126/1000\n",
      "1/1 - 0s - loss: 0.0131\n",
      "Epoch 127/1000\n",
      "1/1 - 0s - loss: 0.0127\n",
      "Epoch 128/1000\n",
      "1/1 - 0s - loss: 0.0123\n",
      "Epoch 129/1000\n",
      "1/1 - 0s - loss: 0.0120\n",
      "Epoch 130/1000\n",
      "1/1 - 0s - loss: 0.0117\n",
      "Epoch 131/1000\n",
      "1/1 - 0s - loss: 0.0114\n",
      "Epoch 132/1000\n",
      "1/1 - 0s - loss: 0.0111\n",
      "Epoch 133/1000\n",
      "1/1 - 0s - loss: 0.0109\n",
      "Epoch 134/1000\n",
      "1/1 - 0s - loss: 0.0106\n",
      "Epoch 135/1000\n",
      "1/1 - 0s - loss: 0.0104\n",
      "Epoch 136/1000\n",
      "1/1 - 0s - loss: 0.0102\n",
      "Epoch 137/1000\n",
      "1/1 - 0s - loss: 0.0100\n",
      "Epoch 138/1000\n",
      "1/1 - 0s - loss: 0.0098\n",
      "Epoch 139/1000\n",
      "1/1 - 0s - loss: 0.0097\n",
      "Epoch 140/1000\n",
      "1/1 - 0s - loss: 0.0095\n",
      "Epoch 141/1000\n",
      "1/1 - 0s - loss: 0.0094\n",
      "Epoch 142/1000\n",
      "1/1 - 0s - loss: 0.0093\n",
      "Epoch 143/1000\n",
      "1/1 - 0s - loss: 0.0091\n",
      "Epoch 144/1000\n",
      "1/1 - 0s - loss: 0.0090\n",
      "Epoch 145/1000\n",
      "1/1 - 0s - loss: 0.0089\n",
      "Epoch 146/1000\n",
      "1/1 - 0s - loss: 0.0088\n",
      "Epoch 147/1000\n",
      "1/1 - 0s - loss: 0.0088\n",
      "Epoch 148/1000\n",
      "1/1 - 0s - loss: 0.0087\n",
      "Epoch 149/1000\n",
      "1/1 - 0s - loss: 0.0086\n",
      "Epoch 150/1000\n",
      "1/1 - 0s - loss: 0.0085\n",
      "Epoch 151/1000\n",
      "1/1 - 0s - loss: 0.0085\n",
      "Epoch 152/1000\n",
      "1/1 - 0s - loss: 0.0084\n",
      "Epoch 153/1000\n",
      "1/1 - 0s - loss: 0.0084\n",
      "Epoch 154/1000\n",
      "1/1 - 0s - loss: 0.0083\n",
      "Epoch 155/1000\n",
      "1/1 - 0s - loss: 0.0083\n",
      "Epoch 156/1000\n",
      "1/1 - 0s - loss: 0.0082\n",
      "Epoch 157/1000\n",
      "1/1 - 0s - loss: 0.0082\n",
      "Epoch 158/1000\n",
      "1/1 - 0s - loss: 0.0081\n",
      "Epoch 159/1000\n",
      "1/1 - 0s - loss: 0.0081\n",
      "Epoch 160/1000\n",
      "1/1 - 0s - loss: 0.0080\n",
      "Epoch 161/1000\n",
      "1/1 - 0s - loss: 0.0080\n",
      "Epoch 162/1000\n",
      "1/1 - 0s - loss: 0.0080\n",
      "Epoch 163/1000\n",
      "1/1 - 0s - loss: 0.0079\n",
      "Epoch 164/1000\n",
      "1/1 - 0s - loss: 0.0079\n",
      "Epoch 165/1000\n",
      "1/1 - 0s - loss: 0.0078\n",
      "Epoch 166/1000\n",
      "1/1 - 0s - loss: 0.0078\n",
      "Epoch 167/1000\n",
      "1/1 - 0s - loss: 0.0078\n",
      "Epoch 168/1000\n",
      "1/1 - 0s - loss: 0.0077\n",
      "Epoch 169/1000\n",
      "1/1 - 0s - loss: 0.0077\n",
      "Epoch 170/1000\n",
      "1/1 - 0s - loss: 0.0077\n",
      "Epoch 171/1000\n",
      "1/1 - 0s - loss: 0.0076\n",
      "Epoch 172/1000\n",
      "1/1 - 0s - loss: 0.0076\n",
      "Epoch 173/1000\n",
      "1/1 - 0s - loss: 0.0075\n",
      "Epoch 174/1000\n",
      "1/1 - 0s - loss: 0.0075\n",
      "Epoch 175/1000\n",
      "1/1 - 0s - loss: 0.0075\n",
      "Epoch 176/1000\n",
      "1/1 - 0s - loss: 0.0074\n",
      "Epoch 177/1000\n",
      "1/1 - 0s - loss: 0.0074\n",
      "Epoch 178/1000\n",
      "1/1 - 0s - loss: 0.0074\n",
      "Epoch 179/1000\n",
      "1/1 - 0s - loss: 0.0073\n",
      "Epoch 180/1000\n",
      "1/1 - 0s - loss: 0.0073\n",
      "Epoch 181/1000\n",
      "1/1 - 0s - loss: 0.0073\n",
      "Epoch 182/1000\n",
      "1/1 - 0s - loss: 0.0072\n",
      "Epoch 183/1000\n",
      "1/1 - 0s - loss: 0.0072\n",
      "Epoch 184/1000\n",
      "1/1 - 0s - loss: 0.0071\n",
      "Epoch 185/1000\n",
      "1/1 - 0s - loss: 0.0071\n",
      "Epoch 186/1000\n",
      "1/1 - 0s - loss: 0.0071\n",
      "Epoch 187/1000\n",
      "1/1 - 0s - loss: 0.0070\n",
      "Epoch 188/1000\n",
      "1/1 - 0s - loss: 0.0070\n",
      "Epoch 189/1000\n",
      "1/1 - 0s - loss: 0.0070\n",
      "Epoch 190/1000\n",
      "1/1 - 0s - loss: 0.0069\n",
      "Epoch 191/1000\n",
      "1/1 - 0s - loss: 0.0069\n",
      "Epoch 192/1000\n",
      "1/1 - 0s - loss: 0.0069\n",
      "Epoch 193/1000\n",
      "1/1 - 0s - loss: 0.0068\n",
      "Epoch 194/1000\n",
      "1/1 - 0s - loss: 0.0068\n",
      "Epoch 195/1000\n",
      "1/1 - 0s - loss: 0.0068\n",
      "Epoch 196/1000\n",
      "1/1 - 0s - loss: 0.0067\n",
      "Epoch 197/1000\n",
      "1/1 - 0s - loss: 0.0067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/1000\n",
      "1/1 - 0s - loss: 0.0066\n",
      "Epoch 199/1000\n",
      "1/1 - 0s - loss: 0.0066\n",
      "Epoch 200/1000\n",
      "1/1 - 0s - loss: 0.0066\n",
      "Epoch 201/1000\n",
      "1/1 - 0s - loss: 0.0065\n",
      "Epoch 202/1000\n",
      "1/1 - 0s - loss: 0.0065\n",
      "Epoch 203/1000\n",
      "1/1 - 0s - loss: 0.0065\n",
      "Epoch 204/1000\n",
      "1/1 - 0s - loss: 0.0064\n",
      "Epoch 205/1000\n",
      "1/1 - 0s - loss: 0.0064\n",
      "Epoch 206/1000\n",
      "1/1 - 0s - loss: 0.0064\n",
      "Epoch 207/1000\n",
      "1/1 - 0s - loss: 0.0063\n",
      "Epoch 208/1000\n",
      "1/1 - 0s - loss: 0.0063\n",
      "Epoch 209/1000\n",
      "1/1 - 0s - loss: 0.0063\n",
      "Epoch 210/1000\n",
      "1/1 - 0s - loss: 0.0062\n",
      "Epoch 211/1000\n",
      "1/1 - 0s - loss: 0.0062\n",
      "Epoch 212/1000\n",
      "1/1 - 0s - loss: 0.0062\n",
      "Epoch 213/1000\n",
      "1/1 - 0s - loss: 0.0062\n",
      "Epoch 214/1000\n",
      "1/1 - 0s - loss: 0.0061\n",
      "Epoch 215/1000\n",
      "1/1 - 0s - loss: 0.0061\n",
      "Epoch 216/1000\n",
      "1/1 - 0s - loss: 0.0061\n",
      "Epoch 217/1000\n",
      "1/1 - 0s - loss: 0.0060\n",
      "Epoch 218/1000\n",
      "1/1 - 0s - loss: 0.0060\n",
      "Epoch 219/1000\n",
      "1/1 - 0s - loss: 0.0060\n",
      "Epoch 220/1000\n",
      "1/1 - 0s - loss: 0.0059\n",
      "Epoch 221/1000\n",
      "1/1 - 0s - loss: 0.0059\n",
      "Epoch 222/1000\n",
      "1/1 - 0s - loss: 0.0059\n",
      "Epoch 223/1000\n",
      "1/1 - 0s - loss: 0.0058\n",
      "Epoch 224/1000\n",
      "1/1 - 0s - loss: 0.0058\n",
      "Epoch 225/1000\n",
      "1/1 - 0s - loss: 0.0058\n",
      "Epoch 226/1000\n",
      "1/1 - 0s - loss: 0.0058\n",
      "Epoch 227/1000\n",
      "1/1 - 0s - loss: 0.0057\n",
      "Epoch 228/1000\n",
      "1/1 - 0s - loss: 0.0057\n",
      "Epoch 229/1000\n",
      "1/1 - 0s - loss: 0.0057\n",
      "Epoch 230/1000\n",
      "1/1 - 0s - loss: 0.0056\n",
      "Epoch 231/1000\n",
      "1/1 - 0s - loss: 0.0056\n",
      "Epoch 232/1000\n",
      "1/1 - 0s - loss: 0.0056\n",
      "Epoch 233/1000\n",
      "1/1 - 0s - loss: 0.0055\n",
      "Epoch 234/1000\n",
      "1/1 - 0s - loss: 0.0055\n",
      "Epoch 235/1000\n",
      "1/1 - 0s - loss: 0.0055\n",
      "Epoch 236/1000\n",
      "1/1 - 0s - loss: 0.0055\n",
      "Epoch 237/1000\n",
      "1/1 - 0s - loss: 0.0054\n",
      "Epoch 238/1000\n",
      "1/1 - 0s - loss: 0.0054\n",
      "Epoch 239/1000\n",
      "1/1 - 0s - loss: 0.0054\n",
      "Epoch 240/1000\n",
      "1/1 - 0s - loss: 0.0053\n",
      "Epoch 241/1000\n",
      "1/1 - 0s - loss: 0.0053\n",
      "Epoch 242/1000\n",
      "1/1 - 0s - loss: 0.0053\n",
      "Epoch 243/1000\n",
      "1/1 - 0s - loss: 0.0053\n",
      "Epoch 244/1000\n",
      "1/1 - 0s - loss: 0.0052\n",
      "Epoch 245/1000\n",
      "1/1 - 0s - loss: 0.0052\n",
      "Epoch 246/1000\n",
      "1/1 - 0s - loss: 0.0052\n",
      "Epoch 247/1000\n",
      "1/1 - 0s - loss: 0.0052\n",
      "Epoch 248/1000\n",
      "1/1 - 0s - loss: 0.0051\n",
      "Epoch 249/1000\n",
      "1/1 - 0s - loss: 0.0051\n",
      "Epoch 250/1000\n",
      "1/1 - 0s - loss: 0.0051\n",
      "Epoch 251/1000\n",
      "1/1 - 0s - loss: 0.0051\n",
      "Epoch 252/1000\n",
      "1/1 - 0s - loss: 0.0050\n",
      "Epoch 253/1000\n",
      "1/1 - 0s - loss: 0.0050\n",
      "Epoch 254/1000\n",
      "1/1 - 0s - loss: 0.0050\n",
      "Epoch 255/1000\n",
      "1/1 - 0s - loss: 0.0050\n",
      "Epoch 256/1000\n",
      "1/1 - 0s - loss: 0.0049\n",
      "Epoch 257/1000\n",
      "1/1 - 0s - loss: 0.0049\n",
      "Epoch 258/1000\n",
      "1/1 - 0s - loss: 0.0049\n",
      "Epoch 259/1000\n",
      "1/1 - 0s - loss: 0.0049\n",
      "Epoch 260/1000\n",
      "1/1 - 0s - loss: 0.0048\n",
      "Epoch 261/1000\n",
      "1/1 - 0s - loss: 0.0048\n",
      "Epoch 262/1000\n",
      "1/1 - 0s - loss: 0.0048\n",
      "Epoch 263/1000\n",
      "1/1 - 0s - loss: 0.0048\n",
      "Epoch 264/1000\n",
      "1/1 - 0s - loss: 0.0047\n",
      "Epoch 265/1000\n",
      "1/1 - 0s - loss: 0.0047\n",
      "Epoch 266/1000\n",
      "1/1 - 0s - loss: 0.0047\n",
      "Epoch 267/1000\n",
      "1/1 - 0s - loss: 0.0047\n",
      "Epoch 268/1000\n",
      "1/1 - 0s - loss: 0.0046\n",
      "Epoch 269/1000\n",
      "1/1 - 0s - loss: 0.0046\n",
      "Epoch 270/1000\n",
      "1/1 - 0s - loss: 0.0046\n",
      "Epoch 271/1000\n",
      "1/1 - 0s - loss: 0.0046\n",
      "Epoch 272/1000\n",
      "1/1 - 0s - loss: 0.0046\n",
      "Epoch 273/1000\n",
      "1/1 - 0s - loss: 0.0045\n",
      "Epoch 274/1000\n",
      "1/1 - 0s - loss: 0.0045\n",
      "Epoch 275/1000\n",
      "1/1 - 0s - loss: 0.0045\n",
      "Epoch 276/1000\n",
      "1/1 - 0s - loss: 0.0045\n",
      "Epoch 277/1000\n",
      "1/1 - 0s - loss: 0.0044\n",
      "Epoch 278/1000\n",
      "1/1 - 0s - loss: 0.0044\n",
      "Epoch 279/1000\n",
      "1/1 - 0s - loss: 0.0044\n",
      "Epoch 280/1000\n",
      "1/1 - 0s - loss: 0.0044\n",
      "Epoch 281/1000\n",
      "1/1 - 0s - loss: 0.0044\n",
      "Epoch 282/1000\n",
      "1/1 - 0s - loss: 0.0043\n",
      "Epoch 283/1000\n",
      "1/1 - 0s - loss: 0.0043\n",
      "Epoch 284/1000\n",
      "1/1 - 0s - loss: 0.0043\n",
      "Epoch 285/1000\n",
      "1/1 - 0s - loss: 0.0043\n",
      "Epoch 286/1000\n",
      "1/1 - 0s - loss: 0.0043\n",
      "Epoch 287/1000\n",
      "1/1 - 0s - loss: 0.0042\n",
      "Epoch 288/1000\n",
      "1/1 - 0s - loss: 0.0042\n",
      "Epoch 289/1000\n",
      "1/1 - 0s - loss: 0.0042\n",
      "Epoch 290/1000\n",
      "1/1 - 0s - loss: 0.0042\n",
      "Epoch 291/1000\n",
      "1/1 - 0s - loss: 0.0042\n",
      "Epoch 292/1000\n",
      "1/1 - 0s - loss: 0.0041\n",
      "Epoch 293/1000\n",
      "1/1 - 0s - loss: 0.0041\n",
      "Epoch 294/1000\n",
      "1/1 - 0s - loss: 0.0041\n",
      "Epoch 295/1000\n",
      "1/1 - 0s - loss: 0.0041\n",
      "Epoch 296/1000\n",
      "1/1 - 0s - loss: 0.0041\n",
      "Epoch 297/1000\n",
      "1/1 - 0s - loss: 0.0040\n",
      "Epoch 298/1000\n",
      "1/1 - 0s - loss: 0.0040\n",
      "Epoch 299/1000\n",
      "1/1 - 0s - loss: 0.0040\n",
      "Epoch 300/1000\n",
      "1/1 - 0s - loss: 0.0040\n",
      "Epoch 301/1000\n",
      "1/1 - 0s - loss: 0.0040\n",
      "Epoch 302/1000\n",
      "1/1 - 0s - loss: 0.0039\n",
      "Epoch 303/1000\n",
      "1/1 - 0s - loss: 0.0039\n",
      "Epoch 304/1000\n",
      "1/1 - 0s - loss: 0.0039\n",
      "Epoch 305/1000\n",
      "1/1 - 0s - loss: 0.0039\n",
      "Epoch 306/1000\n",
      "1/1 - 0s - loss: 0.0039\n",
      "Epoch 307/1000\n",
      "1/1 - 0s - loss: 0.0039\n",
      "Epoch 308/1000\n",
      "1/1 - 0s - loss: 0.0038\n",
      "Epoch 309/1000\n",
      "1/1 - 0s - loss: 0.0038\n",
      "Epoch 310/1000\n",
      "1/1 - 0s - loss: 0.0038\n",
      "Epoch 311/1000\n",
      "1/1 - 0s - loss: 0.0038\n",
      "Epoch 312/1000\n",
      "1/1 - 0s - loss: 0.0038\n",
      "Epoch 313/1000\n",
      "1/1 - 0s - loss: 0.0038\n",
      "Epoch 314/1000\n",
      "1/1 - 0s - loss: 0.0037\n",
      "Epoch 315/1000\n",
      "1/1 - 0s - loss: 0.0037\n",
      "Epoch 316/1000\n",
      "1/1 - 0s - loss: 0.0037\n",
      "Epoch 317/1000\n",
      "1/1 - 0s - loss: 0.0037\n",
      "Epoch 318/1000\n",
      "1/1 - 0s - loss: 0.0037\n",
      "Epoch 319/1000\n",
      "1/1 - 0s - loss: 0.0037\n",
      "Epoch 320/1000\n",
      "1/1 - 0s - loss: 0.0036\n",
      "Epoch 321/1000\n",
      "1/1 - 0s - loss: 0.0036\n",
      "Epoch 322/1000\n",
      "1/1 - 0s - loss: 0.0036\n",
      "Epoch 323/1000\n",
      "1/1 - 0s - loss: 0.0036\n",
      "Epoch 324/1000\n",
      "1/1 - 0s - loss: 0.0036\n",
      "Epoch 325/1000\n",
      "1/1 - 0s - loss: 0.0036\n",
      "Epoch 326/1000\n",
      "1/1 - 0s - loss: 0.0036\n",
      "Epoch 327/1000\n",
      "1/1 - 0s - loss: 0.0035\n",
      "Epoch 328/1000\n",
      "1/1 - 0s - loss: 0.0035\n",
      "Epoch 329/1000\n",
      "1/1 - 0s - loss: 0.0035\n",
      "Epoch 330/1000\n",
      "1/1 - 0s - loss: 0.0035\n",
      "Epoch 331/1000\n",
      "1/1 - 0s - loss: 0.0035\n",
      "Epoch 332/1000\n",
      "1/1 - 0s - loss: 0.0035\n",
      "Epoch 333/1000\n",
      "1/1 - 0s - loss: 0.0035\n",
      "Epoch 334/1000\n",
      "1/1 - 0s - loss: 0.0034\n",
      "Epoch 335/1000\n",
      "1/1 - 0s - loss: 0.0034\n",
      "Epoch 336/1000\n",
      "1/1 - 0s - loss: 0.0034\n",
      "Epoch 337/1000\n",
      "1/1 - 0s - loss: 0.0034\n",
      "Epoch 338/1000\n",
      "1/1 - 0s - loss: 0.0034\n",
      "Epoch 339/1000\n",
      "1/1 - 0s - loss: 0.0034\n",
      "Epoch 340/1000\n",
      "1/1 - 0s - loss: 0.0034\n",
      "Epoch 341/1000\n",
      "1/1 - 0s - loss: 0.0033\n",
      "Epoch 342/1000\n",
      "1/1 - 0s - loss: 0.0033\n",
      "Epoch 343/1000\n",
      "1/1 - 0s - loss: 0.0033\n",
      "Epoch 344/1000\n",
      "1/1 - 0s - loss: 0.0033\n",
      "Epoch 345/1000\n",
      "1/1 - 0s - loss: 0.0033\n",
      "Epoch 346/1000\n",
      "1/1 - 0s - loss: 0.0033\n",
      "Epoch 347/1000\n",
      "1/1 - 0s - loss: 0.0033\n",
      "Epoch 348/1000\n",
      "1/1 - 0s - loss: 0.0033\n",
      "Epoch 349/1000\n",
      "1/1 - 0s - loss: 0.0032\n",
      "Epoch 350/1000\n",
      "1/1 - 0s - loss: 0.0032\n",
      "Epoch 351/1000\n",
      "1/1 - 0s - loss: 0.0032\n",
      "Epoch 352/1000\n",
      "1/1 - 0s - loss: 0.0032\n",
      "Epoch 353/1000\n",
      "1/1 - 0s - loss: 0.0032\n",
      "Epoch 354/1000\n",
      "1/1 - 0s - loss: 0.0032\n",
      "Epoch 355/1000\n",
      "1/1 - 0s - loss: 0.0032\n",
      "Epoch 356/1000\n",
      "1/1 - 0s - loss: 0.0032\n",
      "Epoch 357/1000\n",
      "1/1 - 0s - loss: 0.0031\n",
      "Epoch 358/1000\n",
      "1/1 - 0s - loss: 0.0031\n",
      "Epoch 359/1000\n",
      "1/1 - 0s - loss: 0.0031\n",
      "Epoch 360/1000\n",
      "1/1 - 0s - loss: 0.0031\n",
      "Epoch 361/1000\n",
      "1/1 - 0s - loss: 0.0031\n",
      "Epoch 362/1000\n",
      "1/1 - 0s - loss: 0.0031\n",
      "Epoch 363/1000\n",
      "1/1 - 0s - loss: 0.0031\n",
      "Epoch 364/1000\n",
      "1/1 - 0s - loss: 0.0031\n",
      "Epoch 365/1000\n",
      "1/1 - 0s - loss: 0.0031\n",
      "Epoch 366/1000\n",
      "1/1 - 0s - loss: 0.0030\n",
      "Epoch 367/1000\n",
      "1/1 - 0s - loss: 0.0030\n",
      "Epoch 368/1000\n",
      "1/1 - 0s - loss: 0.0030\n",
      "Epoch 369/1000\n",
      "1/1 - 0s - loss: 0.0030\n",
      "Epoch 370/1000\n",
      "1/1 - 0s - loss: 0.0030\n",
      "Epoch 371/1000\n",
      "1/1 - 0s - loss: 0.0030\n",
      "Epoch 372/1000\n",
      "1/1 - 0s - loss: 0.0030\n",
      "Epoch 373/1000\n",
      "1/1 - 0s - loss: 0.0030\n",
      "Epoch 374/1000\n",
      "1/1 - 0s - loss: 0.0030\n",
      "Epoch 375/1000\n",
      "1/1 - 0s - loss: 0.0030\n",
      "Epoch 376/1000\n",
      "1/1 - 0s - loss: 0.0029\n",
      "Epoch 377/1000\n",
      "1/1 - 0s - loss: 0.0029\n",
      "Epoch 378/1000\n",
      "1/1 - 0s - loss: 0.0029\n",
      "Epoch 379/1000\n",
      "1/1 - 0s - loss: 0.0029\n",
      "Epoch 380/1000\n",
      "1/1 - 0s - loss: 0.0029\n",
      "Epoch 381/1000\n",
      "1/1 - 0s - loss: 0.0029\n",
      "Epoch 382/1000\n",
      "1/1 - 0s - loss: 0.0029\n",
      "Epoch 383/1000\n",
      "1/1 - 0s - loss: 0.0029\n",
      "Epoch 384/1000\n",
      "1/1 - 0s - loss: 0.0029\n",
      "Epoch 385/1000\n",
      "1/1 - 0s - loss: 0.0029\n",
      "Epoch 386/1000\n",
      "1/1 - 0s - loss: 0.0028\n",
      "Epoch 387/1000\n",
      "1/1 - 0s - loss: 0.0028\n",
      "Epoch 388/1000\n",
      "1/1 - 0s - loss: 0.0028\n",
      "Epoch 389/1000\n",
      "1/1 - 0s - loss: 0.0028\n",
      "Epoch 390/1000\n",
      "1/1 - 0s - loss: 0.0028\n",
      "Epoch 391/1000\n",
      "1/1 - 0s - loss: 0.0028\n",
      "Epoch 392/1000\n",
      "1/1 - 0s - loss: 0.0028\n",
      "Epoch 393/1000\n",
      "1/1 - 0s - loss: 0.0028\n",
      "Epoch 394/1000\n",
      "1/1 - 0s - loss: 0.0028\n",
      "Epoch 395/1000\n",
      "1/1 - 0s - loss: 0.0028\n",
      "Epoch 396/1000\n",
      "1/1 - 0s - loss: 0.0028\n",
      "Epoch 397/1000\n",
      "1/1 - 0s - loss: 0.0028\n",
      "Epoch 398/1000\n",
      "1/1 - 0s - loss: 0.0027\n",
      "Epoch 399/1000\n",
      "1/1 - 0s - loss: 0.0027\n",
      "Epoch 400/1000\n",
      "1/1 - 0s - loss: 0.0027\n",
      "Epoch 401/1000\n",
      "1/1 - 0s - loss: 0.0027\n",
      "Epoch 402/1000\n",
      "1/1 - 0s - loss: 0.0027\n",
      "Epoch 403/1000\n",
      "1/1 - 0s - loss: 0.0027\n",
      "Epoch 404/1000\n",
      "1/1 - 0s - loss: 0.0027\n",
      "Epoch 405/1000\n",
      "1/1 - 0s - loss: 0.0027\n",
      "Epoch 406/1000\n",
      "1/1 - 0s - loss: 0.0027\n",
      "Epoch 407/1000\n",
      "1/1 - 0s - loss: 0.0027\n",
      "Epoch 408/1000\n",
      "1/1 - 0s - loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409/1000\n",
      "1/1 - 0s - loss: 0.0027\n",
      "Epoch 410/1000\n",
      "1/1 - 0s - loss: 0.0027\n",
      "Epoch 411/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 412/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 413/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 414/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 415/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 416/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 417/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 418/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 419/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 420/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 421/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 422/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 423/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 424/1000\n",
      "1/1 - 0s - loss: 0.0026\n",
      "Epoch 425/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 426/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 427/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 428/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 429/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 430/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 431/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 432/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 433/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 434/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 435/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 436/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 437/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 438/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 439/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 440/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 441/1000\n",
      "1/1 - 0s - loss: 0.0025\n",
      "Epoch 442/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 443/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 444/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 445/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 446/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 447/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 448/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 449/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 450/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 451/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 452/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 453/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 454/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 455/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 456/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 457/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 458/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 459/1000\n",
      "1/1 - 0s - loss: 0.0024\n",
      "Epoch 460/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 461/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 462/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 463/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 464/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 465/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 466/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 467/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 468/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 469/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 470/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 471/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 472/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 473/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 474/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 475/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 476/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 477/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 478/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 479/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 480/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 481/1000\n",
      "1/1 - 0s - loss: 0.0023\n",
      "Epoch 482/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 483/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 484/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 485/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 486/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 487/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 488/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 489/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 490/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 491/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 492/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 493/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 494/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 495/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 496/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 497/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 498/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 499/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 500/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 501/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 502/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 503/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 504/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 505/1000\n",
      "1/1 - 0s - loss: 0.0022\n",
      "Epoch 506/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 507/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 508/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 509/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 510/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 511/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 512/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 513/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 514/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 515/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 516/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 517/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 518/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 519/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 520/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 521/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 522/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 523/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 524/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 525/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 526/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 527/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 528/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 529/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 530/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 531/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 532/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 533/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 534/1000\n",
      "1/1 - 0s - loss: 0.0021\n",
      "Epoch 535/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 536/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 537/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 538/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 539/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 540/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 541/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 542/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 543/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 544/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 545/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 546/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 547/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 548/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 549/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 550/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 551/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 552/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 553/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 554/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 555/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 556/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 557/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 558/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 559/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 560/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 561/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 562/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 563/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 564/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 565/1000\n",
      "1/1 - 0s - loss: 0.0020\n",
      "Epoch 566/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 567/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 568/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 569/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 570/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 571/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 572/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 573/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 574/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 575/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 576/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 577/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 578/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 579/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 580/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 581/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 582/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 583/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 584/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 585/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 586/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 587/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 588/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 589/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 590/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 591/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 592/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 593/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 594/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 595/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 596/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 597/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 598/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 599/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 600/1000\n",
      "1/1 - 0s - loss: 0.0019\n",
      "Epoch 601/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 602/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 603/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 604/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 605/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 606/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 607/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 608/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 609/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 610/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 611/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 612/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 613/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 614/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 615/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 616/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 617/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 618/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 619/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 620/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 621/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 622/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 623/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 624/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 625/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 626/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 627/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 628/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 629/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 630/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 631/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 632/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 633/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 634/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 635/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 636/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 637/1000\n",
      "1/1 - 0s - loss: 0.0018\n",
      "Epoch 638/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 639/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 640/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 641/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 642/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 643/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 644/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 645/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 646/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 647/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 648/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 649/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 650/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 651/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 652/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 653/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 654/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 655/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 656/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 657/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 658/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 659/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 660/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 661/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 662/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 663/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 664/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 665/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 666/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 667/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 668/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 669/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 670/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 671/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 672/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 673/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 674/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 675/1000\n",
      "1/1 - 0s - loss: 0.0017\n",
      "Epoch 676/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 677/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 678/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 679/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 680/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 681/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 682/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 683/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 684/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 685/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 686/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 687/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 688/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 689/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 690/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 691/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 692/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 693/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 694/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 695/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 696/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 697/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 698/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 699/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 700/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 701/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 702/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 703/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 704/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 705/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 706/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 707/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 708/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 709/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 710/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 711/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 712/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 713/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 714/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 715/1000\n",
      "1/1 - 0s - loss: 0.0016\n",
      "Epoch 716/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 717/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 718/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 719/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 720/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 721/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 722/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 723/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 724/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 725/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 726/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 727/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 728/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 729/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 730/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 731/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 732/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 733/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 734/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 735/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 736/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 737/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 738/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 739/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 740/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 741/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 742/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 743/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 744/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 745/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 746/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 747/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 748/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 749/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 750/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 751/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 752/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 753/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 754/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 755/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 756/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 757/1000\n",
      "1/1 - 0s - loss: 0.0015\n",
      "Epoch 758/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 759/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 760/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 761/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 762/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 763/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 764/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 765/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 766/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 767/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 768/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 769/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 770/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 771/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 772/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 773/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 774/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 775/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 776/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 777/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 778/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 779/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 780/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 781/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 782/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 783/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 784/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 785/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 786/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 787/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 788/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 789/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 790/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 791/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 792/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 793/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 794/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 795/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 796/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 797/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 798/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 799/1000\n",
      "1/1 - 0s - loss: 0.0014\n",
      "Epoch 800/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 801/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 802/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 803/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 804/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 805/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 806/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 807/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 808/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 809/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 810/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 811/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 812/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 813/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 814/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 815/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 816/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 817/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 818/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 819/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 820/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 821/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 822/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 823/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 824/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 825/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 826/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 827/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 828/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 829/1000\n",
      "1/1 - 0s - loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 830/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 831/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 832/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 833/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 834/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 835/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 836/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 837/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 838/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 839/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 840/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 841/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 842/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 843/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 844/1000\n",
      "1/1 - 0s - loss: 0.0013\n",
      "Epoch 845/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 846/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 847/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 848/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 849/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 850/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 851/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 852/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 853/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 854/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 855/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 856/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 857/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 858/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 859/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 860/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 861/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 862/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 863/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 864/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 865/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 866/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 867/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 868/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 869/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 870/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 871/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 872/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 873/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 874/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 875/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 876/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 877/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 878/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 879/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 880/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 881/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 882/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 883/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 884/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 885/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 886/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 887/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 888/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 889/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 890/1000\n",
      "1/1 - 0s - loss: 0.0012\n",
      "Epoch 891/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 892/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 893/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 894/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 895/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 896/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 897/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 898/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 899/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 900/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 901/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 902/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 903/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 904/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 905/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 906/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 907/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 908/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 909/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 910/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 911/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 912/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 913/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 914/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 915/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 916/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 917/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 918/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 919/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 920/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 921/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 922/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 923/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 924/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 925/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 926/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 927/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 928/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 929/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 930/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 931/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 932/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 933/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 934/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 935/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 936/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 937/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 938/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 939/1000\n",
      "1/1 - 0s - loss: 0.0011\n",
      "Epoch 940/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 941/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 942/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 943/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 944/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 945/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 946/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 947/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 948/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 949/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 950/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 951/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 952/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 953/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 954/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 955/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 956/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 957/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 958/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 959/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 960/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 961/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 962/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 963/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 964/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 965/1000\n",
      "1/1 - 0s - loss: 0.0010\n",
      "Epoch 966/1000\n",
      "1/1 - 0s - loss: 9.9865e-04\n",
      "Epoch 967/1000\n",
      "1/1 - 0s - loss: 9.9672e-04\n",
      "Epoch 968/1000\n",
      "1/1 - 0s - loss: 9.9480e-04\n",
      "Epoch 969/1000\n",
      "1/1 - 0s - loss: 9.9288e-04\n",
      "Epoch 970/1000\n",
      "1/1 - 0s - loss: 9.9096e-04\n",
      "Epoch 971/1000\n",
      "1/1 - 0s - loss: 9.8904e-04\n",
      "Epoch 972/1000\n",
      "1/1 - 0s - loss: 9.8713e-04\n",
      "Epoch 973/1000\n",
      "1/1 - 0s - loss: 9.8522e-04\n",
      "Epoch 974/1000\n",
      "1/1 - 0s - loss: 9.8331e-04\n",
      "Epoch 975/1000\n",
      "1/1 - 0s - loss: 9.8140e-04\n",
      "Epoch 976/1000\n",
      "1/1 - 0s - loss: 9.7950e-04\n",
      "Epoch 977/1000\n",
      "1/1 - 0s - loss: 9.7760e-04\n",
      "Epoch 978/1000\n",
      "1/1 - 0s - loss: 9.7570e-04\n",
      "Epoch 979/1000\n",
      "1/1 - 0s - loss: 9.7380e-04\n",
      "Epoch 980/1000\n",
      "1/1 - 0s - loss: 9.7191e-04\n",
      "Epoch 981/1000\n",
      "1/1 - 0s - loss: 9.7002e-04\n",
      "Epoch 982/1000\n",
      "1/1 - 0s - loss: 9.6813e-04\n",
      "Epoch 983/1000\n",
      "1/1 - 0s - loss: 9.6624e-04\n",
      "Epoch 984/1000\n",
      "1/1 - 0s - loss: 9.6435e-04\n",
      "Epoch 985/1000\n",
      "1/1 - 0s - loss: 9.6247e-04\n",
      "Epoch 986/1000\n",
      "1/1 - 0s - loss: 9.6059e-04\n",
      "Epoch 987/1000\n",
      "1/1 - 0s - loss: 9.5871e-04\n",
      "Epoch 988/1000\n",
      "1/1 - 0s - loss: 9.5684e-04\n",
      "Epoch 989/1000\n",
      "1/1 - 0s - loss: 9.5497e-04\n",
      "Epoch 990/1000\n",
      "1/1 - 0s - loss: 9.5310e-04\n",
      "Epoch 991/1000\n",
      "1/1 - 0s - loss: 9.5123e-04\n",
      "Epoch 992/1000\n",
      "1/1 - 0s - loss: 9.4936e-04\n",
      "Epoch 993/1000\n",
      "1/1 - 0s - loss: 9.4750e-04\n",
      "Epoch 994/1000\n",
      "1/1 - 0s - loss: 9.4564e-04\n",
      "Epoch 995/1000\n",
      "1/1 - 0s - loss: 9.4378e-04\n",
      "Epoch 996/1000\n",
      "1/1 - 0s - loss: 9.4193e-04\n",
      "Epoch 997/1000\n",
      "1/1 - 0s - loss: 9.4007e-04\n",
      "Epoch 998/1000\n",
      "1/1 - 0s - loss: 9.3822e-04\n",
      "Epoch 999/1000\n",
      "1/1 - 0s - loss: 9.3637e-04\n",
      "Epoch 1000/1000\n",
      "1/1 - 0s - loss: 9.3453e-04\n",
      "0.1\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "#prepare sequence\n",
    "length = 5\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(1, length, 1)\n",
    "y = seq.reshape(1, length, 1)\n",
    "\n",
    "#LSTM configuration\n",
    "n_neurons = length\n",
    "n_batch = 1\n",
    "n_epoch = 1000\n",
    "#create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(length, 1), return_sequences=True))\n",
    "model.add(tf.keras.layers.TimeDistributed(Dense(1)))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n",
    "\n",
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=2)\n",
    "\n",
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "for value in result[0,:,0]:\n",
    "    print('%.1f' % value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funtional APIs \n",
    "#### Multilayer Perceptron\n",
    "- This is  multilayer perceptron model for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 784, 1)]          0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 784, 10)           20        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 784, 20)           220       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 784, 10)           210       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 784, 1)            11        \n",
      "=================================================================\n",
      "Total params: 461\n",
      "Trainable params: 461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(28*28,1))\n",
    "hidden1 = tf.keras.layers.Dense(10, activation='relu')(inputs)\n",
    "hidden2 = tf.keras.layers.Dense(20, activation='relu')(hidden1)\n",
    "hidden3 = tf.keras.layers.Dense(10, activation='relu')(hidden2)\n",
    "output = tf.keras.layers.Dense(1, activation='relu')(hidden3)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001,),\n",
    "        metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 20s 413us/sample - loss: 6.6645 - accuracy: 0.0985 - val_loss: 6.6644 - val_accuracy: 0.0995\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 18s 383us/sample - loss: 6.6644 - accuracy: 0.0985 - val_loss: 6.6644 - val_accuracy: 0.0995\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_split=0.2, batch_size = 100 , epochs=2, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 64, 64, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 61, 61, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 16)        8208      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2704)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                27050     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 35,813\n",
      "Trainable params: 35,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network for image classification.\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "inputs = tf.keras.Input(shape=(64,64,1))\n",
    "conv1 = tf.keras.layers.Conv2D(32, kernel_size=4, activation='relu')(inputs)\n",
    "pool1 = tf.keras.layers.MaxPooling2D((2,2))(conv1)\n",
    "\n",
    "conv2 = tf.keras.layers.Conv2D(16, kernel_size=4, activation='relu')(pool1)\n",
    "pool2 = tf.keras.layers.MaxPooling2D((2,2))(conv2)\n",
    "\n",
    "flat = Flatten()(pool2)\n",
    "hidden1 = tf.keras.layers.Dense(10, activation='relu')(flat)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(hidden1)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 784, 1)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 10)                480       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 601\n",
      "Trainable params: 601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recurrent Neural Network before using this model scale datasset to range btn 0 - 1\n",
    "inputs = tf.keras.Input(shape=(28*28,1))\n",
    "hidden1 = tf.keras.layers.LSTM(10)(inputs)\n",
    "hidden2 = tf.keras.layers.Dense(10, activation='relu')(hidden1)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(hidden2)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Input Layer\n",
    "- This model uses different sized kernels to interpret an image input, there is a shared input btn submodels which ouputs are flatten into vectors and concatented into one long vector then passed to the fully connected layer for interpretation\n",
    "- Final output layer makes a binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 64, 46, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 61, 43, 32)   544         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 57, 39, 16)   1040        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 30, 21, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 28, 19, 16)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 20160)        0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 8512)         0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 28672)        0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 10)           286730      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            11          dense_22[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 288,325\n",
      "Trainable params: 288,325\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Input Layer\n",
    "inputs = tf.keras.Input(shape=(64,46,1))\n",
    "\n",
    "#First feature extractor\n",
    "conv1 = tf.keras.layers.Conv2D(32, kernel_size=4, activation='relu')(inputs)\n",
    "pool1 = tf.keras.layers.MaxPooling2D((2,2))(conv1)\n",
    "flat1 = tf.keras.layers.Flatten()(pool1)\n",
    "\n",
    "#Second feature ectractor\n",
    "conv2 = tf.keras.layers.Conv2D(16, kernel_size=8, activation='relu')(inputs)\n",
    "pool2 = tf.keras.layers.MaxPooling2D((2,2))(conv2)\n",
    "flat2 = tf.keras.layers.Flatten()(pool2)\n",
    "\n",
    "#Merge feature extractor\n",
    "merge = tf.keras.layers.concatenate([flat1, flat2])\n",
    "\n",
    "#interpretation layer\n",
    "hidden1 = tf.keras.layers.Dense(10, activation='relu')(merge)\n",
    "#Prediction output\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(hidden1)\n",
    "model = tf.keras.Model(inputs= inputs, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Feature Extraction Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 10)           480         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 10)           110         lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 20)           220         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 10)           110         lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 10)           210         dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20)           0           dense_24[0][0]                   \n",
      "                                                                 dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 1)            21          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,151\n",
      "Trainable params: 1,151\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define input\n",
    "inputs = tf.keras.Input(shape=(100,1))\n",
    "\n",
    "#Feature Extraction\n",
    "extract1 = tf.keras.layers.LSTM(10)(inputs)\n",
    "\n",
    "#First interpretation model\n",
    "interp1 = tf.keras.layers.Dense(10, activation='relu')(extract1)\n",
    "\n",
    "#Second interpretation\n",
    "interpl1 = tf.keras.layers.Dense(10, activation='relu')(extract1)\n",
    "interpl2 = tf.keras.layers.Dense(20, activation='relu')(interpl1)\n",
    "interpl3 = tf.keras.layers.Dense(10, activation='relu')(interpl2)\n",
    "\n",
    "#Merge interpretation\n",
    "merge = tf.keras.layers.concatenate([interp1, interpl3])\n",
    "\n",
    "#output\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(merge)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Input Model\n",
    "- image classification of two versions of the image as input is black and white and a color version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 61, 61, 32)   544         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 29, 29, 32)   1568        input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 30, 30, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 32)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 27, 27, 16)   8208        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 11, 11, 16)   8208        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 16)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 5, 5, 16)     0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2704)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 400)          0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3104)         0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 10)           31050       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 10)           110         dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 1)            11          dense_30[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 49,699\n",
      "Trainable params: 49,699\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# first input model\n",
    "inputs1 = tf.keras.Input(shape=(64,64,1))\n",
    "\n",
    "#First input model\n",
    "conv11 = tf.keras.layers.Conv2D(32, kernel_size=4, activation='relu')(inputs1)\n",
    "pool11 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv11)\n",
    "conv12 = tf.keras.layers.Conv2D(16, kernel_size=4, activation='relu')(pool11)\n",
    "pool12 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv12)\n",
    "flat1 = tf.keras.layers.Flatten()(pool12)\n",
    "\n",
    "# second input model\n",
    "inputs2 = tf.keras.Input(shape=(32,32,3))\n",
    "conv21 = tf.keras.layers.Conv2D(32, kernel_size=4, activation='relu')(inputs2)\n",
    "pool21 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv21)\n",
    "conv22 = tf.keras.layers.Conv2D(16, kernel_size=4, activation='relu')(pool21)\n",
    "pool22 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv22)\n",
    "flat2 = tf.keras.layers.Flatten()(pool22)\n",
    "\n",
    "# merge input models\n",
    "merge = tf.keras.layers.concatenate([flat1, flat2])\n",
    "\n",
    "# interpretation model\n",
    "hidden1 = tf.keras.layers.Dense(10, activation='relu')(merge)\n",
    "hidden2 = tf.keras.layers.Dense(10, activation='relu')(hidden1)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(hidden2)\n",
    "model = tf.keras.Model(inputs=[inputs1, inputs2], outputs=output)\n",
    "\n",
    "# summarize layers\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Output Model\n",
    " - First output creates a stacked LSTM interprets the features and makes a binary prediction\n",
    " - Second output model uses the same output layer to make a real-valued prediction for each input step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 100, 10)      480         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 10)           840         lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 10)           110         lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 1)            11          dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 100, 1)       11          lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,452\n",
      "Trainable params: 1,452\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input layer\n",
    "inputs = tf.keras.Input(shape=(100,1))\n",
    "\n",
    "# feature extraction\n",
    "extract = LSTM(10, return_sequences=True)(inputs)\n",
    "\n",
    "# classification output\n",
    "class11 = tf.keras.layers.LSTM(10)(extract)\n",
    "class12 = tf.keras.layers.Dense(10, activation='relu')(class11)\n",
    "output1 = tf.keras.layers.Dense(1, activation='sigmoid')(class12)\n",
    "\n",
    "# sequence output\n",
    "output2 = tf.keras.layers.TimeDistributed(Dense(1, activation='linear'))(extract)\n",
    "\n",
    "# output\n",
    "model = tf.keras.Model(inputs=inputs, outputs=[output1, output2])\n",
    "# summarize layers\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
